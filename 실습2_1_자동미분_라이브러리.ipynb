{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shriver42/OUTTA/blob/main/%EC%8B%A4%EC%8A%B52_1_%EC%9E%90%EB%8F%99%EB%AF%B8%EB%B6%84_%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25533d3b",
      "metadata": {
        "id": "25533d3b"
      },
      "source": [
        "# 실습 3: 자동미분(AutoDiff) 라이브러리"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f60968f6",
      "metadata": {
        "id": "f60968f6"
      },
      "source": [
        "앞서 우리는 그래디언트 기반 학습에 대해 살펴보았다. $\\mathscr{L}$이 간단한 함수일 때는 편미분하는 것이 간단한 일이었지만, 앞으로는 손으로 편미분을 계산하기는 어려운 다양한 함수들을 $\\mathscr{L}$ 로 만나게 될 것이다. 이럴 때 필요한 것이 바로 컴퓨터의 계산 능력이다. 그래디언트 기반 학습에 대한 관심이 크게 증가하면서, 미분을 자동으로 계산해주는 자동미분 라이브러리가 여럿 개발되었다. 널리 쓰이는 라이브러리로는 [PyTorch](https://pytorch.org/), [TensorFlow](https://www.tensorflow.org/), [JAX](https://github.com/google/jax), [Zygote](https://github.com/FluxML/Zygote.jl) 등이 있다.\n",
        "\n",
        "이 책에서는 위의 라이브러리 중에서 쉽게 이해하고 사용할 수 있는 PyTorch 라이브러리를 사용할 것이다. 이 라이브러리는 NumPy 라이브러리와 매우 유사하게 동작하기 때문에, NumPy만 잘 알아도 쉽게 사용할 수 있다. NumPy에서 ndarray(배열)가 기본이 되는 핵심 객체인 것과 같이, PyTorch의 핵심 객체는 Tensor(텐서)라고 부른다. 이 Tensor는 ndarray와 매우 유사하게 동작이 가능하다.\n",
        "\n",
        "이 실습에서 PyTorch를 통한 자동미분에 익숙해지고 나면, 이 책 전반에 걸쳐 PyTorch를 자유자재로 사용하며 딥러닝을 배우게 될 것이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e93acc4d",
      "metadata": {
        "id": "e93acc4d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch as tc\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03d35d08",
      "metadata": {
        "id": "03d35d08"
      },
      "source": [
        "구글 코랩(Google Colab)에서는 PyTorch가 기본적으로 설치되어 있다. 따라서 별도로 설치할 필요 없이 바로 사용 가능하다. PyTorch가 제대로 설치되어 있는지 확인하려면 아래와 같은 코드를 실행해볼 수 있다.\n",
        "torch.cuda.is_available() 코드가 False의 결과가 나오면 메뉴에서\n",
        "\n",
        "런타임 > 런타임 유형 변경 > 하드웨어 가속기\n",
        "\n",
        "에서 보면 CPU가 선택되어 있을 것인데 이를 GPU로 바꿔줘야 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "kPxSBddWT2OT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPxSBddWT2OT",
        "outputId": "4a82fcdf-81e2-4603-eeab-e94d913eb62e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.0+cu121\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a73926ed",
      "metadata": {
        "id": "a73926ed"
      },
      "source": [
        "### Step 1. PyTorch의 여러가지 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "335815d5",
      "metadata": {
        "id": "335815d5"
      },
      "source": [
        "라이브러리를 사용할 때, 유명한 라이브러리의 경우에는 구글링을 통해 쉽게 설명된 블로그 등을 참고할 수도 있다. 하지만 정석은 라이브러리 개발자가 작성한 도큐먼트(document)를 읽는 것이다. 이 실습에서는 PyTorch를 사용한 자동미분을 배우는 것을 가장 중요한 목적으로 다루고 있으므로, 더 다양한 함수와 기능이 궁금하다면 직접 [도큐먼트](https://mygrad.readthedocs.io/en/latest/)를 읽어보길 바란다. 또한, NumPy의 기본 함수들과 일치하는 함수를 많이 가지고 있으므로, NumPy의 함수들을 찾아 PyTorch에 적용해보아도 좋다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d06b0a0d",
      "metadata": {
        "id": "d06b0a0d"
      },
      "source": [
        "#### Tensor 생성\n",
        "Tensor는 Pytorch 라이브러리에서 사용하는 데이터를 배열 형식으로 저장하도록 한다. 다양한 방식으로 Tensor를 생성할 수 있다. 다음은 Tensor를 생성하는 여러 가지 예이다. tc.tensor 외에도 Tensor를 생성하는 다양한 함수들이 있다. 직접 코드를 실행하여 output을 확인해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "42d2424d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42d2424d",
        "outputId": "6979339b-1123-4789-d26c-05dfdd1075ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3000)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# 단일 숫자로 생성한 Tensor\n",
        "tc.tensor(2.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4b71a705",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b71a705",
        "outputId": "4ca516d3-9d03-4ecd-c3f1-3dac56a27180"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# 시퀀스(리스트, 튜플 등) 자료형으로 생성한 Tensor.\n",
        "# dtype을 지정할 수 있는 모든 함수에서\n",
        "# 32-bit floats를 저장하는 텐서를 반환하도록 지정 가능.\n",
        "tc.tensor([1.0, 2.0, 3.0], dtype = tc.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "737f62f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "737f62f3",
        "outputId": "d684bfe1-0261-4143-e264-696ec26bbe0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# numpy.ndarray로부터 생성한 Tensor\n",
        "arr = np.ones((3,3))\n",
        "tc.tensor(arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "970b3585",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "970b3585",
        "outputId": "ca814013-1394-487d-a139-671cfb568241"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Tensor 생성 함수 (ones, zeros; 각각 1, 0으로 채움)\n",
        "#tensor는 가장 바깥쪽으로 부터 읽어나가면 된다. 2: 차원 3: 행, 4: 열\n",
        "tc.zeros([2,3,4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "dbe81f6c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbe81f6c",
        "outputId": "18dc9522-025e-43d9-8970-d1084e921d72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-5, -3, -1,  1,  3,  5,  7,  9, 11, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Tensor 생성 함수 (start 부터 stop 까지 step 만큼 띄워가며 채움)\n",
        "#python과 동일하게 마지막 값은 포함 안한다.\n",
        "tc.arange(-5,15,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ae113b63",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae113b63",
        "outputId": "56b40a3a-1d37-4bf4-f82c-5cc732ab106d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8.])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# start = 0, step = 1이 default 값\n",
        "tc.arange(9.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "fbdb971e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbdb971e",
        "outputId": "bccf248c-30b0-4809-dd55-bc193a3d8b3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4860, 0.3839, 0.1662, 0.5960],\n",
              "        [0.8686, 0.6200, 0.5239, 0.9823],\n",
              "        [0.6334, 0.9245, 0.1514, 0.8861]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# 0~1 사이의 값 무작위로 리턴 (확률분포는 균등분포(uniform))\n",
        "tc.rand(3,4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9373be2a",
      "metadata": {
        "id": "9373be2a"
      },
      "source": [
        "<문제: 주어진 조건을 만족하는 Tensor 생성하기>\n",
        "\n",
        "구간 $[0, \\pi]$에 등간격으로 분포한 15개의 구성요소로 이루어진 shape-(15,)인 tensor를 만들어보자. (Hint: tc.linspace(), tc.pi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "82ebd43d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82ebd43d",
        "outputId": "c25f7bbd-ce4a-4fbd-c4bc-771a364e7d6a",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.2244, 0.4488, 0.6732, 0.8976, 1.1220, 1.3464, 1.5708, 1.7952,\n",
              "        2.0196, 2.2440, 2.4684, 2.6928, 2.9172, 3.1416])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "tc.linspace(0,tc.pi,15)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71697cae",
      "metadata": {
        "id": "71697cae"
      },
      "source": [
        "#### Tensor 변형\n",
        "Tensor의 모양을 변형하는 함수들도 있다. 직접 코드를 실행하여 output을 확인해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "38946f50",
      "metadata": {
        "id": "38946f50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f85b8df1-1b11-4cf9-ec56-dc978749a9c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 2.],\n",
              "        [3., 4., 5.],\n",
              "        [6., 7., 8.]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Tensor의 행과 열을 바꾸어주는 함수\n",
        "x = tc.arange (9.) #Tensor([0., 1., 2., 3., 4., 5., 6., 7., 8.])\n",
        "x.reshape(3,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "3a22b453",
      "metadata": {
        "id": "3a22b453",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f28789e-eb8c-4ef9-c784-9e7301259eba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  3,  6,  9],\n",
              "        [ 1,  4,  7, 10],\n",
              "        [ 2,  5,  8, 11]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Tensor의 전치 행렬을 구하는 함수\n",
        "x = tc.tensor([[0,1,2],[3,4,5],[6,7,8],[9,10,11]])\n",
        "x.t()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "a38b3441",
      "metadata": {
        "id": "a38b3441",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c82ffda-5d6c-40d0-893b-c5cf1a3d6a40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# 슬라이싱 (자유자재로 쓸 수 있으면 좋다)\n",
        "x = tc.tensor([[1,2,3,4,5],[6,7,8,9,10]])\n",
        "x[0,2:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "6320c0ee",
      "metadata": {
        "id": "6320c0ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8db8440b-ab2e-4db5-c388-e2e4df6239c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "x = tc.tensor([[1,2,3,4,5],[6,7,8,9,10]])\n",
        "x[0, -3:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6232d6c1",
      "metadata": {
        "id": "6232d6c1"
      },
      "source": [
        "#### Tensor 표준 수학 연산\n",
        "\n",
        "먼저, PyTorch에서 제공하는 표준적인 수학 함수들을 알아보자. 기본적인 산술 연산을 하는 함수를 비롯하여, (sum, mean, var, std, max, min) 등의 통계량을 구하는 함수 등이 제공된다. 또한, 삼각함수, 쌍곡함수, 지수함수, 로그함수 등의 초월함수도 제공된다. NumPy의 함수들과 동일하게, 벡터화된 함수들이다.\n",
        "\n",
        "단항 함수는 텐서에 대해 요소별로 각각 작동한다. 이항 함수는 두 텐서에 대해 대응되는 위치의 요소 간에 자연스럽게 작동한다. 두 텐서가 동일한 모양이 아니더라도 Numpy와 같은 [브로드캐스팅(Broadcasting)](https://numpy.org/doc/stable/user/basics.broadcasting.html) 규칙을 따르기 때문에, 이항 함수가 작동할 수 있는 경우가 있다.\n",
        "\n",
        "직접 코드를 실행하여 output을 확인해보자. 이를 통해 단항 연산과 이항 연산을 다루는 여러 함수에 대해 이해해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "b4d930c8",
      "metadata": {
        "id": "b4d930c8"
      },
      "outputs": [],
      "source": [
        "x = tc.tensor([0.0, 0.25, 0.5, 0.75, 1.0])\n",
        "y = tc.tensor([[0.],[1.],[2.]])\n",
        "z = tc.tensor([[0,1,2,3],[4,5,6,7],[8,9,10,11]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "aa53ba6b",
      "metadata": {
        "id": "aa53ba6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8c4e20c-86fd-4915-bcf3-6362c295de13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.2474, 0.4794, 0.6816, 0.8415])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# 단항 함수 중 하나인 삼각함수 sin()\n",
        "# 텐서의 모든 요소의 sin 값으로 채워진 같은 크기의 텐서\n",
        "tc.sin(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "27891022",
      "metadata": {
        "id": "27891022",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d497187-3f34-45ff-943a-d9a9c43c964f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(66)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# 단항 함수 중 통계량을 구하는 함수들은 axis 인자를 가짐\n",
        "# axis가 0이면 행에 대해서만 함수를 적용하고,\n",
        "# axis가 1이면 열에 대해서만 함수를 적용\n",
        "tc.sum(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "99ed2ce2",
      "metadata": {
        "id": "99ed2ce2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e5302a2-061a-4779-9594-defcd527c83f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12, 15, 18, 21])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "tc.sum(z, axis = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "628e8b1b",
      "metadata": {
        "id": "628e8b1b"
      },
      "source": [
        "z = tc.tensor([[0,1,2,3],[4,5,6,7],[8,9,10,11]])\n",
        "\n",
        "=>\n",
        "\n",
        "$[[0,1,2,3], \\\\\n",
        "    [4,5,6,7], \\\\\n",
        "    [8,9,10,11]]$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "9fe0294b",
      "metadata": {
        "id": "9fe0294b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "071e6e91-8116-459c-88f0-807bb8617b3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 6, 22, 38])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "tc.sum(z, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "b9686434",
      "metadata": {
        "id": "b9686434",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cf298e2-0c61-40a2-ba49-d8d17ba3e8ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.2500, 0.5000, 0.7500, 1.0000],\n",
              "        [1.0000, 1.2500, 1.5000, 1.7500, 2.0000],\n",
              "        [2.0000, 2.2500, 2.5000, 2.7500, 3.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# 브로드캐스팅 예(1)\n",
        "# x+y, y+z는 브로드캐스팅이 가능, x+z는 불가능\n",
        "#더 작은 텐서가 큰 텐서에 맞춰서 알아서 연산을 해준다\n",
        "x+y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "6c0e5310",
      "metadata": {
        "id": "6c0e5310",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b09ef63-1f54-40bb-cb77-a0dbaccabb4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.],\n",
              "        [ 5.,  6.,  7.,  8.],\n",
              "        [10., 11., 12., 13.]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "y+z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ef7e7090",
      "metadata": {
        "id": "ef7e7090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "fd3110e9-534e-4b32-8cc1-8d3c76823790"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-0e52b3dd32a7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mz\u001b[0m \u001b[0;31m# Error 발생\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1"
          ]
        }
      ],
      "source": [
        "x+z # Error 발생"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "942ebf93",
      "metadata": {
        "id": "942ebf93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ab364d7-b9eb-4662-a561-b497758fdefd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.2500, 0.5000, 0.7500, 1.0000],\n",
              "        [0.0000, 0.5000, 1.0000, 1.5000, 2.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# 브로드캐스팅 예(2)\n",
        "# x*y, y*z는 브로드캐스팅이 가능, x*z는 불가능\n",
        "x*y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "45b61b7f",
      "metadata": {
        "id": "45b61b7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cebe9256-59b6-41db-c731-e4adaf8aeb20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  0.,  0.,  0.],\n",
              "        [ 4.,  5.,  6.,  7.],\n",
              "        [16., 18., 20., 22.]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "y*z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "6b613e37",
      "metadata": {
        "id": "6b613e37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "3bab0c76-0ea7-48c4-d163-84e13c60c3fe"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-babf0bcfe656>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mz\u001b[0m \u001b[0;31m# Error 발생\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1"
          ]
        }
      ],
      "source": [
        "x*z # Error 발생"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad45aec1",
      "metadata": {
        "id": "ad45aec1"
      },
      "source": [
        "<문제: Pytorch의 기본 수학 연산>\n",
        "\n",
        "아래와 같이 정의된 텐서 x에 대해 여러 가지 수학 연산을 적용하여 여러 가지 텐서를 구해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "a98929d0",
      "metadata": {
        "id": "a98929d0"
      },
      "outputs": [],
      "source": [
        "x = tc.Tensor([[ 0.,  1.,  2.,  3.],\n",
        "...                [ 4.,  5.,  6.,  7.],\n",
        "...                [ 8.,  9., 10., 11.],\n",
        "...                [12., 13., 14., 15.]])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1번 문제"
      ],
      "metadata": {
        "id": "prqrJypdiwJ2"
      },
      "id": "prqrJypdiwJ2"
    },
    {
      "cell_type": "markdown",
      "id": "6e03887e",
      "metadata": {
        "id": "6e03887e"
      },
      "source": [
        "1. x의 3행의 첫번째, 세번째 원소에 대한 자연로그 값으로 채워진 shape-(2,)인 Tensor를 구해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "7b89e057",
      "metadata": {
        "id": "7b89e057",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ad3eba8-b2cf-4a97-f055-2b9ecaebfb64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.0794, 2.3026])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "tc.log(x[2,0::2])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d1e928f",
      "metadata": {
        "id": "3d1e928f"
      },
      "source": [
        "## 1번 문제 정답"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tc.log(x[2,0::2])"
      ],
      "metadata": {
        "id": "2wSGga_FiWIq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0622dd8-d3ef-4ec6-f245-88068b6ce0a7"
      },
      "id": "2wSGga_FiWIq",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.0794, 2.3026])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1번 문제 출력 결과 : tensor([2.0794, 2.3026])"
      ],
      "metadata": {
        "id": "F7fzgO9kikUX"
      },
      "id": "F7fzgO9kikUX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2번 문제"
      ],
      "metadata": {
        "id": "6M3xaJomisFT"
      },
      "id": "6M3xaJomisFT"
    },
    {
      "cell_type": "markdown",
      "id": "65c19bdd",
      "metadata": {
        "id": "65c19bdd"
      },
      "source": [
        "2. x를 가로, 세로로 4등분한 각 귀퉁이(왼쪽 위, 오른쪽 위, 왼쪽 아래, 오른쪽 아래)의 4개 원소를 더하여 shape-(2,2)인 Tensor를 구해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "b0076def",
      "metadata": {
        "id": "b0076def",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd570769-6a23-480b-874b-57f359ab7a93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[20., 24.],\n",
              "        [36., 40.]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "x[:2,:2]+x[:2,2:]+x[2:,:2]+x[2:,2:]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2번 문제 정답"
      ],
      "metadata": {
        "id": "AyY6znLKidQj"
      },
      "id": "AyY6znLKidQj"
    },
    {
      "cell_type": "code",
      "source": [
        "x[:2,:2] + x[:2,2:] + x[2:,:2] + x[2:,2:]"
      ],
      "metadata": {
        "id": "a3JavlrAi3Nn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f91a2e1-8bee-4996-e755-630d6a576b0b"
      },
      "id": "a3JavlrAi3Nn",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[20., 24.],\n",
              "        [36., 40.]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2번 문제 출력 결과 :\n",
        "\n",
        "tensor([[20., 24.],\\\n",
        "        [36., 40.]])"
      ],
      "metadata": {
        "id": "2ZYKqDfmjKFu"
      },
      "id": "2ZYKqDfmjKFu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3번 문제"
      ],
      "metadata": {
        "id": "t8AcEm9Ni-9i"
      },
      "id": "t8AcEm9Ni-9i"
    },
    {
      "cell_type": "markdown",
      "id": "d18ec6e0",
      "metadata": {
        "id": "d18ec6e0"
      },
      "source": [
        "  3. x의 각 열의 평균을 구하여 shape-(4,)인 Tensor를 구해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "5ff6a6bc",
      "metadata": {
        "id": "5ff6a6bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35d97670-c097-4780-8743-782ba1da9d02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6., 7., 8., 9.])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "tc.mean(x, axis= 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3번 문제 정답"
      ],
      "metadata": {
        "id": "Mf_Q1BkEjoCf"
      },
      "id": "Mf_Q1BkEjoCf"
    },
    {
      "cell_type": "code",
      "source": [
        "x.mean(axis=0)"
      ],
      "metadata": {
        "id": "-pmoGU-0jnk5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32f681b2-0155-444f-e1d6-cd539ab0d2c6"
      },
      "id": "-pmoGU-0jnk5",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6., 7., 8., 9.])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3번 문제 출력 결과 : tensor([6., 7., 8., 9.])"
      ],
      "metadata": {
        "id": "Pn-E0xyKjobv"
      },
      "id": "Pn-E0xyKjobv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4번 문제"
      ],
      "metadata": {
        "id": "W7y-HGgwjzr7"
      },
      "id": "W7y-HGgwjzr7"
    },
    {
      "cell_type": "markdown",
      "id": "d29b6965",
      "metadata": {
        "id": "d29b6965"
      },
      "source": [
        "4. x의 각 행을 벡터로보고, 각 벡터가 크기가 1이 되도록 정규화하여 shape-(4,4)인 Tensor로 업데이트해보자."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 백터의 크기를 1로 만들기 ㅜ이해 백터를 L2  노름으로 나누는 과정 : 정규화\n",
        "x /= tc.sqrt(tc.sum(x**2, axis = 1, keepdims = True))\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGii2EgCN_si",
        "outputId": "d4d21f2f-cd84-46fa-ac6e-3896f62988f7"
      },
      "id": "aGii2EgCN_si",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.2673, 0.5345, 0.8018],\n",
              "        [0.3563, 0.4454, 0.5345, 0.6236],\n",
              "        [0.4182, 0.4704, 0.5227, 0.5750],\n",
              "        [0.4429, 0.4798, 0.5167, 0.5537]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "d038eb54",
      "metadata": {
        "id": "d038eb54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95937197-ffce-4a8c-fb4f-d4e4a9c15ff1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 1.0000, 1.0000, 1.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# 정규화가 잘 되었는지 확인하기\n",
        "(x**2).sum(axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4번 문제 정답"
      ],
      "metadata": {
        "id": "-zPuP1PPj_yj"
      },
      "id": "-zPuP1PPj_yj"
    },
    {
      "cell_type": "code",
      "source": [
        "x /= tc.sqrt(tc.sum(x**2,axis=1,keepdims = True))\n",
        "x"
      ],
      "metadata": {
        "id": "hZ_679jyj3rQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d3bf643-09de-4f59-cbc3-b0fca96ef36d"
      },
      "id": "hZ_679jyj3rQ",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.2673, 0.5345, 0.8018],\n",
              "        [0.3563, 0.4454, 0.5345, 0.6236],\n",
              "        [0.4182, 0.4704, 0.5227, 0.5750],\n",
              "        [0.4429, 0.4798, 0.5167, 0.5537]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4번 문제 출력 결과 : \\\\\n",
        "\n",
        "tensor([[0.0000, 0.2673, 0.5345, 0.8018], \\\n",
        "        [0.3563, 0.4454, 0.5345, 0.6236], \\\n",
        "        [0.4182, 0.4704, 0.5227, 0.5750], \\\n",
        "        [0.4429, 0.4798, 0.5167, 0.5537]])"
      ],
      "metadata": {
        "id": "dVP8WS0PkDKT"
      },
      "id": "dVP8WS0PkDKT"
    },
    {
      "cell_type": "code",
      "source": [
        "# 정규화가 잘 되었는지 확인하기 정답\n",
        "(x**2).sum(axis=1)"
      ],
      "metadata": {
        "id": "J9xPBjRsj3ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0d71f84-c372-4415-a9cf-c9400d5e673b"
      },
      "id": "J9xPBjRsj3ff",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 1.0000, 1.0000, 1.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#   "
      ],
      "metadata": {
        "id": "n8GyohNmkccZ"
      },
      "id": "n8GyohNmkccZ"
    },
    {
      "cell_type": "markdown",
      "id": "ca7b8e69",
      "metadata": {
        "id": "ca7b8e69"
      },
      "source": [
        "#### 선형대수 연산 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47ce788e",
      "metadata": {
        "id": "47ce788e"
      },
      "source": [
        "PyTorch에는 선형대수 연산을 쉽게 계산하도록 도와주는 함수들도 있다. matmul()은 행렬곱을 계산해주는 함수이다. 이를 이용하여 벡터의 점곱(스칼라곱)을 계산할 수도 있다. einsum()은 아인슈타인 표기법(Einstein notation 또는 Einstein summation convention)을 계산하는 함수이다. 이는 다소 복잡한 함수이지만, 다양한 사용자 지정 가능한 선형 대수 연산을 수행할 수 있다. PyTorch가 자동미분을 수행할 때 이 연산들을 통해 수행한다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "171b9c09",
      "metadata": {
        "id": "171b9c09"
      },
      "source": [
        "먼저 이항 연산 함수인 matmul()연산은 행렬곱을 기본으로 하는 함수이므로 2차원 텐서 간의 연산이 가장 자연스럽게 정의된다. 1차원 텐서 간의 matmul()을 명령하면 1차원 텐서를 1xn 크기의 2차원 텐서로 생각하여 연산을 진행한다. 그리고 n차원(3차원 이상)의 텐서 간의 matmul()은 n-2차원의 텐서의 구성요소가 2차원 텐서(행렬)인 것으로 생각하여 연산을 진행한다. 즉, 행렬이 여러개 모여있는 것으로 생각하고 행렬곱을 진행하는 것이다. matmul()연산 또한 NumPy의 브로드캐스팅 규칙을 따르는 함수이기 때문에 3차원 이상의 텐서에 대해서는 브로드캐스팅에도 유의해야 한다.\n",
        "\n",
        "matmul()을 사용할 때는 tc.matmul(x,y)로 사용할 수 있지만, x @ y 와 같이 연산자 @를 이용하여도 같은 연산을 할 수 있도록 정의되어 있다. 아래의 사용 예시를 따라가면 matmul() 함수의 사용법을 이해할 수 있을 것이다. 직접 코드를 실행하여 output을 확인해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "c0d89dcb",
      "metadata": {
        "id": "c0d89dcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84153967-080e-43c4-c455-09b604d5b53b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-11.)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# 1차원 텐서의 matmul 연산은 점곱(스칼라곱)을 구하는 것과 같음\n",
        "# 내적을 구하는 것과 동일하다\n",
        "x = tc.tensor([1.0, 2.0])\n",
        "y = tc.tensor([-3.0, -4.0])\n",
        "tc.matmul(x,y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1차원 텐서의 matmul 연산은 점곱(스칼라곱)을 구하는 것과 같음\n",
        "# @ : matrix multiplication\n",
        "x = tc.tensor([1.0, 2.0])\n",
        "y = tc.tensor([-3.0, -4.0])\n",
        "x@y"
      ],
      "metadata": {
        "id": "oKmJhLeklBTI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "488eaf4b-fb0c-4afa-e5c8-714cdcf157ff"
      },
      "id": "oKmJhLeklBTI",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-11.)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "594d0ad6",
      "metadata": {
        "id": "594d0ad6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56a2494a-5471-410b-9915-24145f5951d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4,  1,  5],\n",
              "        [ 2,  2,  6],\n",
              "        [10,  4, 16],\n",
              "        [20, 11, 39]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# 2차원 텐서의 matmul 연산은 그냥 행렬곱과 같음\n",
        "a = tc.tensor([[1, 0], [0, 1], [2, 1], [3, 4]])\n",
        "b = tc.tensor([[4, 1, 5], [2, 2, 6]])\n",
        "tc.matmul(a,b)  # a @ b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "375463a3",
      "metadata": {
        "id": "375463a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba8cac7d-95bb-45ad-cd34-99587845545b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0,  1,  2],\n",
            "         [ 3,  4,  5]],\n",
            "\n",
            "        [[ 2,  3,  4],\n",
            "         [ 5,  6,  7]],\n",
            "\n",
            "        [[ 4,  5,  6],\n",
            "         [ 7,  8,  9]],\n",
            "\n",
            "        [[ 6,  7,  8],\n",
            "         [ 9, 10, 11]]])\n",
            "tensor([[[ 0,  1,  2],\n",
            "         [ 3,  4,  5],\n",
            "         [ 6,  7,  8]],\n",
            "\n",
            "        [[ 2,  3,  4],\n",
            "         [ 5,  6,  7],\n",
            "         [ 8,  9, 10]],\n",
            "\n",
            "        [[ 4,  5,  6],\n",
            "         [ 7,  8,  9],\n",
            "         [10, 11, 12]],\n",
            "\n",
            "        [[ 6,  7,  8],\n",
            "         [ 9, 10, 11],\n",
            "         [12, 13, 14]]])\n",
            "tensor([[[ 15,  18,  21],\n",
            "         [ 42,  54,  66]],\n",
            "\n",
            "        [[ 51,  60,  69],\n",
            "         [ 96, 114, 132]],\n",
            "\n",
            "        [[111, 126, 141],\n",
            "         [174, 198, 222]],\n",
            "\n",
            "        [[195, 216, 237],\n",
            "         [276, 306, 336]]])\n"
          ]
        }
      ],
      "source": [
        "# A는 크기가 (4, 2, 3)인 3차원 텐서\n",
        "A1 = tc.arange(2*3).reshape(2,3)\n",
        "A = tc.stack([A1, A1+2, A1+4, A1+6])\n",
        "\n",
        "# B는 크기가 (4, 3, 3)인 3차원 텐서\n",
        "B1 = tc.arange(3*3).reshape((3,3))\n",
        "B = tc.stack([B1, B1+2, B1+4, B1+6])\n",
        "\n",
        "# matmul 연산을 제대로 이해했는지 확인하기 위해\n",
        "# 손으로도 직접 계산해보고, 결과가 동일한지 확인해보기\n",
        "print(A)\n",
        "print(B)\n",
        "print(tc.matmul(A, B))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "6479f8f0",
      "metadata": {
        "id": "6479f8f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c125be66-17c1-43e5-9527-6be5b24d66c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 2, 3])\n",
            "tensor([[[ 15,  18,  21],\n",
            "         [ 42,  54,  66]],\n",
            "\n",
            "        [[ 51,  60,  69],\n",
            "         [ 96, 114, 132]],\n",
            "\n",
            "        [[111, 126, 141],\n",
            "         [174, 198, 222]],\n",
            "\n",
            "        [[195, 216, 237],\n",
            "         [276, 306, 336]]])\n"
          ]
        }
      ],
      "source": [
        "C = tc.matmul(A,B)\n",
        "print(C.shape)\n",
        "print(C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "e4b01755",
      "metadata": {
        "id": "e4b01755",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eb9b22d-5b88-48c8-cf4f-cc9d405b00b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1.0624, 1.1686],\n",
              "         [1.4277, 1.4812],\n",
              "         [1.1384, 1.4273]],\n",
              "\n",
              "        [[1.2196, 1.1783],\n",
              "         [0.8021, 0.9288],\n",
              "         [1.0518, 1.0513]],\n",
              "\n",
              "        [[1.3943, 1.6776],\n",
              "         [1.0576, 0.9310],\n",
              "         [1.4786, 1.4879]],\n",
              "\n",
              "        [[0.2391, 0.2703],\n",
              "         [1.3300, 1.4925],\n",
              "         [0.8224, 0.7731]],\n",
              "\n",
              "        [[0.7558, 1.0782],\n",
              "         [0.4037, 0.4639],\n",
              "         [1.1947, 1.4213]]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# 브로드캐스팅 예 (y를 5개로 브로드캐스팅하여 x와 연산)\n",
        "x = tc.rand(5,3,4)\n",
        "y = tc.rand(4,2)\n",
        "tc.matmul(x,y) # x @ y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bb78257",
      "metadata": {
        "id": "7bb78257"
      },
      "source": [
        "NumPy에서는 행렬곱 연산을 하는 함수가 두 개 있다. 바로 dot연산과 matmul 연산이다.두 함수는 2차원 배열 두개의 곱에 대해 동일한 행렬곱을 결과로 도출한다. 그러나 3차원 이상에서는 서로 다르게 동작한다. 이 두 함수의 차이가 궁금하다면 직접 검색하여 공부해보자."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a3a1d7c",
      "metadata": {
        "id": "1a3a1d7c"
      },
      "source": [
        "다음으로 einsum()함수는 행렬 연산에 관한 다양한 함수들을 다 알지 못하더라도, 이 함수 하나만을 가지고 다양한 행렬 연산을 사용자가 직접 지정해줄 수 있는 함수이다. 이 함수의 원리는 아인슈타인 표기법을 따르는데, 아인슈타인 표기법에 대해 스스로 검색하여 공부해보면 Numpy와 PyTorch에서 einsum()함수를 사용하는 예시들을 쉽게 이해할 수 있을 것이다.\n",
        "\n",
        "아래의 예시들을 직접 실행해보며 einsum()함수의 유용함을 느껴보자, einsum()함수에 대해 완벽히 이해하지 못했더라도 괜찮다. 다만 앞으로 einsum()함수의 새로운 사용 예시를 보게 되더라도 낯설고 어렵게 느끼지 말고, 익숙하게 느끼길 바란다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "beabda70",
      "metadata": {
        "id": "beabda70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fbb9c6e-53c8-4fb5-c189-ce05329a0497"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0,  1,  2,  3,  4],\n",
              "         [ 5,  6,  7,  8,  9],\n",
              "         [10, 11, 12, 13, 14],\n",
              "         [15, 16, 17, 18, 19],\n",
              "         [20, 21, 22, 23, 24]]),\n",
              " tensor([[ 0,  1,  2],\n",
              "         [ 3,  4,  5],\n",
              "         [ 6,  7,  8],\n",
              "         [ 9, 10, 11],\n",
              "         [12, 13, 14]]),\n",
              " tensor([[  0,  -1,  -2],\n",
              "         [ -3,  -4,  -5],\n",
              "         [ -6,  -7,  -8],\n",
              "         [ -9, -10, -11],\n",
              "         [-12, -13, -14]]))"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "a = tc.arange(25).reshape(5,5)\n",
        "b = tc.arange(15).reshape(5,3)\n",
        "c = -tc.arange(15).reshape(5,3)\n",
        "a, b, c"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "i는 행, j는 열을 뜻함\n"
      ],
      "metadata": {
        "id": "SO5CvLLnsh_n"
      },
      "id": "SO5CvLLnsh_n"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "c6166eb9",
      "metadata": {
        "id": "c6166eb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "892548b5-32df-4587-99c1-51198f11854e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(60)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# a의 대각합\n",
        "#문자열로 곱하고 싶은 부분을 나타낸다\n",
        "tc.einsum('ii',a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "7e81572d",
      "metadata": {
        "id": "7e81572d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56cc0b0b-934c-43e4-8713-bf77576faace"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  6, 12, 18, 24])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# a의 대각원소\n",
        "tc.einsum('ii->i', a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "bc252f98",
      "metadata": {
        "id": "bc252f98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8871bd70-f22a-4349-8e8e-071bf29631fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  3,  6,  9, 12],\n",
              "        [ 1,  4,  7, 10, 13],\n",
              "        [ 2,  5,  8, 11, 14]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "# b의 전치행렬\n",
        "tc.einsum('ji',b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "6d586edc",
      "metadata": {
        "id": "6d586edc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c10d5690-bb44-4aea-c782-242a17630169"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 90, 100, 110],\n",
              "         [240, 275, 310],\n",
              "         [390, 450, 510],\n",
              "         [540, 625, 710],\n",
              "         [690, 800, 910]]),\n",
              " tensor([[ 90, 100, 110],\n",
              "         [240, 275, 310],\n",
              "         [390, 450, 510],\n",
              "         [540, 625, 710],\n",
              "         [690, 800, 910]]))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# a와 b의 행렬곱 계산 (matmul과 결과가 동일함을 확인해보기)\n",
        "tc.einsum('ij,jk->ik', a,b), tc.matmul(a,b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "976de1a0",
      "metadata": {
        "id": "976de1a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f04ac880-6696-4f66-cf76-6fe9e13e3a3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  -5,  -50, -149, -302, -509])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "# 같은 모양의 텐서 b,c의 각 행끼리의 점곱을 계산\n",
        "tc.einsum('ij,ij->i',b,c)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50bdd8c5",
      "metadata": {
        "id": "50bdd8c5"
      },
      "source": [
        "#### 자동미분과 딥러닝을 위한 특수 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6676ae0f",
      "metadata": {
        "id": "6676ae0f"
      },
      "source": [
        "PyTorch는 NumPy와 유사한 함수들 외에도 PyTorch만의 딥러닝을 위한 특수 함수들을 제공합니다. torch.nn 모듈에서는 딥러닝을 진행할 신경망을 구현하는 데 필요한 손실 함수(loss function), 활성 함수(activation function), 초기화 함수(initializer)의 대표적인 예시들을 제공합니다. 이러한 함수들에 대해서는 이번 실습에서는 다루지 않을 것이지만, 바로 다음 실습부터 꾸준히 여러 함수들이 등장할 예정입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1a37a44",
      "metadata": {
        "id": "e1a37a44"
      },
      "source": [
        "### Step 2 자동미분 실행하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d850545d",
      "metadata": {
        "id": "d850545d"
      },
      "source": [
        "이제 PyTorch 라이브러리의 핵심 기능인 자동미분에 대해 알아보자. PyTorch를 비롯한 대부분의 자동미분 라이브러리는 함수의 도함수(편도함수)를 직접 구하지 않는다. 그 대신 주어진 점(입력값)에서의 미분계수(편미분계수) 값을 구한다. 즉, 자동미분 라이브러리는 지정해준 점에서의 함수의 순간 기울기를 구하는 기능만을 갖고 있으며, 우리는 이를 이용하여 미분가능한 모든 함수의 모든 지점에서의 기울기를 구할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56abc047",
      "metadata": {
        "id": "56abc047"
      },
      "source": [
        "#### 텐서 객체의 '.backward()' 메서드"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e4dd1f7",
      "metadata": {
        "id": "0e4dd1f7"
      },
      "source": [
        "PyTorch에서 자동미분을 호출하기 위해 필요한 유일한 방법은 Tensor.backward()이다. 다른 텐서로부터 계산한 텐서 F에 대해 F.backward()를 호출하면, PyTorch는 F가 의존하는 모든 텐서에 대해 F의 편미분계수를 계산하도록 지시한다. 이 편미분계수들은 각각의 텐서들의 .grad 속성에 Tensor로 저장된다. 이때 몇 가지 주의사항이 있다.\n",
        "\n",
        "1. requires_grad=True:\n",
        "자동 미분을 추적하려면 텐서를 생성할 때 requires_grad=True로 설정해야 한다.\n",
        "\n",
        "2. backward() 호출:\n",
        "Tensor.backward()를 호출하면 해당 텐서로부터 계산된 모든 텐서에 대해 그래디언트(기울기)를 계산합니다. backward()는 스칼라 값에 대해서만 호출할 수 있습니다. 만약 텐서가 스칼라가 아니라면, 적절한 축소 연산을 통해 스칼라로 변환한 후 backward()를 호출해야 한다 (예: sum())."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee0edf3a",
      "metadata": {
        "id": "ee0edf3a"
      },
      "source": [
        "예를 들어 아래와 같이 x, y, z 텐서가 있고, x와 y의 함수로 정의된 f 텐서가 있는 상황에서의 편미분을 살펴보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "8909fc52",
      "metadata": {
        "id": "8909fc52"
      },
      "outputs": [],
      "source": [
        "x = tc.tensor(2.0, requires_grad = True)   #requires_grad : 추적 가능\n",
        "y = tc.tensor(3.0, requires_grad = True)\n",
        "z = tc.tensor(4.0, requires_grad = True)\n",
        "f = x*y  # tc.multiply(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9b04f19",
      "metadata": {
        "id": "d9b04f19"
      },
      "source": [
        "이 때, f.backward()를 호출하면 PyTorch가 f의 모든 편미분계수를 계산하도록 지시한다. 이는 역전파(backpropagation)라고 하는 컴퓨터가 빠르게 편미분계수를 계산할 수 있는 알고리즘을 사용하여 수행된다. 역전파 알고리즘은 딥러닝의 발전에서 빠질 수 없는 핵심적인 알고리즘이라 할 수 있는 것으로, 연쇄법칙(chain rule)에 기반한 알고리즘이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "eff5c10e",
      "metadata": {
        "id": "eff5c10e"
      },
      "outputs": [],
      "source": [
        "f.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a891efdb",
      "metadata": {
        "id": "a891efdb"
      },
      "source": [
        "x와 y의 .grad() 속성을 살펴보면 $\\frac{d F}{d x}$와 $\\frac{d F}{dy}$의 값을 얻을 수 있다. .grad()는 텐서로 구해진다. z는 f가 의존하는 변수 텐서가 아니므로 .grad() 속성에 값이 없다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "692b2f01",
      "metadata": {
        "id": "692b2f01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86a2093f-c719-49bb-bfd0-447c07ab4c00"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "x.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "208b6de2",
      "metadata": {
        "id": "208b6de2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "246ef926-7202-4302-cc68-fb526be98fa3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "y.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "7d5d2ed2",
      "metadata": {
        "id": "7d5d2ed2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a1395ab-ffb6-46b7-dd59-03d2ef04cc3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "#z는 backward를 하지 않았기에 없다\n",
        "z.grad is None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab7cd692",
      "metadata": {
        "id": "ab7cd692"
      },
      "source": [
        "이번에는 x, y, 그리고 x와 y로부터 구해지는 f까지 세 텐서에 의존하는 텐서 F의 모든 편미분계수를 계산해보자. 즉, F(f(x, y), x, y)인 경우를 살펴볼 것이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "2cebffb7",
      "metadata": {
        "id": "2cebffb7"
      },
      "outputs": [],
      "source": [
        "x = tc.tensor(2.0, requires_grad=True)\n",
        "y = tc.tensor(3.0, requires_grad=True)\n",
        "f = x*y\n",
        "f.retain_grad()\n",
        "F = f + x - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "1a90c30f",
      "metadata": {
        "id": "1a90c30f"
      },
      "outputs": [],
      "source": [
        "F.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cb35f93",
      "metadata": {
        "id": "5cb35f93"
      },
      "source": [
        "f의 .grad() 속성을 살펴보면 $\\frac{\\partial F}{\\partial f}$의 값을 얻을 수 있다.\n",
        "y의 .grad() 속성을 살펴보면 $\\frac{\\partial F}{\\partial y} = \\frac{\\partial F}{\\partial f}\\frac{\\partial f}{\\partial y}$의 값을 얻을 수 있다.\n",
        "\n",
        "마지막으로 x의 경우, t = x에 대해 F = f + t - 2로 쓸 수 있다. 이렇게 생각하고 x의 .grad() 속성을 살펴보면 $\\frac{\\partial F}{\\partial x} = \\frac{\\partial F}{\\partial f}\\frac{\\partial f}{\\partial x} + \\frac{\\partial F}{\\partial t}\\frac{\\partial t}{\\partial x}$의 값을 얻을 수 있다.\n",
        "\n",
        "주의사항으로 PyTorch에서 특정 텐서의 그래디언트를 계산하기 위해서는 그 텐서에 대해 직접적으로 requires_grad=True를 설정하고, 필요하다면 중간 텐서에 대해서도 retain_grad() 메소드를 호출해야 한다. retain_grad()는 중간 텐서의 그래디언트를 저장하도록 한다. f.retain_grad() 코드가 없다면 어떻게 실행되는지 확인해보는 것도 좋을 것이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "17a4384e",
      "metadata": {
        "id": "17a4384e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6892757-253d-482e-f1f2-d164bd85f986"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "f.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "c3da1420",
      "metadata": {
        "id": "c3da1420",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b0c13c3-899f-4ac5-dfe3-aaee8ae4475c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "y.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "f0f394a3",
      "metadata": {
        "id": "f0f394a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a28941b4-5804-40c5-897c-c4ec72b1d636"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06825fb4",
      "metadata": {
        "id": "06825fb4"
      },
      "source": [
        "f와 F가 의존하는 모든 변수들이 PyTorch의 텐서로 저장되어 있었고, f와 F를 이루는 모든 수학적 연산이 PyTorch에서 제공하는 함수였기 때문에 PyTorch를 통해 F의 모든 편미분계수를 구할 수 있었다. 이렇게 구한 편미분계수들로부터 함수의 그래디언트를 이용하는 경사하강법을 쉽게 수행할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05aac9d3",
      "metadata": {
        "id": "05aac9d3"
      },
      "source": [
        "# 문제: 텐서 객체의 backward() 메서드 사용\n",
        "\n",
        "여러가지 수식으로 정의된 x에 대한 함수 F에 대해, x=2.5에서 $\\frac{d F}{d x}\\big|_{x=2.5}$를 구해보자."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1번 문제"
      ],
      "metadata": {
        "id": "MAGBsn7xGd1k"
      },
      "id": "MAGBsn7xGd1k"
    },
    {
      "cell_type": "markdown",
      "id": "f35f6a9d",
      "metadata": {
        "id": "f35f6a9d"
      },
      "source": [
        "1. $F(x)=x^2$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "1ad9f204",
      "metadata": {
        "id": "1ad9f204",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eb126dc-244a-4dca-dacd-1d137ac1c703"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = x**2\n",
        "F.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1번 문제 정답"
      ],
      "metadata": {
        "id": "xfCuA6MxGEHh"
      },
      "id": "xfCuA6MxGEHh"
    },
    {
      "cell_type": "code",
      "source": [
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = x**2\n",
        "F.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "id": "hA-iU8diGMxo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5046e89-64d2-4230-abc6-6eb421dfeab8"
      },
      "id": "hA-iU8diGMxo",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1번 문제 출력 결과 : tensor(5.)"
      ],
      "metadata": {
        "id": "YIOuj1FMGPMw"
      },
      "id": "YIOuj1FMGPMw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2번 문제"
      ],
      "metadata": {
        "id": "ekFW_3OnGSdU"
      },
      "id": "ekFW_3OnGSdU"
    },
    {
      "cell_type": "markdown",
      "id": "7a5cd97f",
      "metadata": {
        "id": "7a5cd97f"
      },
      "source": [
        "2. $F(x)=\\cos{\\sqrt{x}}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "f62fd0dd",
      "metadata": {
        "id": "f62fd0dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8ca8c2d-e3e0-426c-a902-f8859f409153"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.3162)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = tc.cos(tc.sqrt(x))\n",
        "F.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2번 문제 정답"
      ],
      "metadata": {
        "id": "G1rUUHZFGi-3"
      },
      "id": "G1rUUHZFGi-3"
    },
    {
      "cell_type": "code",
      "source": [
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = tc.cos(tc.sqrt(x))\n",
        "F.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "id": "4V1iRDD3GijE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "263160dc-15ab-43cf-832c-be330e03a89d"
      },
      "id": "4V1iRDD3GijE",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.3162)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2번 문제 출력 결과 : tensor(-0.3162)"
      ],
      "metadata": {
        "id": "dIrwUZzyGibE"
      },
      "id": "dIrwUZzyGibE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3번 문제"
      ],
      "metadata": {
        "id": "aBe8aYzXGr3G"
      },
      "id": "aBe8aYzXGr3G"
    },
    {
      "cell_type": "markdown",
      "id": "f994e9f9",
      "metadata": {
        "id": "f994e9f9"
      },
      "source": [
        "3. $F(x)=2+3x-5x^2$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "9aba45f7",
      "metadata": {
        "id": "9aba45f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08562982-f021-4605-8fe8-5efd72a2fc16"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-22.)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = 2 + 3*x - 5*(x**2)\n",
        "F.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3번 문제 정답"
      ],
      "metadata": {
        "id": "b-l8ieGVGv3M"
      },
      "id": "b-l8ieGVGv3M"
    },
    {
      "cell_type": "code",
      "source": [
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = 2+3*x-5*x**2\n",
        "F.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "id": "mEgwk9LhGuT6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eacc9fe-b446-48c5-ac03-311049b63cdb"
      },
      "id": "mEgwk9LhGuT6",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-22.)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3번 문제 출력 결과 : tensor(-22.)"
      ],
      "metadata": {
        "id": "gOabd2fPGul7"
      },
      "id": "gOabd2fPGul7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4번 문제"
      ],
      "metadata": {
        "id": "0oTiFRY5G2tE"
      },
      "id": "0oTiFRY5G2tE"
    },
    {
      "cell_type": "markdown",
      "id": "aa6ca763",
      "metadata": {
        "id": "aa6ca763"
      },
      "source": [
        "4. $F(x)=e^{lnx}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "d028375e",
      "metadata": {
        "id": "d028375e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ebfebcd-4d2a-41be-a0fd-082085fcec45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = tc.exp(tc.log(x))\n",
        "F.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4번 문제 정답"
      ],
      "metadata": {
        "id": "rbGPZ_ydG53A"
      },
      "id": "rbGPZ_ydG53A"
    },
    {
      "cell_type": "code",
      "source": [
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = tc.exp(tc.log(x))\n",
        "F.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "id": "dLQKI_84G5Sa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e8adf35-7e75-4569-d65a-d4eee270758a"
      },
      "id": "dLQKI_84G5Sa",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4번 문제 출력 결과 : tensor(1.)"
      ],
      "metadata": {
        "id": "G49bEx7jG5e4"
      },
      "id": "G49bEx7jG5e4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5번 문제"
      ],
      "metadata": {
        "id": "9UFMZxcHHEX5"
      },
      "id": "9UFMZxcHHEX5"
    },
    {
      "cell_type": "markdown",
      "id": "979502fa",
      "metadata": {
        "id": "979502fa"
      },
      "source": [
        "5. $F(x)=(2xf(x))^2-f(x), f(x)=x^2$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "e333cb51",
      "metadata": {
        "id": "e333cb51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e98a97b-9c61-434d-d0ca-b3fca0bdcdff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2338.7500)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "f = x**2\n",
        "F = (2*x*f)**2 - f\n",
        "F.backward()\n",
        "x.grad\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5번 문제 정답"
      ],
      "metadata": {
        "id": "U0_bPo_AHGKV"
      },
      "id": "U0_bPo_AHGKV"
    },
    {
      "cell_type": "code",
      "source": [
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "f = x**2\n",
        "F = (2*x*f)**2-f\n",
        "F.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "id": "PmQlhnDvHGbA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38e91ec6-fbf3-4308-d606-456b1f8c8454"
      },
      "id": "PmQlhnDvHGbA",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2338.7500)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5번 문제 출력 결과 : tensor(2338.7500)"
      ],
      "metadata": {
        "id": "mfseKPKcHGwV"
      },
      "id": "mfseKPKcHGwV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -"
      ],
      "metadata": {
        "id": "1wT96P_lHMrw"
      },
      "id": "1wT96P_lHMrw"
    },
    {
      "cell_type": "markdown",
      "id": "72ea07a0",
      "metadata": {
        "id": "72ea07a0"
      },
      "source": [
        "#### .grad 속성의 초기화"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e8e4d75",
      "metadata": {
        "id": "0e8e4d75"
      },
      "source": [
        "경사하강법을 수행할 때, 텐서와 관련된 편미분계수를 반복적으로 구해야 한다. 따라서, 경사하강을 반복할 때마다 사이사이에 편미분계수를 폐기해야 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fce6da3",
      "metadata": {
        "id": "6fce6da3"
      },
      "source": [
        "backward()연산을 진행한 함수가 의존하는 텐서들 중 하나의 .grad 속성을 초기화하는 방법은 다음과 같이 두가지가 있다. 아래와 같은 상황을 생각해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "45b77985",
      "metadata": {
        "id": "45b77985",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "898d7c88-70a5-4653-d9d4-5a3970cc80c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "x = tc.tensor(2.0, requires_grad=True)\n",
        "f = x**2\n",
        "f.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b0e92ca",
      "metadata": {
        "id": "9b0e92ca"
      },
      "source": [
        "그래디언트를 초기화하지 않으면, 추가 연산 후 backward()를 호출해도 이전 값에 누적되지 않고 덮어쓴다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "c7a13d5b",
      "metadata": {
        "id": "c7a13d5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f39c066d-58d1-4c50-986c-68cb87ad0bd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8.)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "#위와 같은 함수여도 위의 결과에 중첩되어서 다른 결과가 나온다.\n",
        "g = x**2\n",
        "g.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6477d424",
      "metadata": {
        "id": "6477d424"
      },
      "source": [
        "Tensor.grad를 호출하여 해당 텐서의 .grad 속성을 직접적으로 None으로 재설정할 수도 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "71cbc888",
      "metadata": {
        "id": "71cbc888"
      },
      "outputs": [],
      "source": [
        "#None을 이용하여 초기화 시킬 수 있다\n",
        "x.grad = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "0d3fb5eb",
      "metadata": {
        "id": "0d3fb5eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "006ae3ab-3869-4ab6-9968-c566263322dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "x.grad is None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6de8423c",
      "metadata": {
        "id": "6de8423c"
      },
      "source": [
        "#### PyTorch와 Numpy의 관계"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4133bbb6",
      "metadata": {
        "id": "4133bbb6"
      },
      "source": [
        "우리는 앞의 내용에서 PyTorch에서 NumPy의 다양한 수학함수들을 동일하게 정의해두었다는 것을 충분히 확인했다.\n",
        "\n",
        "PyTorch의 텐서 객체는 NumPy 배열과 비교했을 때 별로 새롭지 않다. 텐서 객체는 Numpy 배열에 대한 정보를 기본으로 가지고 있으며, 단지 배열이 관련된 수학적 연산들을 추적하는 추가 역할을 할 뿐이다. 수학적 연산에 대한 추적은 자동미분을 위해 추가된 역할이라고 볼 수 있다.\n",
        "\n",
        "이러한 관계성에 의해 우리는 텐서를 한꺼풀 벗겨내어 NumPy 배열을 얻을 수 있다. 다음의 텐서 x에 대해 NumPy 배열로 만드는 세 가지 방법을 확인해보자."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7I3HEHz_gIFV",
      "metadata": {
        "id": "7I3HEHz_gIFV"
      },
      "source": [
        "먼저, 기본 텐서의 경우 numpy()를 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "55472dc7",
      "metadata": {
        "id": "55472dc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eb4a7ab-fb03-4aae-b39d-e1218ce9d8e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "x = tc.tensor([0.0,1.0,2.0,3.0])\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "1ef96a8b",
      "metadata": {
        "id": "1ef96a8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbb2c423-b5c2-4b63-eb94-9fa2294ed751"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 2., 3.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "x.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e22945e",
      "metadata": {
        "id": "9e22945e"
      },
      "source": [
        "두번째로, grad 정보가 포함된 경우 detach().numpy()를 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "ac022abd",
      "metadata": {
        "id": "ac022abd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ecc468e-9d28-45c6-a99c-da36becdeb5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "x = tc.tensor([0.0,1.0,2.0,3.0], requires_grad=True)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "38a70485",
      "metadata": {
        "id": "38a70485",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "784cb812-da45-4047-949d-e121e6f1bb61"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 2., 3.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "x.detach().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CqdEZEnAg9p9",
      "metadata": {
        "id": "CqdEZEnAg9p9"
      },
      "source": [
        "세번째로, gpu에 선언된 텐서의 경우 cpu().numpy()를 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "uwST0Z-7g596",
      "metadata": {
        "id": "uwST0Z-7g596",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "9e2776e6-0bfa-4eb8-f9c2-1bfcff97ed19"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-8f1e5a2ff851>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#cuad : GPU 환경을 의미함\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#numpy : CPU 환경에서 쓰임\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#GPU 환경에서 돌리면 오류가 발생하지 않음\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ],
      "source": [
        "#cuad : GPU 환경을 의미함\n",
        "#numpy : CPU 환경에서 쓰임\n",
        "x = tc.tensor([0.0,1.0,2.0,3.0], requires_grad=True).cuda()   #GPU 환경에서 돌리면 오류가 발생하지 않음\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "2wax3zVOhMkf",
      "metadata": {
        "id": "2wax3zVOhMkf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26ce3807-c47a-4e9d-ddc1-451407b52eca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 2., 3.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "x.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61fa582a",
      "metadata": {
        "id": "61fa582a"
      },
      "source": [
        "#### 편미분계수 계산 시 상수 텐서와 변수 텐서"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "364ca3a4",
      "metadata": {
        "id": "364ca3a4"
      },
      "source": [
        "앞서 살펴본 머신러닝 모델에 대해 경사하강법을 진행하는 경우를 생각해보자.\n",
        "\n",
        "머신러닝 모델을 다음과 같이 정의할 때\n",
        "\\begin{equation}\n",
        "\\mathscr{L}\\big(w_1, ..., w_M ; (x_n, y_n)_{n=0}^{N-1}\\big)\n",
        "\\end{equation}\n",
        "\n",
        "경사하강법을 수행하기 위해 우리는 $\\frac{d\\mathscr{L}}{dw_i}$를 각각의 $w_i$에 대해 계산해야 한다. 그러나, $\\frac{d\\mathscr{L}}{dx_i}$는 필요하지 않다. 특히, 입력 데이터셋이 크고 복잡해질수록, 필요없는 수많은 편미분계수를 일일이 계산하는 것은 쓸데없이 많은 비용이 드는 일이다.\n",
        "\n",
        "위에서 배운대로라면, PyTorch 텐서의 .backward() 메서드는 $\\mathscr{L}$를 이루는 모든 변수 텐서들에 대해 편미분계수를 계산한다. 따라서, 우리는 편미분계수 계산이 필요없는 데이터들을 변수 텐서가 아니라 상수 텐서로 표현함으로써 자동으로 .backward() 계산에서 배제되도록 할 것이다. 상수 텐서로 취급할 수 있는 방법을 알아보자."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "667de722",
      "metadata": {
        "id": "667de722"
      },
      "source": [
        "PyTorch의 텐서 객체를 생성할 때 requires_grad=False를 사용하여 상수 텐서를 생성할 수 있다. requires_grad=False로 설정된 텐서는 그래디언트 계산에 포함되지 않는다. 기본값이 requires_grad=False이므로, 특별히 지정하지 않아도 된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "28053219",
      "metadata": {
        "id": "28053219"
      },
      "outputs": [],
      "source": [
        "x = tc.tensor(1.)\n",
        "y = tc.tensor(2., requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "29c2bac7",
      "metadata": {
        "id": "29c2bac7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2390fc9f-3ee7-4740-89d3-6a6d8c34e9db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2., grad_fn=<MulBackward0>)\n",
            "tensor(2., grad_fn=<MulBackward0>)\n"
          ]
        }
      ],
      "source": [
        "F = x * y\n",
        "print(F)\n",
        "F.backward()\n",
        "print(F)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "0ba47cc3",
      "metadata": {
        "id": "0ba47cc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a49834e-106d-4d4c-a195-70cb881cd406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-83-1d2db2814d4a>:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  F.grad\n"
          ]
        }
      ],
      "source": [
        "F.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "6fb9cb00",
      "metadata": {
        "id": "6fb9cb00"
      },
      "outputs": [],
      "source": [
        "x.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "9355969c",
      "metadata": {
        "id": "9355969c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fce0a88e-31de-4440-e040-5c02448ea1fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "y.grad is None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47018679",
      "metadata": {
        "id": "47018679"
      },
      "source": [
        "추가적으로, 상수 텐서만으로 정의된 텐서의 경우에는 어떤 연산을 적용하더라도 상수 텐서가 생성된다. 따라서, 이렇게 얻은 상수 텐서에 대해서는 .backward() 메서드는 에러를 발생시킨다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "9be9f9c8",
      "metadata": {
        "id": "9be9f9c8"
      },
      "outputs": [],
      "source": [
        "x = tc.tensor(1.)\n",
        "y = tc.tensor(2.)\n",
        "F = x + y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "ae6005a5",
      "metadata": {
        "id": "ae6005a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "21e5aa1c-0d09-4c66-efdf-d48710ceda9a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-99ea150b60f8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ],
      "source": [
        "F.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "d2b85dc5",
      "metadata": {
        "id": "d2b85dc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a301652-4f86-4e3a-e732-9938cc8b4d0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "F.grad is None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b10bbdab",
      "metadata": {
        "id": "b10bbdab"
      },
      "source": [
        "### Step 3. 다차원 텐서의 자동미분 실행하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5989cb5b",
      "metadata": {
        "id": "5989cb5b"
      },
      "source": [
        "#### 다차원 텐서에 대해 정의된 함수에서의 자동미분"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95ac6652",
      "metadata": {
        "id": "95ac6652"
      },
      "source": [
        "지금까지는 하나의 스칼라 변수로 이루어진 0차원 텐서에 대해 정의된, 간단한 함수에 대해서만 자동미분을 실행해보았다. 그런데 텐서 객체는 다차원의 배열을 나타낼 수 있다. 따라서 다차원 텐서에 대해 정의된 함수에서 자동미분이 실행되는 방법을 알면 계산을 편리하게 할 수 있다.\n",
        "\n",
        "다차원 텐서와 관련된 .grad 속성을 어떻게 해석해야 할까? 한마디로 표현하면, 텐서의 각 원소를 스칼라 값 변수로 해석하면 된다. 즉, 다차원 텐서를 스칼라 변수들의 집합으로 보면 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88c0e308",
      "metadata": {
        "id": "88c0e308"
      },
      "source": [
        "이렇게만 말해서는 이해가 잘 가지 않을 것이다. 다음과 같은 계산을 통해 자세히 알아보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c211a0be",
      "metadata": {
        "id": "c211a0be"
      },
      "outputs": [],
      "source": [
        "tensor = tc.tensor([2.0, 4.0, 8.0], requires_grad=True)\n",
        "arr = tc.tensor([-1.0, 2.0, 0], requires_grad=True)\n",
        "F = (arr * tensor ** 2).sum()\n",
        "F.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9a0d070",
      "metadata": {
        "id": "b9a0d070"
      },
      "source": [
        "위의 코드에서 정의된 함수 F를 풀어서 쓰면 $F = -1\\:(x_0)^2 + 2\\:(x_1)^2 + 0\\:(x_2)^2$이다. 그리고 다차원 텐서의 각 원소를 스칼라 값 변수로 해석한다는 것은, $\\mathrm{tensor} = [x_0, x_1, x_2]$로 보겠다는 뜻이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afbb87af",
      "metadata": {
        "id": "afbb87af"
      },
      "source": [
        "이때, tensor.grad에는 어떤 값이 저장되어야 타당할까? tensor의 각 스칼라 변수들로 편미분한 값들을 tensor와 같은 shape의 배열로 저장하면 좋을 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fc1254d",
      "metadata": {
        "id": "1fc1254d"
      },
      "source": [
        "\\begin{align}\n",
        "{\\nabla}F &= \\big[\\frac{\\partial F}{\\partial x_0},\\frac{\\partial F}{\\partial x_1},\\frac{\\partial F}{\\partial x_2}\\big]\\\\\n",
        "&= \\big[-2x_0,\\:4x_1,\\:0x_2\\big]\\\\\n",
        "{\\nabla}F\\big|_{x_0=2, x_1=4, x_2=8} &= \\big[-4,\\:16,\\:0\\big]\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd9e4e53",
      "metadata": {
        "id": "cd9e4e53"
      },
      "source": [
        "실제로 tensor.grad 는 tensor에 저장된 특정 값에서의 ${\\nabla}F$ 를 저장한다. 다음 코드를 실행하여 확인해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff494ccb",
      "metadata": {
        "id": "ff494ccb"
      },
      "outputs": [],
      "source": [
        "tensor.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6637697f",
      "metadata": {
        "id": "6637697f"
      },
      "source": [
        "일반화하여 표현하면 다음과 같다. tensor의 각 원소는 스칼라 값 변수로 해석할 수 있고, tensor.grad에서 대응되는 위치의 요소는 해당 변수에 대한 미분계수이다.\n",
        "\n",
        "$\\text{tensor}[x_0, \\dots, x_{(N-1)}] \\rightarrow \\text{tensor.grad}[x_0, \\dots, x_{(N-1)}] = {\\nabla}F = \\big[\\frac{\\partial F}{\\partial x_0},\\dots,\\frac{\\partial F}{\\partial x_{(N-1)}}\\big]$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b333799",
      "metadata": {
        "id": "9b333799"
      },
      "source": [
        "#### 벡터화된 자동미분"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4eca391",
      "metadata": {
        "id": "c4eca391"
      },
      "source": [
        "방금 다차원 텐서에 의해 정의된 스칼라 함수에 대한 자동미분에 대해 배웠다. 이번에는 스칼라 함수가 아닌, 벡터 함수에 대해 자동미분을 실행할 때는 어떻게 실행되는지 알아보자.\n",
        "\n",
        ".backward() 메서드를 호출한 최종 함수가 스칼라가 아니라 벡터 함수라면, PyTorch는 최종 함수를 스칼라로 다 합친 후에 역전파를 진행해야한다.\n",
        "\n",
        "이렇게 합친 $\\sum F$는 스칼라이기 때문에 $\\frac{\\partial (\\sum F)}{\\partial x_{i}}$ 또한 스칼라이다. 따라서 위에서 살펴본 바와 같이 tensor와 tensor.grad는 항상 같은 shape을 갖는다.\n",
        "\n",
        "이렇게만 말해서는 이해가 가지 않으니, 다음과 같은 계산을 통해 알아보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43a7cb94",
      "metadata": {
        "id": "43a7cb94"
      },
      "outputs": [],
      "source": [
        "tensor = tc.linspace(-5, 5, 20, requires_grad=True)\n",
        "F = tensor ** 2  # shape-(20)인 텐서\n",
        "F_sum = F.sum()\n",
        "F_sum.backward()\n",
        "#F.backward()\n",
        "tensor.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d4fce29",
      "metadata": {
        "id": "6d4fce29"
      },
      "source": [
        "위의 코드에서 정의된 함수 F는 $F= \\big[x_0 ^2,\\ \\dots, \\; x^2_{99} \\big]$이다. 그리고 PyTorch에서 F_sum.backward()를 실행할 때 이를 스칼라로 다 합친다는 것은, $\\sum {F} = x_0 ^2 + \\dots + x^2_{99}$로 합친 후 이에 대해 .backward()를 실행하겠다는 뜻이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f3bc6ee",
      "metadata": {
        "id": "2f3bc6ee"
      },
      "source": [
        "그런데 여기서 의문이 생긴다. 다변수 벡터함수 $F$의 편미분 계수들을 구하기 위해서는 야코비 행렬을 구하는 게 합당해 보인다. 그런데 $\\sum F$에 대해 .backward()를 실행시키는 것은 매우 다른 결과를 불러온다.\n",
        "\n",
        "각 성분함수에 대한 편미분 계수들을 일일이 구하지 못하고, 대신 성분함수들의 합에 대한 편미분 계수 $\\frac{\\partial (F_0+F_1+ \\cdots + F_{N-1})}{\\partial x_i}$ 만을 구하게 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85f872b3",
      "metadata": {
        "id": "85f872b3"
      },
      "source": [
        "왜 PyTorch에서는 자동미분 기능을 이렇게 구현한 것일까? 만약 다변수 벡터함수 의 각 성분함수들이 각각 독립인 입력 변수에 대해 정의되었다면, 즉 독립인 $x_0, x_1,\\cdots, x_{(N-1)}$ 에 대해 $F=[F_0(x_0), F_1(x_1), \\cdots, F_{N-1}(x_{(N-1)})]$ 로 정의되었다면 $\\sum F$에 대해 .backward()를 실행시키는 것은 의미있는 행위가 된다. 유효한 모든 편미분 계수를 $\\big[\\frac{\\partial F_{0}}{\\partial x_0},\\dots,\\frac{\\partial F_{N-1}}{\\partial x_{(N-1)}}\\big]$ 와 같이 구할 수 있게 되기 때문이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67aadde5",
      "metadata": {
        "id": "67aadde5"
      },
      "source": [
        "다시 위의 예시로 돌아가보자.  $F= \\big[x_0 ^2,\\ \\dots, \\; x^2_{99} \\big]$에 대해 .backward()를 실행시킨 것은  $\\sum{F} = x_0 ^2 + \\dots + x^2_{99}$에 대해 .backward()를 실행시킨 것과 같다. 그리고 이후에 입력 tensor $\\rm\\textbf{x} = \\big[ x_0, x_1,\\cdots, x_{(N-1)}\\big]$ 에 대한 tensor.grad를 구하면 입력 tensor $\\rm\\textbf{x}$와 shape이 동일한 ${\\nabla}(\\Sigma{{F}}) = \\big[2x_0,\\ \\dots, \\; 2x_{99} \\big]$ 가 구해진다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94d7fc45",
      "metadata": {
        "id": "94d7fc45"
      },
      "source": [
        "이 계산은 결국, 100개의 독립적인 값들에 대해 함수 $f(x) = x ^ 2$ 의 편미분계수 값 ($\\frac{\\mathrm{d}f}{\\mathrm{d}x} = 2x$)을 한번에 계산한 것과 같았다. 따라서, PyTorch를 이용하여 독립적인 값들에 대한 성분함수로 이루어진 다변수 벡터 함수의 미분을 구하는 기능은, 여러 개의 독립적인 데이터를 하나의 텐서로 묶어서 동일한 계산을 한 번에 수행할 때 큰 이점이 있다. 신경망에 대해 배우고 본격적인 딥러닝에 대해 실습할 때 도움이 될 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b44d37d0",
      "metadata": {
        "id": "b44d37d0"
      },
      "source": [
        "### 문제: 도함수의 그래프 그리기\n",
        "\n",
        ".backward() 메서드를 이용하면 특정 점에서의 그래디언트만 구할 수 있고, 도함수의 식과 그래프는 알 수 없다. 그런데, 벡터화된 자동미분을 이용하면 여러 점에서의 편미분계수 값을 한번에 구할 수 있으므로, matplotlib을 통해 그래프를 찍을 수 있게 된다.\n",
        "\n",
        "1. 벡터화된 자동미분을 수행하는 다음의 함수를 완성해보자. matplotlib에 관한 실습1의 내용을 잘 떠올리면서 작성해보자. (주의: matplotlib에 데이터를 전달할 때는 torch의 텐서가 아닌, 널리 알려진 라이브러리인 NumPy의 배열을 사용하는 것이 좋습니다.)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " $f(x) = \\sin{(2x)}\\; \\cos{(x)}\\; e^{-x/3}$의 그래프와 그 도함수를 torch를 이용해서 그려보자."
      ],
      "metadata": {
        "id": "n-UzYgKBZkV9"
      },
      "id": "n-UzYgKBZkV9"
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "63b190cf",
      "metadata": {
        "id": "63b190cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f74f363c-b9ec-438d-c1ad-e716648f4b2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0.0000,  0.0020,  0.0040,  ..., -0.0273, -0.0273, -0.0273],\n",
              "        grad_fn=<MulBackward0>),\n",
              " tensor([2.0000, 1.9987, 1.9973,  ..., 0.0021, 0.0022, 0.0024]))"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "x = tc.linspace(0,10,10000, requires_grad = True)\n",
        "y = tc.sin(2*x) * tc.cos(x) * tc.exp(-x/3)\n",
        "y_sum = y.sum()\n",
        "y_sum.backward()\n",
        "y, x.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "a956957d",
      "metadata": {
        "id": "a956957d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def plot_func_and_deriv(x, func):\n",
        "    \"\"\"\n",
        "    함수 func(x)와 도함수 dfunc/dx를 같은 축(axis) 상에 그리는 함수\n",
        "\n",
        "    매개변수 (Parameters)\n",
        "    ----------\n",
        "    x : PyTorch.Tensor, shape-(N,)\n",
        "        함수 func(x)와 도함수 dfunc/dx를 그리는 x의 정의역\n",
        "\n",
        "    func: Callable[[Tensor], Tensor]\n",
        "        x에 대한 일변수 함수\n",
        "\n",
        "    반환 값 (Returns)\n",
        "    -------\n",
        "    Tuple[Figure, Axis]\n",
        "        matplotlib로 그래프를 그리기 위한 fig와 ax\n",
        "    \"\"\"\n",
        "    x = tc.tensor(x, requires_grad=True)\n",
        "    y = func(x)\n",
        "    y.sum().backward()\n",
        "\n",
        "    # 여기에 코드 작성\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(x.detach().numpy(), y.detach().numpy(), c=\"red\")\n",
        "    ax.plot(x.detach().numpy(), x.grad.detach().numpy(), c=\"blue\")\n",
        "    ax.grid(True)\n",
        "\n",
        "    return fig, ax"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6565d15f",
      "metadata": {
        "id": "6565d15f"
      },
      "source": [
        "2. 이제 위에서 작성한 함수를 이용하여 구간 $[0, 10]$를 균등하게 10,000개로 나눈 정의역에 대해 함수 $f(x) = \\sin{(2x)}\\; \\cos{(x)}\\; e^{-x/3}$와 그 도함수의 그래프를 그려보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "72733202",
      "metadata": {
        "id": "72733202"
      },
      "outputs": [],
      "source": [
        "def f(x):\n",
        "    # 여기에 코드 작성\n",
        "    return tc.sin(x) * tc.cos(x) * tc.exp(-x/3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "7c5f677e",
      "metadata": {
        "id": "7c5f677e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "0e2bbddf-e85e-4ef8-a4a2-50669bf3ae6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-95-a5175a552b13>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = tc.tensor(x, requires_grad=True)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x = tc.linspace(0, 10, 10000)\n",
        "fig, ax = plot_func_and_deriv(x, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0a1f72a",
      "metadata": {
        "id": "c0a1f72a"
      },
      "source": [
        "### Step 4. Torch의 자동미분을 이용한 경사하강법"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72b0de77",
      "metadata": {
        "id": "72b0de77"
      },
      "source": [
        "#### 경사하강법 코드 수정하기 (1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a2062d0",
      "metadata": {
        "id": "6a2062d0"
      },
      "source": [
        "자동미분을 이용하면 경사하강법을 쉽게 구현할 수 있다. 연습을 위해 간단한 일변수 함수에 대해 경사하강법을 수행해볼 것이다. 앞선 예제에서도 다룬적 있는 함수 $\\mathscr{L}(w) = w^2$에 대한 경사하강법을 수행하며 자동미분을 잘 활용해보자.\n",
        "\n",
        "앞선 예제에서는 $\\mathscr{L}(w) = w^2$의 도함수가 $\\frac{d \\mathscr{L}}{d w} = 2w$임을 알고 있는 상태에서 경사하강법 함수 descent_down_parabola()를 작성해보았다.\n",
        "\n",
        "```python\n",
        "def descent_down_parabola(w_start, learning_rate, num_steps):\n",
        "    w_values = [w_start]\n",
        "    for _ in range(num_steps):\n",
        "        w_old = w_values[-1]\n",
        "        w_new = w_old - learning_rate * (2 * w_old)\n",
        "        w_values.append(w_new)\n",
        "    return np.array(w_values)\n",
        "```\n",
        "\n",
        "이번에는 도함수를 모르는 $\\mathscr{L}(w)$에 대해서도 적용할 수 있는, 자동미분을 이용한 경사하강법 함수를 작성해보자. $w$의 값을 PyTorch 텐서로 저장한 후, $\\mathscr{L}(w)$를 $w$의 식으로 정의해주어, .backward() 메서드를 사용하여 편미분계수를 구할 수 있다.\n",
        "\n",
        "아래의 경사하강법 공식에 따라 자동미분을 이용한 경사하강법을 프로그래밍으로 구현해보자.\n",
        "\n",
        "\\begin{equation}\n",
        "w_{\\mathrm{new}} = w_{\\mathrm{old}} - \\delta \\frac{\\mathrm{d}\\mathscr{L}}{\\mathrm{d}w}\\big|_{w_{\\mathrm{old}}}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2da681a1",
      "metadata": {
        "id": "2da681a1"
      },
      "source": [
        "다음과 같이 $w$의 시작점과 학습률 $\\delta$, 몇 단계 반복할 것인지가 주어졌다고 하자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "941881f8",
      "metadata": {
        "id": "941881f8"
      },
      "outputs": [],
      "source": [
        "#파라미터들의 초기값 설정\n",
        "w = tc.tensor([10.0], requires_grad=True)\n",
        "learning_rate = 0.3\n",
        "num_steps = 20  #파라미터 반복 횟수"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64bfcec4",
      "metadata": {
        "id": "64bfcec4"
      },
      "source": [
        "이러한 상황에 대해 아래의 코드를 채워 경사하강법을 수행하는 코드를 작성해보자. 제대로 코드를 작성한다면, 다음과 같이 $w=0$으로 서서히 가까워지는 결과가 출력될 것이다.\n",
        "```\n",
        "Tensor(4.)\n",
        "Tensor(1.6)\n",
        "Tensor(0.64)\n",
        "Tensor(0.256)\n",
        "Tensor(0.1024)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "7fda26a0",
      "metadata": {
        "id": "7fda26a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5f52ffd-986d-49f8-ab28-447cdc679722"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.], requires_grad=True)\n",
            "tensor([1.6000], requires_grad=True)\n",
            "tensor([0.6400], requires_grad=True)\n",
            "tensor([0.2560], requires_grad=True)\n",
            "tensor([0.1024], requires_grad=True)\n",
            "tensor([0.0410], requires_grad=True)\n",
            "tensor([0.0164], requires_grad=True)\n",
            "tensor([0.0066], requires_grad=True)\n",
            "tensor([0.0026], requires_grad=True)\n",
            "tensor([0.0010], requires_grad=True)\n",
            "tensor([0.0004], requires_grad=True)\n",
            "tensor([0.0002], requires_grad=True)\n",
            "tensor([6.7109e-05], requires_grad=True)\n",
            "tensor([2.6844e-05], requires_grad=True)\n",
            "tensor([1.0737e-05], requires_grad=True)\n",
            "tensor([4.2950e-06], requires_grad=True)\n",
            "tensor([1.7180e-06], requires_grad=True)\n",
            "tensor([6.8719e-07], requires_grad=True)\n",
            "tensor([2.7488e-07], requires_grad=True)\n",
            "tensor([1.0995e-07], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "for _ in range(num_steps):\n",
        "    ℒ = w ** 2\n",
        "    ℒ.backward()\n",
        "    # 여기에 코드 작성\n",
        "\n",
        "    #  블록 안에서 w를 업데이트. 이는 PyTorch가 이 블록 내의 연산을 추적하지 않도록 한다.\n",
        "    #  메모리 관리에 유리하다\n",
        "    with tc.no_grad():\n",
        "      w -= learning_rate * w.grad\n",
        "    #w의 그래디언트를 초기화. 이를 통해 다음 단계에서 그래디언트가 누적되지 않도록 한다.\n",
        "    w.grad = None\n",
        "\n",
        "    print(w)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "604b8e15",
      "metadata": {
        "id": "604b8e15"
      },
      "source": [
        "그런데 코드를 작성할 때, 한가지 생각해볼만한 부분이 있다. 위의 코드를 완성하여 원하는 출력값도 제대로 얻었다면, 아래의 두 코드와 자신의 답변을 비교해보자. 꼭 먼저 코드를 직접 작성해본 후에 답변을 확인하길 바란다.\n",
        "\n",
        "다음의 두 코드는 모두 원하는 출력값을 얻게 해주는 코드이다.\n",
        "첫번째 코드는 다음과 같다.\n",
        "```python\n",
        "w = w - learning_rate * w.grad\n",
        "```\n",
        "두번째 코드는 다음과 같다.\n",
        "```python\n",
        "w.data -= learning_rate * w.grad\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "205b2767",
      "metadata": {
        "id": "205b2767"
      },
      "source": [
        "두 코드는 동일한 출력값을 얻게 해줄 뿐 아니라, 사실상 같은 의미라고 느껴진다. 그리고 첫번째 코드가 우리가 알고 있는 공식에 더 가까원 형태이기 때문에 좀 더 직관적이다. 그러나, 두번째 코드는 두가지 이점이 있다.\n",
        "\n",
        "첫째로 컴퓨터 계산 속도를 최적화할 수 있다. 앞서 PyTorch의 텐서는 NumPy 배열의 수학적 연산들을 추적하는 추가 기능을 갖고 있는 객체라는 것을 배웠다. 그러나 이렇게 수학 연산을 추적하는 과정이 w 값을 갱신하는 과정에서는 굳이 필요하지 않다. 따라서 첫번째 코드와 같이 텐서를 사용하면, 불필요한 수학 연산의 추적으로 인해 간접적인 연산 처리 시간인 오버헤드(overhead)만 발생한다. 그러나 두번째 코드에서는 직접 텐서의 데이터를 업데이트함으로써, 불필요한 연산 그래프 추적을 피한다.\n",
        "\n",
        "둘째로 추가적인 메모리 공간을 필요로 하지 않는다. 연산자 '-='는 증강 업데이트(augmented update)를 실행하는 연산자이다. 이는 컴퓨터가 새로운 메모리 공간을 할당하여 배열의 값을 교체하는 대신, 사용하던 메모리 공간을 그대로 다시 덮어쓰는 것을 의미한다. 따라서 기존 메모리 공간을 그대로 사용하므로, 메모리 사용이 최적화된다.\n",
        "\n",
        "조만간 신경망에 대해 배운 후, 어렵고 복잡한 수학적 함수의 파라미터를 조정하게 되면, 수많은 대규모 데이터를 업데이트하게 될 것이다. 이런 상황에서 위의 두가지 이점은 학습의 성능에 큰 차이를 만들 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "606ef82a",
      "metadata": {
        "id": "606ef82a"
      },
      "source": [
        "#### 경사하강법 코드 수정하기 (2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf2419b9",
      "metadata": {
        "id": "cf2419b9"
      },
      "source": [
        "이번에는 앞선 예제에서 다룬적 있는 이변수 함수 $\\mathscr{L}(w_1, w_2) = 2w_1^2 + 3w_2^2$에 대한 경사하강법을 수행하며 자동미분을 잘 활용해보자.\n",
        "\n",
        "앞선 예제에서는 $\\mathscr{L}(w) = w^2$의 도함수가 $\\frac{d \\mathscr{L}}{d w} = 2w$임을 알고 있는 상태에서 경사하강법 함수 descent_down_2d_parabola()를 작성해보았다.\n",
        "\n",
        "```python\n",
        "def descent_down_2d_parabola(w_start, learning_rate, num_steps):\n",
        "    xy_values = [w_start]\n",
        "    for _ in range(num_steps):\n",
        "        xy_old = xy_values[-1]\n",
        "        xy_new = xy_old - learning_rate * (np.array([4., 6.]) * xy_old)\n",
        "        xy_values.append(xy_new)\n",
        "    return np.array(xy_values)\n",
        "```\n",
        "\n",
        "이번에는 도함수를 모르는 $\\mathscr{L}(w_1, w_2)$에 대해서도 적용할 수 있는, 자동미분을 이용한 경사하강법 함수를 작성해보자. 다차원 텐서로 정의된 함수의 자동미분을 잘 떠올리면 해결하는 데 도움이 될 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0657ae3",
      "metadata": {
        "id": "f0657ae3"
      },
      "source": [
        "다음과 같이 $\\rm\\textbf w$의 시작점과 학습률 $\\delta$, 몇 단계 반복할 것인지가 주어졌다고 하자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "8ff9d793",
      "metadata": {
        "id": "8ff9d793"
      },
      "outputs": [],
      "source": [
        "w = tc.tensor([2., 4.], requires_grad=True)\n",
        "learning_rate = 0.1\n",
        "num_steps = 30"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c03fd2c5",
      "metadata": {
        "id": "c03fd2c5"
      },
      "source": [
        "이러한 상황에 대해 아래의 코드를 채워 경사하강법을 수행하는 코드를 작성해보자. 제대로 코드를 작성한다면, 다음과 같이 $w_1=0, w_2=0$으로 서서히 가까워지는 결과가 출력될 것이다.\n",
        "```\n",
        "Tensor([1.2, 1.6])\n",
        "Tensor([0.72, 0.64])\n",
        "Tensor([0.432, 0.256])\n",
        "Tensor([0.2592, 0.1024])\n",
        "Tensor([0.15552, 0.04096])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "6dc9819f",
      "metadata": {
        "id": "6dc9819f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ec0435a-5819-4190-9110-a16a4eb340e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.2000, 1.6000], requires_grad=True)\n",
            "tensor([0.7200, 0.6400], requires_grad=True)\n",
            "tensor([0.4320, 0.2560], requires_grad=True)\n",
            "tensor([0.2592, 0.1024], requires_grad=True)\n",
            "tensor([0.1555, 0.0410], requires_grad=True)\n",
            "tensor([0.0933, 0.0164], requires_grad=True)\n",
            "tensor([0.0560, 0.0066], requires_grad=True)\n",
            "tensor([0.0336, 0.0026], requires_grad=True)\n",
            "tensor([0.0202, 0.0010], requires_grad=True)\n",
            "tensor([0.0121, 0.0004], requires_grad=True)\n",
            "tensor([0.0073, 0.0002], requires_grad=True)\n",
            "tensor([4.3536e-03, 6.7109e-05], requires_grad=True)\n",
            "tensor([2.6121e-03, 2.6844e-05], requires_grad=True)\n",
            "tensor([1.5673e-03, 1.0737e-05], requires_grad=True)\n",
            "tensor([9.4037e-04, 4.2950e-06], requires_grad=True)\n",
            "tensor([5.6422e-04, 1.7180e-06], requires_grad=True)\n",
            "tensor([3.3853e-04, 6.8719e-07], requires_grad=True)\n",
            "tensor([2.0312e-04, 2.7488e-07], requires_grad=True)\n",
            "tensor([1.2187e-04, 1.0995e-07], requires_grad=True)\n",
            "tensor([7.3123e-05, 4.3980e-08], requires_grad=True)\n",
            "tensor([4.3874e-05, 1.7592e-08], requires_grad=True)\n",
            "tensor([2.6324e-05, 7.0369e-09], requires_grad=True)\n",
            "tensor([1.5795e-05, 2.8147e-09], requires_grad=True)\n",
            "tensor([9.4768e-06, 1.1259e-09], requires_grad=True)\n",
            "tensor([5.6861e-06, 4.5036e-10], requires_grad=True)\n",
            "tensor([3.4116e-06, 1.8014e-10], requires_grad=True)\n",
            "tensor([2.0470e-06, 7.2058e-11], requires_grad=True)\n",
            "tensor([1.2282e-06, 2.8823e-11], requires_grad=True)\n",
            "tensor([7.3691e-07, 1.1529e-11], requires_grad=True)\n",
            "tensor([4.4215e-07, 4.6117e-12], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "#결과적으로 1에 가까워지는 모습을 볼 수 있다\n",
        "const = tc.tensor([2.0, 3.0])\n",
        "for _ in range(num_steps):\n",
        "    ℒ = const * w ** 2\n",
        "    ℒ.sum().backward()\n",
        "    # 여기에 코드 작성\n",
        "\n",
        "    # w 업데이트 (메모리 최적화)\n",
        "    with tc.no_grad():\n",
        "      w -= learning_rate * w.grad\n",
        "    # w 값 출력\n",
        "    print(w)\n",
        "\n",
        "    # 그래디언트 초기화\n",
        "    w.grad.zero_()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f86fbb1",
      "metadata": {
        "id": "8f86fbb1"
      },
      "source": [
        "#### 일반적인 경사하강법 함수 작성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "633555d6",
      "metadata": {
        "id": "633555d6"
      },
      "source": [
        "일변수 함수, 다변수 함수에 대해 경사하강법을 수행해보았으니, 보편적인 상황에 대해 적용할 수 있는 일반적인 경사하강법 함수를 작성하는 것만 남았다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78175514",
      "metadata": {
        "id": "78175514"
      },
      "source": [
        "<문제: 일반적인 경사하강법 함수 작성하기>\n",
        "\n",
        "이 문제의 목표는 어떤 함수가 어떤 텐서로 정의되어 있는지에 상관없이 사용할 수 있는 경사하강법 함수를 작성하는 것이다. 함수 외부에서 텐서와 텐서들로 정의된 함수를 모두 정의한 후, .backward() 메서드까지 실행한다. 함수 내부로는 텐서들만 전달해주어, 함수 내에서는 그 텐서들을 이용하여 경사하강법을 실행한다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d8ac2fb",
      "metadata": {
        "id": "4d8ac2fb"
      },
      "source": [
        "아래 함수의 주석을 잘 보고, 일반적인 경사하강법 함수를 작성해보자. 주석을 보면 이 함수는 단일 텐서를 인자로 입력받을 수도 있지만, 여러개의 텐서로 이루어진 iterable한 객체를 입력받을 수도 있다. 어떻게 코딩해야 할지 막막한 느낌이 든다면, 다음 힌트를 살펴보자.\n",
        "\n",
        "> HINT\n",
        "> 1. 여러 개의 텐서로 이루어진 iterable한 자료형이 들어올 수 있으므로, for문을 이용하여 텐서를 하나씩 꺼내며 경사하강하는 코드를 작성해야한다.\n",
        "> 2. 단일 텐서가 들어오면 for문을 이용할 수 없으므로, 단일 텐서를 단일 텐서가 들어있는 리스트로 바꾸어주는 과정이 있어야 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "db9666b8",
      "metadata": {
        "id": "db9666b8"
      },
      "outputs": [],
      "source": [
        "def gradient_step(tensors, learning_rate):\n",
        "    \"\"\"\n",
        "    경사하강법의 공식에 따라 gradient-step을 실행.\n",
        "\n",
        "    매개변수 (Parameters)\n",
        "    ----------\n",
        "    tensors : Union[Tensor, Iterable[Tensors]]\n",
        "        단일 텐서, 혹은 텐서로 이루어진 iterable(리스트, 튜플 등) 모두 가능\n",
        "        만약 특정 tensor에 대한 `tensor.grad`가 `None`인 경우, 업데이트를 건너 뜀\n",
        "\n",
        "    learning_rate : float\n",
        "        매 gradient-step에서의 학습률. 양수\n",
        "\n",
        "    참고\n",
        "    -----\n",
        "    함수에서 진행되는 모든 gradient-steps는 tensor 내에서 바로 반영되므로, 반환 값 없음\n",
        "    \"\"\"\n",
        "    # isinstance 함수를 이용하여 입력된 tensors가 단일 텐서인지, iterable인지 판단한다\n",
        "\n",
        "    if isinstance(tensors, tc.Tensor):\n",
        "        # Only one tensor was provided. Pack\n",
        "        # it into a list so it can be accessed via\n",
        "        # iteration\n",
        "        tensors = [tensors]\n",
        "\n",
        "\n",
        "    # for 문을 이용하여 tensors의 tensor를 하나씩 꺼내며 경사하강을 진행\n",
        "    for i in tensors:\n",
        "      if f.grad is not None:\n",
        "        f.data -= learning_rate * t.grad\n",
        "        t.grad.zero_()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63edb99a",
      "metadata": {
        "id": "63edb99a"
      },
      "source": [
        "앞서 수행했던 함수 $\\mathscr{L}(w) = w^2$에 대한 경사하강법을 다시 한번 실행해봄으로써 보편적인 경사하강법 함수가 우리가 원하는대로 동작하는지 확인해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "fbf280d6",
      "metadata": {
        "id": "fbf280d6"
      },
      "outputs": [],
      "source": [
        "w = tc.tensor(10.0, requires_grad=True)\n",
        "learning_rate = 0.3\n",
        "num_steps = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "9abee228",
      "metadata": {
        "id": "9abee228",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5fefe0d-cccb-428c-ea57-46935dd6762a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10., requires_grad=True)\n",
            "tensor(10., requires_grad=True)\n",
            "tensor(10., requires_grad=True)\n",
            "tensor(10., requires_grad=True)\n",
            "tensor(10., requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "for _ in range(num_steps):\n",
        "    ℒ = w ** 2\n",
        "    ℒ.backward()\n",
        "    w.grad\n",
        "    print(w)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99313c60",
      "metadata": {
        "id": "99313c60"
      },
      "source": [
        "### 배운 내용 되돌아보기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cecca3d9",
      "metadata": {
        "id": "cecca3d9"
      },
      "source": [
        "이번 실습에서는 자동미분을 도와주는 PyTorch 라이브러리의 사용법을 배우고 익혔다. PyTorch는 앞으로의 거의 모든 실습에서 사용되는 중요한 라이브러리이다.\n",
        "\n",
        "- Tensor를 생성하는 여러 가지 함수들을 사용해보았다. 원소를 직접 적어줄 수도 있고, 리스트, 튜플, NumPy의 ndarray 등으로부터 Tensor를 생성할 수도 있었다.\n",
        "\n",
        "- 기존에 생성된 Tensor의 행과 열을 자유자재로 바꾸거나 일부 행이나 열만 슬라이싱 해보았다.\n",
        "\n",
        "- PyTorch에서 제공하는 다양한 수학 연산 함수들을 사용해보았다. 그 과정에서 NumPy의 함수들과의 유사성을 확인하였다.\n",
        "\n",
        "- 선형대수 연산을 돕는 함수인 matmul()과 einsum()을 사용해보았다.\n",
        "\n",
        "- PyTorch에 딥러닝을 위한 특수 함수들이 다양하게 존재함을 알게 되었으나, 사용해보지는 않았다.\n",
        "\n",
        "- PyTorch 텐서 객체의 .backward() 메서드를 사용하여 자동미분을 실행하고, 텐서의 .grad 속성을 이용하여 편미분 계수를 구해보았다.\n",
        "\n",
        "- 경사하강을 반복하며 최적의 모델을 찾아갈 때, 경사하강이 1회 종료될 때마다 기존의 편미분 계수를 폐기해주어야 함을 알게 되었다. 이를 위해 .grad 속성을 폐기하는 방법을 직접 사용해보았다.\n",
        "\n",
        "- PyTorch 텐서와 NumPy의 배열 사이의 관계를 알게 되었다.\n",
        "\n",
        "- 불필요한 편미분 계수를 계산하는 것을 방지하기 위해, 텐서를 상수 취급하는 방법을 도입해야 함을 알게 되었다. 그리고 텐서를 상수 취급하기 위한 방법을 사용해보았다.\n",
        "\n",
        "- 다차원 텐서에 대해 정의된 함수 (다변수 함수)에서 자동미분을 실행하면 다차원 텐서의 각 원소가 스칼라 값 변수로 해석되어 자동미분이 이루어짐을 알게 되었다. 또한 다차원 텐서의 .grad 속성에 함수의 그래디언트 값이 저장됨을 확인하였다.\n",
        "\n",
        "- 다변수 벡터 함수에 대해 자동미분을 실행하면 모든 성분함수를 합한 것에 대해 자동미분이 이루어짐을 알게 되었다. 또한 이런 규칙이 어떤 유용함을 가지는지 확인하였다.\n",
        "\n",
        "- PyTorch의 자동미분을 이용하여 경사하강법 함수를 새롭게 구현해보았다."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xfCuA6MxGEHh",
        "G1rUUHZFGi-3",
        "b-l8ieGVGv3M",
        "rbGPZ_ydG53A",
        "U0_bPo_AHGKV",
        "61fa582a",
        "b10bbdab"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}