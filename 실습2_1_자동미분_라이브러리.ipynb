{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shriver42/OUTTA/blob/main/%EC%8B%A4%EC%8A%B52_1_%EC%9E%90%EB%8F%99%EB%AF%B8%EB%B6%84_%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25533d3b",
      "metadata": {
        "id": "25533d3b"
      },
      "source": [
        "# 실습 3: 자동미분(AutoDiff) 라이브러리"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f60968f6",
      "metadata": {
        "id": "f60968f6"
      },
      "source": [
        "앞서 우리는 그래디언트 기반 학습에 대해 살펴보았다. $\\mathscr{L}$이 간단한 함수일 때는 편미분하는 것이 간단한 일이었지만, 앞으로는 손으로 편미분을 계산하기는 어려운 다양한 함수들을 $\\mathscr{L}$ 로 만나게 될 것이다. 이럴 때 필요한 것이 바로 컴퓨터의 계산 능력이다. 그래디언트 기반 학습에 대한 관심이 크게 증가하면서, 미분을 자동으로 계산해주는 자동미분 라이브러리가 여럿 개발되었다. 널리 쓰이는 라이브러리로는 [PyTorch](https://pytorch.org/), [TensorFlow](https://www.tensorflow.org/), [JAX](https://github.com/google/jax), [Zygote](https://github.com/FluxML/Zygote.jl) 등이 있다.\n",
        "\n",
        "이 책에서는 위의 라이브러리 중에서 쉽게 이해하고 사용할 수 있는 PyTorch 라이브러리를 사용할 것이다. 이 라이브러리는 NumPy 라이브러리와 매우 유사하게 동작하기 때문에, NumPy만 잘 알아도 쉽게 사용할 수 있다. NumPy에서 ndarray(배열)가 기본이 되는 핵심 객체인 것과 같이, PyTorch의 핵심 객체는 Tensor(텐서)라고 부른다. 이 Tensor는 ndarray와 매우 유사하게 동작이 가능하다.\n",
        "\n",
        "이 실습에서 PyTorch를 통한 자동미분에 익숙해지고 나면, 이 책 전반에 걸쳐 PyTorch를 자유자재로 사용하며 딥러닝을 배우게 될 것이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e93acc4d",
      "metadata": {
        "id": "e93acc4d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch as tc\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03d35d08",
      "metadata": {
        "id": "03d35d08"
      },
      "source": [
        "구글 코랩(Google Colab)에서는 PyTorch가 기본적으로 설치되어 있다. 따라서 별도로 설치할 필요 없이 바로 사용 가능하다. PyTorch가 제대로 설치되어 있는지 확인하려면 아래와 같은 코드를 실행해볼 수 있다.\n",
        "torch.cuda.is_available() 코드가 False의 결과가 나오면 메뉴에서\n",
        "\n",
        "런타임 > 런타임 유형 변경 > 하드웨어 가속기\n",
        "\n",
        "에서 보면 CPU가 선택되어 있을 것인데 이를 GPU로 바꿔줘야 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "kPxSBddWT2OT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPxSBddWT2OT",
        "outputId": "589a652e-3e1b-4f0c-e18f-6d1a41b79a95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.0+cu121\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a73926ed",
      "metadata": {
        "id": "a73926ed"
      },
      "source": [
        "### Step 1. PyTorch의 여러가지 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "335815d5",
      "metadata": {
        "id": "335815d5"
      },
      "source": [
        "라이브러리를 사용할 때, 유명한 라이브러리의 경우에는 구글링을 통해 쉽게 설명된 블로그 등을 참고할 수도 있다. 하지만 정석은 라이브러리 개발자가 작성한 도큐먼트(document)를 읽는 것이다. 이 실습에서는 PyTorch를 사용한 자동미분을 배우는 것을 가장 중요한 목적으로 다루고 있으므로, 더 다양한 함수와 기능이 궁금하다면 직접 [도큐먼트](https://mygrad.readthedocs.io/en/latest/)를 읽어보길 바란다. 또한, NumPy의 기본 함수들과 일치하는 함수를 많이 가지고 있으므로, NumPy의 함수들을 찾아 PyTorch에 적용해보아도 좋다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d06b0a0d",
      "metadata": {
        "id": "d06b0a0d"
      },
      "source": [
        "#### Tensor 생성\n",
        "Tensor는 Pytorch 라이브러리에서 사용하는 데이터를 배열 형식으로 저장하도록 한다. 다양한 방식으로 Tensor를 생성할 수 있다. 다음은 Tensor를 생성하는 여러 가지 예이다. tc.tensor 외에도 Tensor를 생성하는 다양한 함수들이 있다. 직접 코드를 실행하여 output을 확인해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "42d2424d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42d2424d",
        "outputId": "885a1b77-5aa1-4cdb-cc2a-1519413040cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3000)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# 단일 숫자로 생성한 Tensor\n",
        "tc.tensor(2.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4b71a705",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b71a705",
        "outputId": "0bcfce2f-aefa-4499-95b2-95b80971cb56"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# 시퀀스(리스트, 튜플 등) 자료형으로 생성한 Tensor.\n",
        "# dtype을 지정할 수 있는 모든 함수에서\n",
        "# 32-bit floats를 저장하는 텐서를 반환하도록 지정 가능.\n",
        "tc.tensor([1.0, 2.0, 3.0], dtype = tc.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "737f62f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "737f62f3",
        "outputId": "16b91eae-3301-4553-be93-45414c914702"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# numpy.ndarray로부터 생성한 Tensor\n",
        "arr = np.ones((3,3))\n",
        "tc.tensor(arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "970b3585",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "970b3585",
        "outputId": "922c162f-9c8c-4d13-9044-30738d3e4eb5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Tensor 생성 함수 (ones, zeros; 각각 1, 0으로 채움)\n",
        "#tensor는 가장 바깥쪽으로 부터 읽어나가면 된다. 2: 차원 3: 행, 4: 열\n",
        "tc.zeros([2,3,4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbe81f6c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbe81f6c",
        "outputId": "d754b468-b635-4457-95d7-1ac3d61f293e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-5, -3, -1,  1,  3,  5,  7,  9, 11, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Tensor 생성 함수 (start 부터 stop 까지 step 만큼 띄워가며 채움)\n",
        "#python과 동일하게 마지막 값은 포함 안한다.\n",
        "tc.arange(-5,15,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae113b63",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae113b63",
        "outputId": "6cfd00da-8f6b-4e06-b083-a8380a5896cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8.])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# start = 0, step = 1이 default 값\n",
        "tc.arange(9.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbdb971e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbdb971e",
        "outputId": "5fbea770-a576-4411-c300-9124d4a8ed23"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8931, 0.3190, 0.0201, 0.1794],\n",
              "        [0.0462, 0.5018, 0.8943, 0.9524],\n",
              "        [0.8608, 0.4059, 0.2507, 0.2827]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# 0~1 사이의 값 무작위로 리턴 (확률분포는 균등분포(uniform))\n",
        "tc.rand(3,4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9373be2a",
      "metadata": {
        "id": "9373be2a"
      },
      "source": [
        "<문제: 주어진 조건을 만족하는 Tensor 생성하기>\n",
        "\n",
        "구간 $[0, \\pi]$에 등간격으로 분포한 15개의 구성요소로 이루어진 shape-(15,)인 tensor를 만들어보자. (Hint: tc.linspace(), tc.pi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82ebd43d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82ebd43d",
        "outputId": "8f4f4268-1af5-4b6f-fa3f-6b8c295c4d1f",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.2244, 0.4488, 0.6732, 0.8976, 1.1220, 1.3464, 1.5708, 1.7952,\n",
              "        2.0196, 2.2440, 2.4684, 2.6928, 2.9172, 3.1416])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "tc.linspace(0,tc.pi,15)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71697cae",
      "metadata": {
        "id": "71697cae"
      },
      "source": [
        "#### Tensor 변형\n",
        "Tensor의 모양을 변형하는 함수들도 있다. 직접 코드를 실행하여 output을 확인해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38946f50",
      "metadata": {
        "id": "38946f50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cb513f1-3cfe-4182-df31-73344696a7f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 2.],\n",
              "        [3., 4., 5.],\n",
              "        [6., 7., 8.]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Tensor의 행과 열을 바꾸어주는 함수\n",
        "x = tc.arange (9.) #Tensor([0., 1., 2., 3., 4., 5., 6., 7., 8.])\n",
        "x.reshape(3,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a22b453",
      "metadata": {
        "id": "3a22b453",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20406d2f-4cfd-4b5f-84e4-98b95e1b6f28"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  3,  6,  9],\n",
              "        [ 1,  4,  7, 10],\n",
              "        [ 2,  5,  8, 11]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Tensor의 전치 행렬을 구하는 함수\n",
        "x = tc.tensor([[0,1,2],[3,4,5],[6,7,8],[9,10,11]])\n",
        "x.t()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a38b3441",
      "metadata": {
        "id": "a38b3441",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e147c57d-fbf9-47cd-cd7c-f0a909c44d8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# 슬라이싱 (자유자재로 쓸 수 있으면 좋다)\n",
        "x = tc.tensor([[1,2,3,4,5],[6,7,8,9,10]])\n",
        "x[0,2:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6320c0ee",
      "metadata": {
        "id": "6320c0ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64eed6b0-2985-44f7-a293-30ecd3edf505"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "x = tc.tensor([[1,2,3,4,5],[6,7,8,9,10]])\n",
        "x[0, -3:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6232d6c1",
      "metadata": {
        "id": "6232d6c1"
      },
      "source": [
        "#### Tensor 표준 수학 연산\n",
        "\n",
        "먼저, PyTorch에서 제공하는 표준적인 수학 함수들을 알아보자. 기본적인 산술 연산을 하는 함수를 비롯하여, (sum, mean, var, std, max, min) 등의 통계량을 구하는 함수 등이 제공된다. 또한, 삼각함수, 쌍곡함수, 지수함수, 로그함수 등의 초월함수도 제공된다. NumPy의 함수들과 동일하게, 벡터화된 함수들이다.\n",
        "\n",
        "단항 함수는 텐서에 대해 요소별로 각각 작동한다. 이항 함수는 두 텐서에 대해 대응되는 위치의 요소 간에 자연스럽게 작동한다. 두 텐서가 동일한 모양이 아니더라도 Numpy와 같은 [브로드캐스팅(Broadcasting)](https://numpy.org/doc/stable/user/basics.broadcasting.html) 규칙을 따르기 때문에, 이항 함수가 작동할 수 있는 경우가 있다.\n",
        "\n",
        "직접 코드를 실행하여 output을 확인해보자. 이를 통해 단항 연산과 이항 연산을 다루는 여러 함수에 대해 이해해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4d930c8",
      "metadata": {
        "id": "b4d930c8"
      },
      "outputs": [],
      "source": [
        "x = tc.tensor([0.0, 0.25, 0.5, 0.75, 1.0])\n",
        "y = tc.tensor([[0.],[1.],[2.]])\n",
        "z = tc.tensor([[0,1,2,3],[4,5,6,7],[8,9,10,11]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa53ba6b",
      "metadata": {
        "id": "aa53ba6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae0506d9-2a5b-438a-ecc9-f47c6672ba5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.2474, 0.4794, 0.6816, 0.8415])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# 단항 함수 중 하나인 삼각함수 sin()\n",
        "# 텐서의 모든 요소의 sin 값으로 채워진 같은 크기의 텐서\n",
        "tc.sin(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27891022",
      "metadata": {
        "id": "27891022",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd246d0f-61ac-49e4-c7aa-cc462e8dd470"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(66)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# 단항 함수 중 통계량을 구하는 함수들은 axis 인자를 가짐\n",
        "# axis가 0이면 행에 대해서만 함수를 적용하고,\n",
        "# axis가 1이면 열에 대해서만 함수를 적용\n",
        "tc.sum(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99ed2ce2",
      "metadata": {
        "id": "99ed2ce2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73f133eb-a6e6-4e0d-8c65-4f77102c54bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12, 15, 18, 21])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "tc.sum(z, axis = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "628e8b1b",
      "metadata": {
        "id": "628e8b1b"
      },
      "source": [
        "z = tc.tensor([[0,1,2,3],[4,5,6,7],[8,9,10,11]])\n",
        "\n",
        "=>\n",
        "\n",
        "$[[0,1,2,3], \\\\\n",
        "    [4,5,6,7], \\\\\n",
        "    [8,9,10,11]]$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fe0294b",
      "metadata": {
        "id": "9fe0294b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e32fdab-5ebe-49af-f0e0-e236ed3bb66b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 6, 22, 38])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "tc.sum(z, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9686434",
      "metadata": {
        "id": "b9686434",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a43868c-54aa-4966-8c99-f6052485a9d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.2500, 0.5000, 0.7500, 1.0000],\n",
              "        [1.0000, 1.2500, 1.5000, 1.7500, 2.0000],\n",
              "        [2.0000, 2.2500, 2.5000, 2.7500, 3.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# 브로드캐스팅 예(1)\n",
        "# x+y, y+z는 브로드캐스팅이 가능, x+z는 불가능\n",
        "#더 작은 텐서가 큰 텐서에 맞춰서 알아서 연산을 해준다\n",
        "x+y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c0e5310",
      "metadata": {
        "id": "6c0e5310",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "579644c5-8dce-49ad-8a38-8aae96ffbe13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.],\n",
              "        [ 5.,  6.,  7.,  8.],\n",
              "        [10., 11., 12., 13.]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "y+z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef7e7090",
      "metadata": {
        "id": "ef7e7090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "bf1fc61f-6971-4a06-f2c0-dfc0922068a5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-0e52b3dd32a7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mz\u001b[0m \u001b[0;31m# Error 발생\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1"
          ]
        }
      ],
      "source": [
        "x+z # Error 발생"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "942ebf93",
      "metadata": {
        "id": "942ebf93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20ac3bab-c74f-4848-beb9-fb244dec74de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.2500, 0.5000, 0.7500, 1.0000],\n",
              "        [0.0000, 0.5000, 1.0000, 1.5000, 2.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# 브로드캐스팅 예(2)\n",
        "# x*y, y*z는 브로드캐스팅이 가능, x*z는 불가능\n",
        "x*y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45b61b7f",
      "metadata": {
        "id": "45b61b7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66c8a894-bfea-420c-cbbe-826eadd07bcb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  0.,  0.,  0.],\n",
              "        [ 4.,  5.,  6.,  7.],\n",
              "        [16., 18., 20., 22.]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "y*z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b613e37",
      "metadata": {
        "id": "6b613e37"
      },
      "outputs": [],
      "source": [
        "x*z # Error 발생"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad45aec1",
      "metadata": {
        "id": "ad45aec1"
      },
      "source": [
        "<문제: Pytorch의 기본 수학 연산>\n",
        "\n",
        "아래와 같이 정의된 텐서 x에 대해 여러 가지 수학 연산을 적용하여 여러 가지 텐서를 구해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a98929d0",
      "metadata": {
        "id": "a98929d0"
      },
      "outputs": [],
      "source": [
        "x = tc.Tensor([[ 0.,  1.,  2.,  3.],\n",
        "...                [ 4.,  5.,  6.,  7.],\n",
        "...                [ 8.,  9., 10., 11.],\n",
        "...                [12., 13., 14., 15.]])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1번 문제"
      ],
      "metadata": {
        "id": "prqrJypdiwJ2"
      },
      "id": "prqrJypdiwJ2"
    },
    {
      "cell_type": "markdown",
      "id": "6e03887e",
      "metadata": {
        "id": "6e03887e"
      },
      "source": [
        "1. x의 3행의 첫번째, 세번째 원소에 대한 자연로그 값으로 채워진 shape-(2,)인 Tensor를 구해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b89e057",
      "metadata": {
        "id": "7b89e057",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3fbefe3-5284-4e3c-9b2b-651b20fc8c5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.0794, 2.3026])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "tc.log(x[2,0::2])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d1e928f",
      "metadata": {
        "id": "3d1e928f"
      },
      "source": [
        "## 1번 문제 정답"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tc.log(x[2,0::2])"
      ],
      "metadata": {
        "id": "2wSGga_FiWIq"
      },
      "id": "2wSGga_FiWIq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1번 문제 출력 결과 : tensor([2.0794, 2.3026])"
      ],
      "metadata": {
        "id": "F7fzgO9kikUX"
      },
      "id": "F7fzgO9kikUX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2번 문제"
      ],
      "metadata": {
        "id": "6M3xaJomisFT"
      },
      "id": "6M3xaJomisFT"
    },
    {
      "cell_type": "markdown",
      "id": "65c19bdd",
      "metadata": {
        "id": "65c19bdd"
      },
      "source": [
        "2. x를 가로, 세로로 4등분한 각 귀퉁이(왼쪽 위, 오른쪽 위, 왼쪽 아래, 오른쪽 아래)의 4개 원소를 더하여 shape-(2,2)인 Tensor를 구해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0076def",
      "metadata": {
        "id": "b0076def",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c65db4dd-77de-433b-977a-b646c8ea9314"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[20., 24.],\n",
              "        [36., 40.]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "x[:2,:2]+x[:2,2:]+x[2:,:2]+x[2:,2:]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2번 문제 정답"
      ],
      "metadata": {
        "id": "AyY6znLKidQj"
      },
      "id": "AyY6znLKidQj"
    },
    {
      "cell_type": "code",
      "source": [
        "x[:2,:2] + x[:2,2:] + x[2:,:2] + x[2:,2:]"
      ],
      "metadata": {
        "id": "a3JavlrAi3Nn"
      },
      "id": "a3JavlrAi3Nn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2번 문제 출력 결과 :\n",
        "\n",
        "tensor([[20., 24.],\\\n",
        "        [36., 40.]])"
      ],
      "metadata": {
        "id": "2ZYKqDfmjKFu"
      },
      "id": "2ZYKqDfmjKFu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3번 문제"
      ],
      "metadata": {
        "id": "t8AcEm9Ni-9i"
      },
      "id": "t8AcEm9Ni-9i"
    },
    {
      "cell_type": "markdown",
      "id": "d18ec6e0",
      "metadata": {
        "id": "d18ec6e0"
      },
      "source": [
        "  3. x의 각 열의 평균을 구하여 shape-(4,)인 Tensor를 구해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ff6a6bc",
      "metadata": {
        "id": "5ff6a6bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "844f644a-eb15-4818-f85d-691c2c461c5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6., 7., 8., 9.])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "tc.mean(x, axis= 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3번 문제 정답"
      ],
      "metadata": {
        "id": "Mf_Q1BkEjoCf"
      },
      "id": "Mf_Q1BkEjoCf"
    },
    {
      "cell_type": "code",
      "source": [
        "x.mean(axis=0)"
      ],
      "metadata": {
        "id": "-pmoGU-0jnk5"
      },
      "id": "-pmoGU-0jnk5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3번 문제 출력 결과 : tensor([6., 7., 8., 9.])"
      ],
      "metadata": {
        "id": "Pn-E0xyKjobv"
      },
      "id": "Pn-E0xyKjobv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4번 문제"
      ],
      "metadata": {
        "id": "W7y-HGgwjzr7"
      },
      "id": "W7y-HGgwjzr7"
    },
    {
      "cell_type": "markdown",
      "id": "d29b6965",
      "metadata": {
        "id": "d29b6965"
      },
      "source": [
        "4. x의 각 행을 벡터로보고, 각 벡터가 크기가 1이 되도록 정규화하여 shape-(4,4)인 Tensor로 업데이트해보자."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 백터의 크기를 1로 만들기 ㅜ이해 백터를 L2  노름으로 나누는 과정 : 정규화\n",
        "x /= tc.sqrt(tc.sum(x**2, axis = 1, keepdims = True))\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGii2EgCN_si",
        "outputId": "17537812-a4b4-4124-f49f-eacd3c4e844a"
      },
      "id": "aGii2EgCN_si",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.8093, 0.4793, 0.3396],\n",
              "        [0.9990, 0.0413, 0.0147, 0.0081],\n",
              "        [0.9992, 0.0372, 0.0122, 0.0064],\n",
              "        [0.9993, 0.0358, 0.0114, 0.0058]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d038eb54",
      "metadata": {
        "id": "d038eb54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c48cfcff-e054-40cb-e319-493b4ad74a53"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 1.0000, 1.0000, 1.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "# 정규화가 잘 되었는지 확인하기\n",
        "(x**2).sum(axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4번 문제 정답"
      ],
      "metadata": {
        "id": "-zPuP1PPj_yj"
      },
      "id": "-zPuP1PPj_yj"
    },
    {
      "cell_type": "code",
      "source": [
        "x /= tc.sqrt(tc.sum(x**2,axis=1,keepdims = True))\n",
        "x"
      ],
      "metadata": {
        "id": "hZ_679jyj3rQ"
      },
      "id": "hZ_679jyj3rQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4번 문제 출력 결과 : \\\\\n",
        "\n",
        "tensor([[0.0000, 0.2673, 0.5345, 0.8018], \\\n",
        "        [0.3563, 0.4454, 0.5345, 0.6236], \\\n",
        "        [0.4182, 0.4704, 0.5227, 0.5750], \\\n",
        "        [0.4429, 0.4798, 0.5167, 0.5537]])"
      ],
      "metadata": {
        "id": "dVP8WS0PkDKT"
      },
      "id": "dVP8WS0PkDKT"
    },
    {
      "cell_type": "code",
      "source": [
        "# 정규화가 잘 되었는지 확인하기 정답\n",
        "(x**2).sum(axis=1)"
      ],
      "metadata": {
        "id": "J9xPBjRsj3ff"
      },
      "id": "J9xPBjRsj3ff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#   "
      ],
      "metadata": {
        "id": "n8GyohNmkccZ"
      },
      "id": "n8GyohNmkccZ"
    },
    {
      "cell_type": "markdown",
      "id": "ca7b8e69",
      "metadata": {
        "id": "ca7b8e69"
      },
      "source": [
        "#### 선형대수 연산 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47ce788e",
      "metadata": {
        "id": "47ce788e"
      },
      "source": [
        "PyTorch에는 선형대수 연산을 쉽게 계산하도록 도와주는 함수들도 있다. matmul()은 행렬곱을 계산해주는 함수이다. 이를 이용하여 벡터의 점곱(스칼라곱)을 계산할 수도 있다. einsum()은 아인슈타인 표기법(Einstein notation 또는 Einstein summation convention)을 계산하는 함수이다. 이는 다소 복잡한 함수이지만, 다양한 사용자 지정 가능한 선형 대수 연산을 수행할 수 있다. PyTorch가 자동미분을 수행할 때 이 연산들을 통해 수행한다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "171b9c09",
      "metadata": {
        "id": "171b9c09"
      },
      "source": [
        "먼저 이항 연산 함수인 matmul()연산은 행렬곱을 기본으로 하는 함수이므로 2차원 텐서 간의 연산이 가장 자연스럽게 정의된다. 1차원 텐서 간의 matmul()을 명령하면 1차원 텐서를 1xn 크기의 2차원 텐서로 생각하여 연산을 진행한다. 그리고 n차원(3차원 이상)의 텐서 간의 matmul()은 n-2차원의 텐서의 구성요소가 2차원 텐서(행렬)인 것으로 생각하여 연산을 진행한다. 즉, 행렬이 여러개 모여있는 것으로 생각하고 행렬곱을 진행하는 것이다. matmul()연산 또한 NumPy의 브로드캐스팅 규칙을 따르는 함수이기 때문에 3차원 이상의 텐서에 대해서는 브로드캐스팅에도 유의해야 한다.\n",
        "\n",
        "matmul()을 사용할 때는 tc.matmul(x,y)로 사용할 수 있지만, x @ y 와 같이 연산자 @를 이용하여도 같은 연산을 할 수 있도록 정의되어 있다. 아래의 사용 예시를 따라가면 matmul() 함수의 사용법을 이해할 수 있을 것이다. 직접 코드를 실행하여 output을 확인해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0d89dcb",
      "metadata": {
        "id": "c0d89dcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b59c8c7-202a-4109-a74e-82448625a634"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-11.)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "# 1차원 텐서의 matmul 연산은 점곱(스칼라곱)을 구하는 것과 같음\n",
        "# 내적을 구하는 것과 동일하다\n",
        "x = tc.tensor([1.0, 2.0])\n",
        "y = tc.tensor([-3.0, -4.0])\n",
        "tc.matmul(x,y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1차원 텐서의 matmul 연산은 점곱(스칼라곱)을 구하는 것과 같음\n",
        "# @ : matrix multiplication\n",
        "x = tc.tensor([1.0, 2.0])\n",
        "y = tc.tensor([-3.0, -4.0])\n",
        "x@y"
      ],
      "metadata": {
        "id": "oKmJhLeklBTI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "375b35eb-8cb3-44b0-fe22-c78e5a8bee7d"
      },
      "id": "oKmJhLeklBTI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-11.)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "594d0ad6",
      "metadata": {
        "id": "594d0ad6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47b8af9f-51bc-4c8f-b00b-afc40ed5a565"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4,  1,  5],\n",
              "        [ 2,  2,  6],\n",
              "        [10,  4, 16],\n",
              "        [20, 11, 39]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "# 2차원 텐서의 matmul 연산은 그냥 행렬곱과 같음\n",
        "a = tc.tensor([[1, 0], [0, 1], [2, 1], [3, 4]])\n",
        "b = tc.tensor([[4, 1, 5], [2, 2, 6]])\n",
        "tc.matmul(a,b)  # a @ b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "375463a3",
      "metadata": {
        "id": "375463a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e14e305e-30ff-4b07-fda8-35561768d28c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0,  1,  2],\n",
            "         [ 3,  4,  5]],\n",
            "\n",
            "        [[ 2,  3,  4],\n",
            "         [ 5,  6,  7]],\n",
            "\n",
            "        [[ 4,  5,  6],\n",
            "         [ 7,  8,  9]],\n",
            "\n",
            "        [[ 6,  7,  8],\n",
            "         [ 9, 10, 11]]])\n",
            "tensor([[[ 0,  1,  2],\n",
            "         [ 3,  4,  5],\n",
            "         [ 6,  7,  8]],\n",
            "\n",
            "        [[ 2,  3,  4],\n",
            "         [ 5,  6,  7],\n",
            "         [ 8,  9, 10]],\n",
            "\n",
            "        [[ 4,  5,  6],\n",
            "         [ 7,  8,  9],\n",
            "         [10, 11, 12]],\n",
            "\n",
            "        [[ 6,  7,  8],\n",
            "         [ 9, 10, 11],\n",
            "         [12, 13, 14]]])\n",
            "tensor([[[ 15,  18,  21],\n",
            "         [ 42,  54,  66]],\n",
            "\n",
            "        [[ 51,  60,  69],\n",
            "         [ 96, 114, 132]],\n",
            "\n",
            "        [[111, 126, 141],\n",
            "         [174, 198, 222]],\n",
            "\n",
            "        [[195, 216, 237],\n",
            "         [276, 306, 336]]])\n"
          ]
        }
      ],
      "source": [
        "# A는 크기가 (4, 2, 3)인 3차원 텐서\n",
        "A1 = tc.arange(2*3).reshape(2,3)\n",
        "A = tc.stack([A1, A1+2, A1+4, A1+6])\n",
        "\n",
        "# B는 크기가 (4, 3, 3)인 3차원 텐서\n",
        "B1 = tc.arange(3*3).reshape((3,3))\n",
        "B = tc.stack([B1, B1+2, B1+4, B1+6])\n",
        "\n",
        "# matmul 연산을 제대로 이해했는지 확인하기 위해\n",
        "# 손으로도 직접 계산해보고, 결과가 동일한지 확인해보기\n",
        "print(A)\n",
        "print(B)\n",
        "print(tc.matmul(A, B))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6479f8f0",
      "metadata": {
        "id": "6479f8f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93067012-4943-4c98-fb20-9bdb6bc3d424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 2, 3])\n",
            "tensor([[[ 15,  18,  21],\n",
            "         [ 42,  54,  66]],\n",
            "\n",
            "        [[ 51,  60,  69],\n",
            "         [ 96, 114, 132]],\n",
            "\n",
            "        [[111, 126, 141],\n",
            "         [174, 198, 222]],\n",
            "\n",
            "        [[195, 216, 237],\n",
            "         [276, 306, 336]]])\n"
          ]
        }
      ],
      "source": [
        "C = tc.matmul(A,B)\n",
        "print(C.shape)\n",
        "print(C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4b01755",
      "metadata": {
        "id": "e4b01755",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74b544d9-6a44-4821-d4ae-c4f095e1e088"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1.3481, 0.7644],\n",
              "         [1.6353, 1.1690],\n",
              "         [1.7170, 1.3143]],\n",
              "\n",
              "        [[1.3230, 0.3635],\n",
              "         [2.1351, 1.1179],\n",
              "         [1.8111, 0.8387]],\n",
              "\n",
              "        [[0.9971, 0.7296],\n",
              "         [1.0433, 0.5757],\n",
              "         [2.2006, 1.2617]],\n",
              "\n",
              "        [[2.9000, 1.6864],\n",
              "         [1.2712, 0.6129],\n",
              "         [2.4665, 1.2381]],\n",
              "\n",
              "        [[0.8217, 0.4602],\n",
              "         [1.3320, 0.7044],\n",
              "         [2.5454, 1.6606]]])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "# 브로드캐스팅 예 (y를 5개로 브로드캐스팅하여 x와 연산)\n",
        "x = tc.rand(5,3,4)\n",
        "y = tc.rand(4,2)\n",
        "tc.matmul(x,y) # x @ y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bb78257",
      "metadata": {
        "id": "7bb78257"
      },
      "source": [
        "NumPy에서는 행렬곱 연산을 하는 함수가 두 개 있다. 바로 dot연산과 matmul 연산이다.두 함수는 2차원 배열 두개의 곱에 대해 동일한 행렬곱을 결과로 도출한다. 그러나 3차원 이상에서는 서로 다르게 동작한다. 이 두 함수의 차이가 궁금하다면 직접 검색하여 공부해보자."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a3a1d7c",
      "metadata": {
        "id": "1a3a1d7c"
      },
      "source": [
        "다음으로 einsum()함수는 행렬 연산에 관한 다양한 함수들을 다 알지 못하더라도, 이 함수 하나만을 가지고 다양한 행렬 연산을 사용자가 직접 지정해줄 수 있는 함수이다. 이 함수의 원리는 아인슈타인 표기법을 따르는데, 아인슈타인 표기법에 대해 스스로 검색하여 공부해보면 Numpy와 PyTorch에서 einsum()함수를 사용하는 예시들을 쉽게 이해할 수 있을 것이다.\n",
        "\n",
        "아래의 예시들을 직접 실행해보며 einsum()함수의 유용함을 느껴보자, einsum()함수에 대해 완벽히 이해하지 못했더라도 괜찮다. 다만 앞으로 einsum()함수의 새로운 사용 예시를 보게 되더라도 낯설고 어렵게 느끼지 말고, 익숙하게 느끼길 바란다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beabda70",
      "metadata": {
        "id": "beabda70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ca95e2a-10b5-4732-bb89-fc07c90ddb7e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0,  1,  2,  3,  4],\n",
              "         [ 5,  6,  7,  8,  9],\n",
              "         [10, 11, 12, 13, 14],\n",
              "         [15, 16, 17, 18, 19],\n",
              "         [20, 21, 22, 23, 24]]),\n",
              " tensor([[ 0,  1,  2],\n",
              "         [ 3,  4,  5],\n",
              "         [ 6,  7,  8],\n",
              "         [ 9, 10, 11],\n",
              "         [12, 13, 14]]),\n",
              " tensor([[  0,  -1,  -2],\n",
              "         [ -3,  -4,  -5],\n",
              "         [ -6,  -7,  -8],\n",
              "         [ -9, -10, -11],\n",
              "         [-12, -13, -14]]))"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "a = tc.arange(25).reshape(5,5)\n",
        "b = tc.arange(15).reshape(5,3)\n",
        "c = -tc.arange(15).reshape(5,3)\n",
        "a, b, c"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "i는 행, j는 열을 뜻함\n"
      ],
      "metadata": {
        "id": "SO5CvLLnsh_n"
      },
      "id": "SO5CvLLnsh_n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6166eb9",
      "metadata": {
        "id": "c6166eb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1f91175-b7be-4f73-faab-be7a62f8dd41"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(60)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "# a의 대각합\n",
        "#문자열로 곱하고 싶은 부분을 나타낸다\n",
        "tc.einsum('ii',a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e81572d",
      "metadata": {
        "id": "7e81572d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5ebf525-cfb4-492e-9592-049152923f5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  6, 12, 18, 24])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "# a의 대각원소\n",
        "tc.einsum('ii->i', a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc252f98",
      "metadata": {
        "id": "bc252f98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56084b7d-c1a6-41d5-b717-6ea5c5dd9a78"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  3,  6,  9, 12],\n",
              "        [ 1,  4,  7, 10, 13],\n",
              "        [ 2,  5,  8, 11, 14]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "# b의 전치행렬\n",
        "tc.einsum('ji',b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d586edc",
      "metadata": {
        "id": "6d586edc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0778cd27-bb6a-449a-a610-e2eeef363217"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 90, 100, 110],\n",
              "         [240, 275, 310],\n",
              "         [390, 450, 510],\n",
              "         [540, 625, 710],\n",
              "         [690, 800, 910]]),\n",
              " tensor([[ 90, 100, 110],\n",
              "         [240, 275, 310],\n",
              "         [390, 450, 510],\n",
              "         [540, 625, 710],\n",
              "         [690, 800, 910]]))"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "# a와 b의 행렬곱 계산 (matmul과 결과가 동일함을 확인해보기)\n",
        "tc.einsum('ij,jk->ik', a,b), tc.matmul(a,b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "976de1a0",
      "metadata": {
        "id": "976de1a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a2a5e1b-0c16-4bf7-e3b6-cc78bddc6b8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  -5,  -50, -149, -302, -509])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "# 같은 모양의 텐서 b,c의 각 행끼리의 점곱을 계산\n",
        "tc.einsum('ij,ij->i',b,c)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50bdd8c5",
      "metadata": {
        "id": "50bdd8c5"
      },
      "source": [
        "#### 자동미분과 딥러닝을 위한 특수 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6676ae0f",
      "metadata": {
        "id": "6676ae0f"
      },
      "source": [
        "PyTorch는 NumPy와 유사한 함수들 외에도 PyTorch만의 딥러닝을 위한 특수 함수들을 제공합니다. torch.nn 모듈에서는 딥러닝을 진행할 신경망을 구현하는 데 필요한 손실 함수(loss function), 활성 함수(activation function), 초기화 함수(initializer)의 대표적인 예시들을 제공합니다. 이러한 함수들에 대해서는 이번 실습에서는 다루지 않을 것이지만, 바로 다음 실습부터 꾸준히 여러 함수들이 등장할 예정입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1a37a44",
      "metadata": {
        "id": "e1a37a44"
      },
      "source": [
        "### Step 2 자동미분 실행하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d850545d",
      "metadata": {
        "id": "d850545d"
      },
      "source": [
        "이제 PyTorch 라이브러리의 핵심 기능인 자동미분에 대해 알아보자. PyTorch를 비롯한 대부분의 자동미분 라이브러리는 함수의 도함수(편도함수)를 직접 구하지 않는다. 그 대신 주어진 점(입력값)에서의 미분계수(편미분계수) 값을 구한다. 즉, 자동미분 라이브러리는 지정해준 점에서의 함수의 순간 기울기를 구하는 기능만을 갖고 있으며, 우리는 이를 이용하여 미분가능한 모든 함수의 모든 지점에서의 기울기를 구할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56abc047",
      "metadata": {
        "id": "56abc047"
      },
      "source": [
        "#### 텐서 객체의 '.backward()' 메서드"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e4dd1f7",
      "metadata": {
        "id": "0e4dd1f7"
      },
      "source": [
        "PyTorch에서 자동미분을 호출하기 위해 필요한 유일한 방법은 Tensor.backward()이다. 다른 텐서로부터 계산한 텐서 F에 대해 F.backward()를 호출하면, PyTorch는 F가 의존하는 모든 텐서에 대해 F의 편미분계수를 계산하도록 지시한다. 이 편미분계수들은 각각의 텐서들의 .grad 속성에 Tensor로 저장된다. 이때 몇 가지 주의사항이 있다.\n",
        "\n",
        "1. requires_grad=True:\n",
        "자동 미분을 추적하려면 텐서를 생성할 때 requires_grad=True로 설정해야 한다.\n",
        "\n",
        "2. backward() 호출:\n",
        "Tensor.backward()를 호출하면 해당 텐서로부터 계산된 모든 텐서에 대해 그래디언트(기울기)를 계산합니다. backward()는 스칼라 값에 대해서만 호출할 수 있습니다. 만약 텐서가 스칼라가 아니라면, 적절한 축소 연산을 통해 스칼라로 변환한 후 backward()를 호출해야 한다 (예: sum())."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee0edf3a",
      "metadata": {
        "id": "ee0edf3a"
      },
      "source": [
        "예를 들어 아래와 같이 x, y, z 텐서가 있고, x와 y의 함수로 정의된 f 텐서가 있는 상황에서의 편미분을 살펴보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8909fc52",
      "metadata": {
        "id": "8909fc52"
      },
      "outputs": [],
      "source": [
        "x = tc.tensor(2.0, requires_grad = True)   #requires_grad : 추적 가능\n",
        "y = tc.tensor(3.0, requires_grad = True)\n",
        "z = tc.tensor(4.0, requires_grad = True)\n",
        "f = x*y  # tc.multiply(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9b04f19",
      "metadata": {
        "id": "d9b04f19"
      },
      "source": [
        "이 때, f.backward()를 호출하면 PyTorch가 f의 모든 편미분계수를 계산하도록 지시한다. 이는 역전파(backpropagation)라고 하는 컴퓨터가 빠르게 편미분계수를 계산할 수 있는 알고리즘을 사용하여 수행된다. 역전파 알고리즘은 딥러닝의 발전에서 빠질 수 없는 핵심적인 알고리즘이라 할 수 있는 것으로, 연쇄법칙(chain rule)에 기반한 알고리즘이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eff5c10e",
      "metadata": {
        "id": "eff5c10e"
      },
      "outputs": [],
      "source": [
        "f.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a891efdb",
      "metadata": {
        "id": "a891efdb"
      },
      "source": [
        "x와 y의 .grad() 속성을 살펴보면 $\\frac{d F}{d x}$와 $\\frac{d F}{dy}$의 값을 얻을 수 있다. .grad()는 텐서로 구해진다. z는 f가 의존하는 변수 텐서가 아니므로 .grad() 속성에 값이 없다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "692b2f01",
      "metadata": {
        "id": "692b2f01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7faec5ae-7c8e-4654-f468-c284bcdb66b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "x.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "208b6de2",
      "metadata": {
        "id": "208b6de2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a6b124d-a68f-4f6d-a83f-576f43381e9f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "y.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d5d2ed2",
      "metadata": {
        "id": "7d5d2ed2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb41442f-4676-4271-c301-1078e34db3bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "#z는 backward를 하지 않았기에 없다\n",
        "z.grad is None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab7cd692",
      "metadata": {
        "id": "ab7cd692"
      },
      "source": [
        "이번에는 x, y, 그리고 x와 y로부터 구해지는 f까지 세 텐서에 의존하는 텐서 F의 모든 편미분계수를 계산해보자. 즉, F(f(x, y), x, y)인 경우를 살펴볼 것이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cebffb7",
      "metadata": {
        "id": "2cebffb7"
      },
      "outputs": [],
      "source": [
        "x = tc.tensor(2.0, requires_grad=True)\n",
        "y = tc.tensor(3.0, requires_grad=True)\n",
        "f = x*y\n",
        "f.retain_grad()\n",
        "F = f + x - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a90c30f",
      "metadata": {
        "id": "1a90c30f"
      },
      "outputs": [],
      "source": [
        "F.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cb35f93",
      "metadata": {
        "id": "5cb35f93"
      },
      "source": [
        "f의 .grad() 속성을 살펴보면 $\\frac{\\partial F}{\\partial f}$의 값을 얻을 수 있다.\n",
        "y의 .grad() 속성을 살펴보면 $\\frac{\\partial F}{\\partial y} = \\frac{\\partial F}{\\partial f}\\frac{\\partial f}{\\partial y}$의 값을 얻을 수 있다.\n",
        "\n",
        "마지막으로 x의 경우, t = x에 대해 F = f + t - 2로 쓸 수 있다. 이렇게 생각하고 x의 .grad() 속성을 살펴보면 $\\frac{\\partial F}{\\partial x} = \\frac{\\partial F}{\\partial f}\\frac{\\partial f}{\\partial x} + \\frac{\\partial F}{\\partial t}\\frac{\\partial t}{\\partial x}$의 값을 얻을 수 있다.\n",
        "\n",
        "주의사항으로 PyTorch에서 특정 텐서의 그래디언트를 계산하기 위해서는 그 텐서에 대해 직접적으로 requires_grad=True를 설정하고, 필요하다면 중간 텐서에 대해서도 retain_grad() 메소드를 호출해야 한다. retain_grad()는 중간 텐서의 그래디언트를 저장하도록 한다. f.retain_grad() 코드가 없다면 어떻게 실행되는지 확인해보는 것도 좋을 것이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17a4384e",
      "metadata": {
        "id": "17a4384e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47e76023-4249-4562-9498-8fc3bf774085"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "f.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3da1420",
      "metadata": {
        "id": "c3da1420",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3338c73-51aa-4347-aca6-824f3de5383b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "y.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0f394a3",
      "metadata": {
        "id": "f0f394a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "563851de-26fb-41ef-c2a1-07ceb70a7f12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06825fb4",
      "metadata": {
        "id": "06825fb4"
      },
      "source": [
        "f와 F가 의존하는 모든 변수들이 PyTorch의 텐서로 저장되어 있었고, f와 F를 이루는 모든 수학적 연산이 PyTorch에서 제공하는 함수였기 때문에 PyTorch를 통해 F의 모든 편미분계수를 구할 수 있었다. 이렇게 구한 편미분계수들로부터 함수의 그래디언트를 이용하는 경사하강법을 쉽게 수행할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05aac9d3",
      "metadata": {
        "id": "05aac9d3"
      },
      "source": [
        "# 문제: 텐서 객체의 backward() 메서드 사용\n",
        "\n",
        "여러가지 수식으로 정의된 x에 대한 함수 F에 대해, x=2.5에서 $\\frac{d F}{d x}\\big|_{x=2.5}$를 구해보자."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1번 문제"
      ],
      "metadata": {
        "id": "MAGBsn7xGd1k"
      },
      "id": "MAGBsn7xGd1k"
    },
    {
      "cell_type": "markdown",
      "id": "f35f6a9d",
      "metadata": {
        "id": "f35f6a9d"
      },
      "source": [
        "1. $F(x)=x^2$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1ad9f204",
      "metadata": {
        "id": "1ad9f204",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4a59683-0f45-470c-97df-938235c01f36"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = x**2\n",
        "F.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1번 문제 정답"
      ],
      "metadata": {
        "id": "xfCuA6MxGEHh"
      },
      "id": "xfCuA6MxGEHh"
    },
    {
      "cell_type": "code",
      "source": [
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = x**2\n",
        "F.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "id": "hA-iU8diGMxo"
      },
      "id": "hA-iU8diGMxo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1번 문제 출력 결과 : tensor(5.)"
      ],
      "metadata": {
        "id": "YIOuj1FMGPMw"
      },
      "id": "YIOuj1FMGPMw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2번 문제"
      ],
      "metadata": {
        "id": "ekFW_3OnGSdU"
      },
      "id": "ekFW_3OnGSdU"
    },
    {
      "cell_type": "markdown",
      "id": "7a5cd97f",
      "metadata": {
        "id": "7a5cd97f"
      },
      "source": [
        "2. $F(x)=\\cos{\\sqrt{x}}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f62fd0dd",
      "metadata": {
        "id": "f62fd0dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "087cc523-0703-42b6-c360-e22e44148a82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.3162)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = tc.cos(tc.sqrt(x))\n",
        "F.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2번 문제 정답"
      ],
      "metadata": {
        "id": "G1rUUHZFGi-3"
      },
      "id": "G1rUUHZFGi-3"
    },
    {
      "cell_type": "code",
      "source": [
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = tc.cos(tc.sqrt(x))\n",
        "F.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "id": "4V1iRDD3GijE"
      },
      "id": "4V1iRDD3GijE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2번 문제 출력 결과 : tensor(-0.3162)"
      ],
      "metadata": {
        "id": "dIrwUZzyGibE"
      },
      "id": "dIrwUZzyGibE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3번 문제"
      ],
      "metadata": {
        "id": "aBe8aYzXGr3G"
      },
      "id": "aBe8aYzXGr3G"
    },
    {
      "cell_type": "markdown",
      "id": "f994e9f9",
      "metadata": {
        "id": "f994e9f9"
      },
      "source": [
        "3. $F(x)=2+3x-5x^2$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9aba45f7",
      "metadata": {
        "id": "9aba45f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89cb3273-bc97-48e4-fd7f-06514fc07ff9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-22.)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = 2 + 3*x - 5*(x**2)\n",
        "F.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3번 문제 정답"
      ],
      "metadata": {
        "id": "b-l8ieGVGv3M"
      },
      "id": "b-l8ieGVGv3M"
    },
    {
      "cell_type": "code",
      "source": [
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = 2+3*x-5*x**2\n",
        "F.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "id": "mEgwk9LhGuT6"
      },
      "id": "mEgwk9LhGuT6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3번 문제 출력 결과 : tensor(-22.)"
      ],
      "metadata": {
        "id": "gOabd2fPGul7"
      },
      "id": "gOabd2fPGul7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4번 문제"
      ],
      "metadata": {
        "id": "0oTiFRY5G2tE"
      },
      "id": "0oTiFRY5G2tE"
    },
    {
      "cell_type": "markdown",
      "id": "aa6ca763",
      "metadata": {
        "id": "aa6ca763"
      },
      "source": [
        "4. $F(x)=e^{lnx}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d028375e",
      "metadata": {
        "id": "d028375e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b8d945a-6e40-40f5-f5f4-ec856ffa8aa5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = tc.exp(tc.log(x))\n",
        "F.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4번 문제 정답"
      ],
      "metadata": {
        "id": "rbGPZ_ydG53A"
      },
      "id": "rbGPZ_ydG53A"
    },
    {
      "cell_type": "code",
      "source": [
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = tc.exp(tc.log(x))\n",
        "F.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "id": "dLQKI_84G5Sa"
      },
      "id": "dLQKI_84G5Sa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4번 문제 출력 결과 : tensor(1.)"
      ],
      "metadata": {
        "id": "G49bEx7jG5e4"
      },
      "id": "G49bEx7jG5e4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5번 문제"
      ],
      "metadata": {
        "id": "9UFMZxcHHEX5"
      },
      "id": "9UFMZxcHHEX5"
    },
    {
      "cell_type": "markdown",
      "id": "979502fa",
      "metadata": {
        "id": "979502fa"
      },
      "source": [
        "5. $F(x)=(2xf(x))^2-f(x), f(x)=x^2$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e333cb51",
      "metadata": {
        "id": "e333cb51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61b83298-28e2-4da3-f944-7d2742d4e993"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2338.7500)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "f = x**2\n",
        "F = (2*x*f)**2 - f\n",
        "F.backward()\n",
        "x.grad\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5번 문제 정답"
      ],
      "metadata": {
        "id": "U0_bPo_AHGKV"
      },
      "id": "U0_bPo_AHGKV"
    },
    {
      "cell_type": "code",
      "source": [
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "f = x**2\n",
        "F = (2*x*f)**2-f\n",
        "F.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "id": "PmQlhnDvHGbA"
      },
      "id": "PmQlhnDvHGbA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5번 문제 출력 결과 : tensor(2338.7500)"
      ],
      "metadata": {
        "id": "mfseKPKcHGwV"
      },
      "id": "mfseKPKcHGwV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -"
      ],
      "metadata": {
        "id": "1wT96P_lHMrw"
      },
      "id": "1wT96P_lHMrw"
    },
    {
      "cell_type": "markdown",
      "id": "72ea07a0",
      "metadata": {
        "id": "72ea07a0"
      },
      "source": [
        "#### .grad 속성의 초기화"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e8e4d75",
      "metadata": {
        "id": "0e8e4d75"
      },
      "source": [
        "경사하강법을 수행할 때, 텐서와 관련된 편미분계수를 반복적으로 구해야 한다. 따라서, 경사하강을 반복할 때마다 사이사이에 편미분계수를 폐기해야 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fce6da3",
      "metadata": {
        "id": "6fce6da3"
      },
      "source": [
        "backward()연산을 진행한 함수가 의존하는 텐서들 중 하나의 .grad 속성을 초기화하는 방법은 다음과 같이 두가지가 있다. 아래와 같은 상황을 생각해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "45b77985",
      "metadata": {
        "id": "45b77985",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd0d339e-4f54-4f9f-d6ae-d6026469636e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "x = tc.tensor(2.0, requires_grad=True)\n",
        "f = x**2\n",
        "f.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b0e92ca",
      "metadata": {
        "id": "9b0e92ca"
      },
      "source": [
        "그래디언트를 초기화하지 않으면, 추가 연산 후 backward()를 호출해도 이전 값에 누적되지 않고 덮어쓴다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "c7a13d5b",
      "metadata": {
        "id": "c7a13d5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfcf39d1-ff63-49fd-8f20-8ad0ab6dfae8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8.)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "#위와 같은 함수여도 위의 결과에 중첩되어서 다른 결과가 나온다.\n",
        "g = x**2\n",
        "g.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6477d424",
      "metadata": {
        "id": "6477d424"
      },
      "source": [
        "Tensor.grad를 호출하여 해당 텐서의 .grad 속성을 직접적으로 None으로 재설정할 수도 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "71cbc888",
      "metadata": {
        "id": "71cbc888"
      },
      "outputs": [],
      "source": [
        "#None을 이용하여 초기화 시킬 수 있다\n",
        "x.grad = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "0d3fb5eb",
      "metadata": {
        "id": "0d3fb5eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b24acfec-223a-441f-9a61-cd5675699c1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "x.grad is None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6de8423c",
      "metadata": {
        "id": "6de8423c"
      },
      "source": [
        "#### PyTorch와 Numpy의 관계"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4133bbb6",
      "metadata": {
        "id": "4133bbb6"
      },
      "source": [
        "우리는 앞의 내용에서 PyTorch에서 NumPy의 다양한 수학함수들을 동일하게 정의해두었다는 것을 충분히 확인했다.\n",
        "\n",
        "PyTorch의 텐서 객체는 NumPy 배열과 비교했을 때 별로 새롭지 않다. 텐서 객체는 Numpy 배열에 대한 정보를 기본으로 가지고 있으며, 단지 배열이 관련된 수학적 연산들을 추적하는 추가 역할을 할 뿐이다. 수학적 연산에 대한 추적은 자동미분을 위해 추가된 역할이라고 볼 수 있다.\n",
        "\n",
        "이러한 관계성에 의해 우리는 텐서를 한꺼풀 벗겨내어 NumPy 배열을 얻을 수 있다. 다음의 텐서 x에 대해 NumPy 배열로 만드는 세 가지 방법을 확인해보자."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7I3HEHz_gIFV",
      "metadata": {
        "id": "7I3HEHz_gIFV"
      },
      "source": [
        "먼저, 기본 텐서의 경우 numpy()를 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "55472dc7",
      "metadata": {
        "id": "55472dc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe65d4f6-a624-47ca-b9da-0636a30124ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "x = tc.tensor([0.0,1.0,2.0,3.0])\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "1ef96a8b",
      "metadata": {
        "id": "1ef96a8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a054580d-e0b8-4daf-960d-c745dea4384c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 2., 3.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "x.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e22945e",
      "metadata": {
        "id": "9e22945e"
      },
      "source": [
        "두번째로, grad 정보가 포함된 경우 detach().numpy()를 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "ac022abd",
      "metadata": {
        "id": "ac022abd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9620358-2fc0-47d2-ac82-1597294fb859"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "x = tc.tensor([0.0,1.0,2.0,3.0], requires_grad=True)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "38a70485",
      "metadata": {
        "id": "38a70485",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dff651ac-4e7d-4185-e979-6a22e5aca439"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 2., 3.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "x.detach().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CqdEZEnAg9p9",
      "metadata": {
        "id": "CqdEZEnAg9p9"
      },
      "source": [
        "세번째로, gpu에 선언된 텐서의 경우 cpu().numpy()를 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "uwST0Z-7g596",
      "metadata": {
        "id": "uwST0Z-7g596",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "ac97f18c-3028-4d59-e246-52dae34a82f2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-4a1cbd2921a7>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#cuad : GPU 환경을 의미함\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#numpy : CPU 환경에서 쓰임\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ],
      "source": [
        "#cuad : GPU 환경을 의미함\n",
        "#numpy : CPU 환경에서 쓰임\n",
        "x = tc.tensor([0.0,1.0,2.0,3.0], requires_grad=True).cuda()   #GPU 환경에서 돌리면 오류가 발생하지 않음\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "2wax3zVOhMkf",
      "metadata": {
        "id": "2wax3zVOhMkf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46ea2adf-576d-4b15-f8a8-51d95bde754f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 2., 3.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "x.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61fa582a",
      "metadata": {
        "id": "61fa582a"
      },
      "source": [
        "#### 편미분계수 계산 시 상수 텐서와 변수 텐서"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "364ca3a4",
      "metadata": {
        "id": "364ca3a4"
      },
      "source": [
        "앞서 살펴본 머신러닝 모델에 대해 경사하강법을 진행하는 경우를 생각해보자.\n",
        "\n",
        "머신러닝 모델을 다음과 같이 정의할 때\n",
        "\\begin{equation}\n",
        "\\mathscr{L}\\big(w_1, ..., w_M ; (x_n, y_n)_{n=0}^{N-1}\\big)\n",
        "\\end{equation}\n",
        "\n",
        "경사하강법을 수행하기 위해 우리는 $\\frac{d\\mathscr{L}}{dw_i}$를 각각의 $w_i$에 대해 계산해야 한다. 그러나, $\\frac{d\\mathscr{L}}{dx_i}$는 필요하지 않다. 특히, 입력 데이터셋이 크고 복잡해질수록, 필요없는 수많은 편미분계수를 일일이 계산하는 것은 쓸데없이 많은 비용이 드는 일이다.\n",
        "\n",
        "위에서 배운대로라면, PyTorch 텐서의 .backward() 메서드는 $\\mathscr{L}$를 이루는 모든 변수 텐서들에 대해 편미분계수를 계산한다. 따라서, 우리는 편미분계수 계산이 필요없는 데이터들을 변수 텐서가 아니라 상수 텐서로 표현함으로써 자동으로 .backward() 계산에서 배제되도록 할 것이다. 상수 텐서로 취급할 수 있는 방법을 알아보자."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "667de722",
      "metadata": {
        "id": "667de722"
      },
      "source": [
        "PyTorch의 텐서 객체를 생성할 때 requires_grad=False를 사용하여 상수 텐서를 생성할 수 있다. requires_grad=False로 설정된 텐서는 그래디언트 계산에 포함되지 않는다. 기본값이 requires_grad=False이므로, 특별히 지정하지 않아도 된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28053219",
      "metadata": {
        "id": "28053219"
      },
      "outputs": [],
      "source": [
        "x = tc.tensor(1.)\n",
        "y = tc.tensor(2., requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29c2bac7",
      "metadata": {
        "id": "29c2bac7"
      },
      "outputs": [],
      "source": [
        "F = x * y\n",
        "print(F)\n",
        "F.backward()\n",
        "print(F)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ba47cc3",
      "metadata": {
        "id": "0ba47cc3"
      },
      "outputs": [],
      "source": [
        "F.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fb9cb00",
      "metadata": {
        "id": "6fb9cb00"
      },
      "outputs": [],
      "source": [
        "x.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9355969c",
      "metadata": {
        "id": "9355969c"
      },
      "outputs": [],
      "source": [
        "y.grad is None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47018679",
      "metadata": {
        "id": "47018679"
      },
      "source": [
        "추가적으로, 상수 텐서만으로 정의된 텐서의 경우에는 어떤 연산을 적용하더라도 상수 텐서가 생성된다. 따라서, 이렇게 얻은 상수 텐서에 대해서는 .backward() 메서드는 에러를 발생시킨다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9be9f9c8",
      "metadata": {
        "id": "9be9f9c8"
      },
      "outputs": [],
      "source": [
        "x = tc.tensor(1.)\n",
        "y = tc.tensor(2.)\n",
        "F = x + y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae6005a5",
      "metadata": {
        "id": "ae6005a5"
      },
      "outputs": [],
      "source": [
        "F.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2b85dc5",
      "metadata": {
        "id": "d2b85dc5"
      },
      "outputs": [],
      "source": [
        "F.grad is None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b10bbdab",
      "metadata": {
        "id": "b10bbdab"
      },
      "source": [
        "### Step 3. 다차원 텐서의 자동미분 실행하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5989cb5b",
      "metadata": {
        "id": "5989cb5b"
      },
      "source": [
        "#### 다차원 텐서에 대해 정의된 함수에서의 자동미분"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95ac6652",
      "metadata": {
        "id": "95ac6652"
      },
      "source": [
        "지금까지는 하나의 스칼라 변수로 이루어진 0차원 텐서에 대해 정의된, 간단한 함수에 대해서만 자동미분을 실행해보았다. 그런데 텐서 객체는 다차원의 배열을 나타낼 수 있다. 따라서 다차원 텐서에 대해 정의된 함수에서 자동미분이 실행되는 방법을 알면 계산을 편리하게 할 수 있다.\n",
        "\n",
        "다차원 텐서와 관련된 .grad 속성을 어떻게 해석해야 할까? 한마디로 표현하면, 텐서의 각 원소를 스칼라 값 변수로 해석하면 된다. 즉, 다차원 텐서를 스칼라 변수들의 집합으로 보면 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88c0e308",
      "metadata": {
        "id": "88c0e308"
      },
      "source": [
        "이렇게만 말해서는 이해가 잘 가지 않을 것이다. 다음과 같은 계산을 통해 자세히 알아보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c211a0be",
      "metadata": {
        "id": "c211a0be"
      },
      "outputs": [],
      "source": [
        "tensor = tc.tensor([2.0, 4.0, 8.0], requires_grad=True)\n",
        "arr = tc.tensor([-1.0, 2.0, 0], requires_grad=True)\n",
        "F = (arr * tensor ** 2).sum()\n",
        "F.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9a0d070",
      "metadata": {
        "id": "b9a0d070"
      },
      "source": [
        "위의 코드에서 정의된 함수 F를 풀어서 쓰면 $F = -1\\:(x_0)^2 + 2\\:(x_1)^2 + 0\\:(x_2)^2$이다. 그리고 다차원 텐서의 각 원소를 스칼라 값 변수로 해석한다는 것은, $\\mathrm{tensor} = [x_0, x_1, x_2]$로 보겠다는 뜻이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afbb87af",
      "metadata": {
        "id": "afbb87af"
      },
      "source": [
        "이때, tensor.grad에는 어떤 값이 저장되어야 타당할까? tensor의 각 스칼라 변수들로 편미분한 값들을 tensor와 같은 shape의 배열로 저장하면 좋을 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fc1254d",
      "metadata": {
        "id": "1fc1254d"
      },
      "source": [
        "\\begin{align}\n",
        "{\\nabla}F &= \\big[\\frac{\\partial F}{\\partial x_0},\\frac{\\partial F}{\\partial x_1},\\frac{\\partial F}{\\partial x_2}\\big]\\\\\n",
        "&= \\big[-2x_0,\\:4x_1,\\:0x_2\\big]\\\\\n",
        "{\\nabla}F\\big|_{x_0=2, x_1=4, x_2=8} &= \\big[-4,\\:16,\\:0\\big]\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd9e4e53",
      "metadata": {
        "id": "cd9e4e53"
      },
      "source": [
        "실제로 tensor.grad 는 tensor에 저장된 특정 값에서의 ${\\nabla}F$ 를 저장한다. 다음 코드를 실행하여 확인해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff494ccb",
      "metadata": {
        "id": "ff494ccb"
      },
      "outputs": [],
      "source": [
        "tensor.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6637697f",
      "metadata": {
        "id": "6637697f"
      },
      "source": [
        "일반화하여 표현하면 다음과 같다. tensor의 각 원소는 스칼라 값 변수로 해석할 수 있고, tensor.grad에서 대응되는 위치의 요소는 해당 변수에 대한 미분계수이다.\n",
        "\n",
        "$\\text{tensor}[x_0, \\dots, x_{(N-1)}] \\rightarrow \\text{tensor.grad}[x_0, \\dots, x_{(N-1)}] = {\\nabla}F = \\big[\\frac{\\partial F}{\\partial x_0},\\dots,\\frac{\\partial F}{\\partial x_{(N-1)}}\\big]$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b333799",
      "metadata": {
        "id": "9b333799"
      },
      "source": [
        "#### 벡터화된 자동미분"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4eca391",
      "metadata": {
        "id": "c4eca391"
      },
      "source": [
        "방금 다차원 텐서에 의해 정의된 스칼라 함수에 대한 자동미분에 대해 배웠다. 이번에는 스칼라 함수가 아닌, 벡터 함수에 대해 자동미분을 실행할 때는 어떻게 실행되는지 알아보자.\n",
        "\n",
        ".backward() 메서드를 호출한 최종 함수가 스칼라가 아니라 벡터 함수라면, PyTorch는 최종 함수를 스칼라로 다 합친 후에 역전파를 진행해야한다.\n",
        "\n",
        "이렇게 합친 $\\sum F$는 스칼라이기 때문에 $\\frac{\\partial (\\sum F)}{\\partial x_{i}}$ 또한 스칼라이다. 따라서 위에서 살펴본 바와 같이 tensor와 tensor.grad는 항상 같은 shape을 갖는다.\n",
        "\n",
        "이렇게만 말해서는 이해가 가지 않으니, 다음과 같은 계산을 통해 알아보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43a7cb94",
      "metadata": {
        "id": "43a7cb94"
      },
      "outputs": [],
      "source": [
        "tensor = tc.linspace(-5, 5, 20, requires_grad=True)\n",
        "F = tensor ** 2  # shape-(20)인 텐서\n",
        "F_sum = F.sum()\n",
        "F_sum.backward()\n",
        "#F.backward()\n",
        "tensor.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d4fce29",
      "metadata": {
        "id": "6d4fce29"
      },
      "source": [
        "위의 코드에서 정의된 함수 F는 $F= \\big[x_0 ^2,\\ \\dots, \\; x^2_{99} \\big]$이다. 그리고 PyTorch에서 F_sum.backward()를 실행할 때 이를 스칼라로 다 합친다는 것은, $\\sum {F} = x_0 ^2 + \\dots + x^2_{99}$로 합친 후 이에 대해 .backward()를 실행하겠다는 뜻이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f3bc6ee",
      "metadata": {
        "id": "2f3bc6ee"
      },
      "source": [
        "그런데 여기서 의문이 생긴다. 다변수 벡터함수 $F$의 편미분 계수들을 구하기 위해서는 야코비 행렬을 구하는 게 합당해 보인다. 그런데 $\\sum F$에 대해 .backward()를 실행시키는 것은 매우 다른 결과를 불러온다.\n",
        "\n",
        "각 성분함수에 대한 편미분 계수들을 일일이 구하지 못하고, 대신 성분함수들의 합에 대한 편미분 계수 $\\frac{\\partial (F_0+F_1+ \\cdots + F_{N-1})}{\\partial x_i}$ 만을 구하게 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85f872b3",
      "metadata": {
        "id": "85f872b3"
      },
      "source": [
        "왜 PyTorch에서는 자동미분 기능을 이렇게 구현한 것일까? 만약 다변수 벡터함수 의 각 성분함수들이 각각 독립인 입력 변수에 대해 정의되었다면, 즉 독립인 $x_0, x_1,\\cdots, x_{(N-1)}$ 에 대해 $F=[F_0(x_0), F_1(x_1), \\cdots, F_{N-1}(x_{(N-1)})]$ 로 정의되었다면 $\\sum F$에 대해 .backward()를 실행시키는 것은 의미있는 행위가 된다. 유효한 모든 편미분 계수를 $\\big[\\frac{\\partial F_{0}}{\\partial x_0},\\dots,\\frac{\\partial F_{N-1}}{\\partial x_{(N-1)}}\\big]$ 와 같이 구할 수 있게 되기 때문이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67aadde5",
      "metadata": {
        "id": "67aadde5"
      },
      "source": [
        "다시 위의 예시로 돌아가보자.  $F= \\big[x_0 ^2,\\ \\dots, \\; x^2_{99} \\big]$에 대해 .backward()를 실행시킨 것은  $\\sum{F} = x_0 ^2 + \\dots + x^2_{99}$에 대해 .backward()를 실행시킨 것과 같다. 그리고 이후에 입력 tensor $\\rm\\textbf{x} = \\big[ x_0, x_1,\\cdots, x_{(N-1)}\\big]$ 에 대한 tensor.grad를 구하면 입력 tensor $\\rm\\textbf{x}$와 shape이 동일한 ${\\nabla}(\\Sigma{{F}}) = \\big[2x_0,\\ \\dots, \\; 2x_{99} \\big]$ 가 구해진다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94d7fc45",
      "metadata": {
        "id": "94d7fc45"
      },
      "source": [
        "이 계산은 결국, 100개의 독립적인 값들에 대해 함수 $f(x) = x ^ 2$ 의 편미분계수 값 ($\\frac{\\mathrm{d}f}{\\mathrm{d}x} = 2x$)을 한번에 계산한 것과 같았다. 따라서, PyTorch를 이용하여 독립적인 값들에 대한 성분함수로 이루어진 다변수 벡터 함수의 미분을 구하는 기능은, 여러 개의 독립적인 데이터를 하나의 텐서로 묶어서 동일한 계산을 한 번에 수행할 때 큰 이점이 있다. 신경망에 대해 배우고 본격적인 딥러닝에 대해 실습할 때 도움이 될 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b44d37d0",
      "metadata": {
        "id": "b44d37d0"
      },
      "source": [
        "### 문제: 도함수의 그래프 그리기\n",
        "\n",
        ".backward() 메서드를 이용하면 특정 점에서의 그래디언트만 구할 수 있고, 도함수의 식과 그래프는 알 수 없다. 그런데, 벡터화된 자동미분을 이용하면 여러 점에서의 편미분계수 값을 한번에 구할 수 있으므로, matplotlib을 통해 그래프를 찍을 수 있게 된다.\n",
        "\n",
        "1. 벡터화된 자동미분을 수행하는 다음의 함수를 완성해보자. matplotlib에 관한 실습1의 내용을 잘 떠올리면서 작성해보자. (주의: matplotlib에 데이터를 전달할 때는 torch의 텐서가 아닌, 널리 알려진 라이브러리인 NumPy의 배열을 사용하는 것이 좋습니다.)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " $f(x) = \\sin{(2x)}\\; \\cos{(x)}\\; e^{-x/3}$의 그래프와 그 도함수를 torch를 이용해서 그려보자."
      ],
      "metadata": {
        "id": "n-UzYgKBZkV9"
      },
      "id": "n-UzYgKBZkV9"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "63b190cf",
      "metadata": {
        "id": "63b190cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3015ebe-ca89-4bac-bb4b-752e9d151885"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0.0000,  0.0020,  0.0040,  ..., -0.0273, -0.0273, -0.0273],\n",
              "        grad_fn=<MulBackward0>),\n",
              " tensor([2.0000, 1.9987, 1.9973,  ..., 0.0021, 0.0022, 0.0024]))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "x = tc.linspace(0,10,10000, requires_grad = True)\n",
        "y = tc.sin(2*x) * tc.cos(x) * tc.exp(-x/3)\n",
        "y_sum = y.sum()\n",
        "y_sum.backward()\n",
        "y, x.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "a956957d",
      "metadata": {
        "id": "a956957d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def plot_func_and_deriv(x, func):\n",
        "    \"\"\"\n",
        "    함수 func(x)와 도함수 dfunc/dx를 같은 축(axis) 상에 그리는 함수\n",
        "\n",
        "    매개변수 (Parameters)\n",
        "    ----------\n",
        "    x : PyTorch.Tensor, shape-(N,)\n",
        "        함수 func(x)와 도함수 dfunc/dx를 그리는 x의 정의역\n",
        "\n",
        "    func: Callable[[Tensor], Tensor]\n",
        "        x에 대한 일변수 함수\n",
        "\n",
        "    반환 값 (Returns)\n",
        "    -------\n",
        "    Tuple[Figure, Axis]\n",
        "        matplotlib로 그래프를 그리기 위한 fig와 ax\n",
        "    \"\"\"\n",
        "    x = tc.tensor(x, requires_grad=True)\n",
        "    y = func(x)\n",
        "    y.sum().backward()\n",
        "\n",
        "    # 여기에 코드 작성\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(x.detach().numpy(), y.detach().numpy(), c=\"red\")\n",
        "    ax.plot(x.detach().numpy(), x.grad.detach().numpy(), c=\"blue\")\n",
        "    ax.grid(True)\n",
        "\n",
        "    return fig, ax"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6565d15f",
      "metadata": {
        "id": "6565d15f"
      },
      "source": [
        "2. 이제 위에서 작성한 함수를 이용하여 구간 $[0, 10]$를 균등하게 10,000개로 나눈 정의역에 대해 함수 $f(x) = \\sin{(2x)}\\; \\cos{(x)}\\; e^{-x/3}$와 그 도함수의 그래프를 그려보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "72733202",
      "metadata": {
        "id": "72733202"
      },
      "outputs": [],
      "source": [
        "def f(x):\n",
        "    # 여기에 코드 작성\n",
        "    return tc.sin(x) * tc.cos(x) * tc.exp(-x/3) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "7c5f677e",
      "metadata": {
        "id": "7c5f677e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "5b9a57a8-675c-4e13-85bb-9e0244722cec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-a5175a552b13>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = tc.tensor(x, requires_grad=True)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAGdCAYAAAA8F1jjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABpbElEQVR4nO3dd1zU9R8H8NcdHMvArYiiorn3FrUyB5qjTJuaaZmVaWna0FJTs0wzM3f+SsvUsuE2B6lpJu69cGuK4AYFgYP7/v54d5wEyvqOu+P1fDx4fI/j+HzffO647/s+06QoigIiIiIiJ2Q2OgAiIiKie2GiQkRERE6LiQoRERE5LSYqRERE5LSYqBAREZHTYqJCRERETouJChERETktJipERETktDyNDiCvbDYboqKi4O/vD5PJZHQ4RERElA2KouDWrVsICgqC2XzvdhOXT1SioqIQHBxsdBhERESUC//88w/KlClzz5+7fKLi7+8PQP7QgIAAVcu2Wq1Yt24dwsLCYLFYVC2bHFjP+mA964P1rA/Wsz60rOe4uDgEBwenXcfvxeUTFXt3T0BAgCaJip+fHwICAviPoCHWsz5Yz/pgPeuD9awPPeo5q2EbHExLRERETouJChERETktJipERETktJioEBERkdNiokJEREROi4kKEREROS0mKkREROS0mKgQERGR02KiQkRERE4r14nK5s2b0blzZwQFBcFkMmHp0qXpfq4oCkaOHIlSpUrB19cXbdq0wYkTJ9I95vr16+jRowcCAgJQqFAh9OnTB7dv385tSERERORmcp2oxMfHo06dOpg+fXqmP58wYQKmTJmCWbNmYfv27ShQoADatWuHxMTEtMf06NEDhw8fRnh4OFauXInNmzfj1VdfzW1IRERE5GZyvdfPY489hsceeyzTnymKgsmTJ2P48OF44oknAADz5s1DyZIlsXTpUjz33HM4evQo1qxZg507d6Jhw4YAgKlTp6JDhw6YOHEigoKCchsaERERuQlNNiU8c+YMoqOj0aZNm7T7ChYsiCZNmiAiIgLPPfccIiIiUKhQobQkBQDatGkDs9mM7du348knn8y07KSkJCQlJaV9HxcXB0A2TrJarar9DRs3mrBwoQnlyxdH27bqlUsZ2Z83NZ8/yoj1rA/Wsz5Yz/rQsp6zW6YmiUp0dDQAoGTJkunuL1myZNrPoqOjUaJEifTBeHqiSJEiaY/JzLhx4zB69OgM969btw5+fn55DT3NN9/UxMqVFdG6dWnUqxeuWrl0b+HhrGc9sJ71wXrWB+tZH1rUc0JCQrYep0mioqVhw4Zh8ODBad/HxcUhODgYYWFhCAgIUO083t4mrFwJ7N5dEq1bt4W3N7cR14rVakV4eDjatm3L7do1xHrWB+tZH6xnfWhZz/YekaxokqgEBgYCAGJiYlCqVKm0+2NiYlC3bt20x1y+fDnd76WkpOD69etpv58Zb29veHt7Z7jfYrGoWomtWgEBAQpu3vTB/v0paN7c5XI6l6P2c0iZYz3rg/WsD9azPrSo5+yWp8k6KiEhIQgMDMT69evT7ouLi8P27dsRGhoKAAgNDcXNmzexe/futMds2LABNpsNTZo00SKsHPHyAsLCFADAihUmg6MhIiLKn3KdqNy+fRv79u3Dvn37AMgA2n379uH8+fMwmUwYNGgQxo4di+XLl+PgwYN48cUXERQUhC5dugAAqlWrhvbt26Nv377YsWMH/v77bwwYMADPPfec08z46djRBgBYtYrr4hERERkh1/0Zu3btwqOPPpr2vX3cSK9evfDdd9/hvffeQ3x8PF599VXcvHkTLVq0wJo1a+Dj45P2OwsWLMCAAQPQunVrmM1mdOvWDVOmTMnDn6Ou9u0VmEwKDh0y4dIl4K5eLCIiItJBrhOVli1bQlGUe/7cZDJhzJgxGDNmzD0fU6RIESxcuDC3IWiuaFEgJCQWp08XwoYNQI8eRkdERESUv7BPIwu1a18BANw13IaIiIh0wkQlC3XqOBKV+zQgERERkQaYqGShWrXrsFgUnD8PnD5tdDRERET5CxOVLPj4pKJJE2lKYfcPERGRvpioZMMjj0iismWLwYEQERHlM0xUsqFZM0lU/v7b4ECIiIjyGSYq2dC4sQKTScao3Ge/RCIiIlIZE5VsKFgQqFlTbm/damwsRERE+QkTlWxq3lyOTFSIiIj0w0Qlm5o1kyPHqRAREemHiUo22VtUdu8GEhONjYWIiCi/YKKSTSEhQMmSgNUK7NljdDRERET5AxOVbDKZgMaN5fauXcbGQkRElF8wUcmBhg3lyESFiIhIH0xUcoCJChERkb6YqORAgwZyPHYMuHXL2FiIiIjyAyYqOVCyJFCmDKAowN69RkdDRETk/pio5JC9+2f3bmPjICIiyg+YqOQQx6kQERHph4lKDjFRISIi0g8TlRyyD6g9fhyIjTU2FiIiInfHRCWHihWTAbUAcPCgsbEQERG5OyYquVC7thwPHDA2DiIiInfHRCUX6tSR4/79xsZBRETk7pio5AITFSIiIn0wUckFe9fPwYOAzWZsLERERO6MiUouVKoE+PgACQnAqVNGR0NEROS+mKjkgqcnUKOG3Gb3DxERkXaYqOSSfZwKZ/4QERFph4lKLnFALRERkfaYqOQS11IhIiLSnqaJSmpqKkaMGIGQkBD4+vqiYsWK+Pjjj6EoStpjFEXByJEjUapUKfj6+qJNmzY4ceKElmGpwp6onD3LpfSJiIi0ommiMn78eMycORPTpk3D0aNHMX78eEyYMAFTp05Ne8yECRMwZcoUzJo1C9u3b0eBAgXQrl07JCYmahlanhUpApQuLbcPHzY2FiIiInelaaKydetWPPHEE+jYsSPKly+Pp556CmFhYdixYwcAaU2ZPHkyhg8fjieeeAK1a9fGvHnzEBUVhaVLl2oZmirsM3+OHDE2DiIiInflqWXhzZo1w+zZs3H8+HFUrlwZ+/fvx5YtWzBp0iQAwJkzZxAdHY02bdqk/U7BggXRpEkTRERE4LnnnstQZlJSEpKSktK+j4uLAwBYrVZYrVZV47eXd69yq1Y1Y906Dxw6lAqrlSu/5VZW9UzqYD3rg/WsD9azPrSs5+yWqWmiMnToUMTFxaFq1arw8PBAamoqPvnkE/To0QMAEB0dDQAoWbJkut8rWbJk2s/+a9y4cRg9enSG+9etWwc/Pz+V/wIRHh6e6f0pKeUA1MWmTdfw++8Rmpw7P7lXPZO6WM/6YD3rg/WsDy3qOSEhIVuP0zRR+fnnn7FgwQIsXLgQNWrUwL59+zBo0CAEBQWhV69euSpz2LBhGDx4cNr3cXFxCA4ORlhYGAICAtQKHYBke+Hh4Wjbti0sFkuGnxcubMKMGcDVq8XRoUMHVc+dn2RVz6QO1rM+WM/6YD3rQ8t6tveIZEXTROXdd9/F0KFD07pwatWqhXPnzmHcuHHo1asXAgMDAQAxMTEoVapU2u/FxMSgbt26mZbp7e0Nb2/vDPdbLBbNXqz3KrtWLTleuGDCnTsWqJwn5TtaPofkwHrWB+tZH6xnfWhRz9ktT9PBtAkJCTCb05/Cw8MDtn938gsJCUFgYCDWr1+f9vO4uDhs374doaGhWoamisKFAXt+xQG1RERE6tO0RaVz58745JNPULZsWdSoUQN79+7FpEmT8PLLLwMATCYTBg0ahLFjx6JSpUoICQnBiBEjEBQUhC5dumgZmmpq1AAuXZJEpWlTo6MhIiJyL5omKlOnTsWIESPwxhtv4PLlywgKCsJrr72GkSNHpj3mvffeQ3x8PF599VXcvHkTLVq0wJo1a+Dj46NlaKqpXh344w+2qBAREWlB00TF398fkydPxuTJk+/5GJPJhDFjxmDMmDFahqKZ6tXlyESFiIhIfdzrJ4/si75xdVoiIiL1MVHJo2rV5Hj+PHDrlrGxEBERuRsmKnlUtChgX6/u2DFjYyEiInI3TFRUwO4fIiIibTBRUUHVqnJkiwoREZG6mKiooEoVOUZGGhsHERGRu2GiogImKkRERNpgoqICe6Jy8iSQkmJsLERERO6EiYoKypYFfHwAqxU4d87oaIiIiNwHExUVmM1ApUpym90/RERE6mGiohKOUyEiIlIfExWVMFEhIiJSHxMVlVSuLEcmKkREROphoqIStqgQERGpj4mKSuyJyqVLQFycsbEQERG5CyYqKilUCChRQm4fP25oKERERG6DiYqK2P1DRESkLiYqKmKiQkREpC4mKipiokJERKQuJioqYqJCRESkLiYqKrInKidOADabsbEQERG5AyYqKgoJATw9gYQE4OJFo6MhIiJyfUxUVGSxAOXLy+1TpwwNhYiIyC0wUVHZgw/K8cQJY+MgIiJyB0xUVFapkhxPnjQ2DiIiInfAREVl9hYVJipERER5x0RFZUxUiIiI1MNERWV3JyqKYmwsREREro6JisrKlwfMZpmiHB1tdDRERESujYmKyry8gHLl5DZn/hAREeWN5onKxYsX8cILL6Bo0aLw9fVFrVq1sGvXrrSfK4qCkSNHolSpUvD19UWbNm1wwsWv8BynQkREpA5NE5UbN26gefPmsFgsWL16NY4cOYIvvvgChQsXTnvMhAkTMGXKFMyaNQvbt29HgQIF0K5dOyQmJmoZmqY4RZmIiEgdnloWPn78eAQHB2Pu3Llp94WEhKTdVhQFkydPxvDhw/HEE08AAObNm4eSJUti6dKleO6557QMTzNsUSEiIlKHponK8uXL0a5dOzz99NPYtGkTSpcujTfeeAN9+/YFAJw5cwbR0dFo06ZN2u8ULFgQTZo0QURERKaJSlJSEpKSktK+j4uLAwBYrVZYrVZV47eXl9Nyy5c3AfDEiRMKrNYUVWNyR7mtZ8oZ1rM+WM/6YD3rQ8t6zm6ZJkXRbhKtj48PAGDw4MF4+umnsXPnTgwcOBCzZs1Cr169sHXrVjRv3hxRUVEoVapU2u8988wzMJlMWLRoUYYyR40ahdGjR2e4f+HChfDz89PqT8mRf/55AG++2Rq+vlYsXPg7TCajIyIiInIuCQkJ6N69O2JjYxEQEHDPx2maqHh5eaFhw4bYunVr2n1vvfUWdu7ciYiIiFwlKpm1qAQHB+Pq1av3/UNzw2q1Ijw8HG3btoXFYsn27yUmAgULekJRTPjnHytKllQ1LLeT23qmnGE964P1rA/Wsz60rOe4uDgUK1Ysy0RF066fUqVKoXr16unuq1atGn777TcAQGBgIAAgJiYmXaISExODunXrZlqmt7c3vL29M9xvsVg0e7HmtGyLBQgOBs6fB86ds6BMGU3CcjtaPofkwHrWB+tZH6xnfWhRz9ktT9NZP82bN0dkZGS6+44fP45y/y40EhISgsDAQKxfvz7t53Fxcdi+fTtCQ0O1DE1zHFBLRESUd5omKm+//Ta2bduGTz/9FCdPnsTChQsxe/Zs9O/fHwBgMpkwaNAgjB07FsuXL8fBgwfx4osvIigoCF26dNEyNM1xijIREVHeadr106hRIyxZsgTDhg3DmDFjEBISgsmTJ6NHjx5pj3nvvfcQHx+PV199FTdv3kSLFi2wZs2atIG4rootKkRERHmnaaICAJ06dUKnTp3u+XOTyYQxY8ZgzJgxWoeiKyYqREREece9fjRiT1ROnOAuykRERLnFREUjFSrIMTYWuHbN2FiIiIhcFRMVjfj5AaVLy212/xAREeUOExUNVawoxzNnjI2DiIjIVTFR0ZC9++fUKWPjICIiclVMVDRkT1ROnzY2DiIiIlfFREVDTFSIiIjyhomKhpioEBER5Q0TFQ3ZE5ULF4C7NnwmIiKibGKioqESJYACBWTBt3PnjI6GiIjI9TBR0ZDJxO4fIiKivGCiojEmKkRERLnHREVjTFSIiIhyj4mKxpioEBER5R4TFY0xUSEiIso9JioauztRURRjYyEiInI1TFQ0Vr68zP65dQu4etXoaIiIiFwLExWN+fgApUvLbXb/EBER5QwTFR1wnAoREVHuMFHRARMVIiKi3GGiogMmKkRERLnDREUHTFSIiIhyh4mKDpioEBER5Q4TFR3YE5V//gGSk42NhYiIyJUwUdFBiRJAgQKy4Nu5c0ZHQ0RE5DqYqOjAZGL3DxERUW4wUdEJExUiIqKcY6KiE3uicuqUsXEQERG5EiYqOmGLChERUc4xUdEJExUiIqKc0y1R+eyzz2AymTBo0KC0+xITE9G/f38ULVoUDzzwALp164aYmBi9QtLV3YmKohgbCxERkavQJVHZuXMnvv76a9SuXTvd/W+//TZWrFiBX375BZs2bUJUVBS6du2qR0i6K19eZv/cugVcu2Z0NERERK5B80Tl9u3b6NGjB/73v/+hcOHCaffHxsbi22+/xaRJk9CqVSs0aNAAc+fOxdatW7Ft2zatw9Kdjw8QFCS3OaCWiIgoezy1PkH//v3RsWNHtGnTBmPHjk27f/fu3bBarWjTpk3afVWrVkXZsmURERGBpk2bZlpeUlISkpKS0r6Pi4sDAFitVlitVlVjt5enVrkhIR64eNGMEydSUL8++3/s1K5nyhzrWR+sZ32wnvWhZT1nt0xNE5WffvoJe/bswc6dOzP8LDo6Gl5eXihUqFC6+0uWLIno6Oh7ljlu3DiMHj06w/3r1q2Dn59fnmPOTHh4uCrlWCz1AJTF2rXH4e9/QpUy3Yla9Uz3x3rWB+tZH6xnfWhRzwkJCdl6nGaJyj///IOBAwciPDwcPj4+qpU7bNgwDB48OO37uLg4BAcHIywsDAEBAaqdB5BsLzw8HG3btoXFYslzeXv2mLFxI+DlVRUdOlTK/EG3b8P0xx8wHTokGwMFB8PWogVQrVqez++s1K5nyhzrWR+sZ32wnvWhZT3be0Syolmisnv3bly+fBn169dPuy81NRWbN2/GtGnTsHbtWiQnJ+PmzZvpWlViYmIQGBh4z3K9vb3h7e2d4X6LxaLZi1Wtsh98UI5nz5phsfxneFBcHPDxx8CsWcDt2+l+5AEATZsCn30GPPJInuNwVlo+h+TAetYH61kfrGd9aFHP2S1Ps0SldevWOHjwYLr7XnrpJVStWhXvv/8+goODYbFYsH79enTr1g0AEBkZifPnzyM0NFSrsAxln6J85sx/frBnD9Cli2yvDEhG89BDgJ8fEBkJ/PknsG0b0LIl8MYbwKRJQCbJGhERkbvRLFHx9/dHzZo1091XoEABFC1aNO3+Pn36YPDgwShSpAgCAgLw5ptvIjQ09J4DaV2dPVE5fx6wWgGLBcC6dZKk3LkjD5gyBejQQeYy28XEAKNGSWvLjBnAgQPAqlWAyl1dREREzkbzWT/38+WXX8JsNqNbt25ISkpCu3btMGPGDCND0lRgoExTTkyUxpMKUVscSUr79sBPPwEFC2b8xZIlgZkzgc6dge7dgS1bgLZtgfBwJis6URTg0CHgr7+AS5eAAgWA6tWlkYtPARGRdnRNVP7888903/v4+GD69OmYPn26nmEYxmQCQkKAo0eBM9svo8JbT0qS8thjwNKlgJfX/Qvo0AHYsAEICwN27ACefRZYsQLwNDTfdHurVgEjRgB792b8mZ8f0KcPMHIkUKyY/rEREbk77vWjs7Sl9D/8Frh6FahXD/jtt6yTFLv69YE1awBfXzm+8452weZz8fHASy8BnTpJkuLjA7RrB/TrB/TsKc9lQgIwdSpQtSqwZInRERMRuR8mKjoLCZHj6TMAChUCfv1Vko6caNgQmD9fbn/1FbB8uZohEoAbN6Th6rvvALMZGDIEuHBBcsMZM4B584CTJ2WIUa1asi1C164ycYt7ORERqYeJis4qFJBNF0+jgnwUtzex5FTXroB9PZmXXwaiolSKkOLjJUnZulVyyQ0bgIkTgaJF0z/OZJKhQrt3A2+9JfeNHCndRExWiIjUwURFT4qCCqumAgDOFKwL9OiRt/I+/RSoW1c+zvfvn+fwCEhNladl1y5JTDZvznrpGotFGrYmT5bvP/kE+PxzzUMlIsoXmKjo6fffEXJIumlOmx9MPwU5N7y9gR9+kMG0S5cCy5blPcZ87vPPpRq9veVYq1b2f3fgQEeCMnQosHKlNjESEeUnTFT0kpoKDB2KEMhqb9dueCCbqwffX82aMoACAN58M8OqtpR9u3dLtw0g41CaN895GUOGAK+9Jl0/3btzp2wiorxioqKXH34ADh2Cf2ELihezAchkhdrcGjkSKF9eFmdhn0OuJCcDL74IpKQA3brJbJ/cMJlkzb4WLYBbt2R2UEqKurESEeUnTFT0kJoKjBsnt4cORUgFqfbTp1Uq38/PkaBMnCgrklGOTJ0KHDkCFC8OfP113nrlvLxkUlZAABAR4XjqiYgo55io6GHZMuD4cZlC0q+fYy0VtRIVQJoBmjaVhT1GjVKxYPcXFeWosvHjM87uyY1y5aT7CJApy0eP5r1MIqL8iImK1hRFrn6AzMzx97/35oR5YTJJawoAfPMNcOyYioW7t5EjZWhPkyZAr17qldu9u+x6YLXKU88py0REOcdERWubN8ty9z4+aYttpC36pmaLCiCjP594ArDZZI4sZenkSVnUDQC+/FIWd1OLySTTln19gY0bgYUL1SubiCi/YKKiNXv7f69eQIkSAKBN14/dyJFyXLgQOHFCgxO4lzFjZAjRY48BoaHqlx8SAgwfLrfffVcWkyMiouxjoqKl6Ghg8WK53a9f2t32ROXsWWn8UFX9+kDHjlIwR3HeV2QksGCB3B4zRrvzDBkiz/mlS45F4YiIKHuYqGhpzhyZmxoaCtSpk3Z3mTKAhweQlKTRBB37YiA//KDyQBj38sUXks917izbJ2nF2xsYO1Zujx8ve1ESEVH2MFHRSmqqzHMFgNdfT/cjT0+ZFQJo1P3TpIlsQpOSIldjyuDKFcnjAOC997Q/37PPSmPXrVuOpIWIiLLGREUr4eHA+fNAkSLA009n+LEmM3/u9v77cpw7V7YCpnRmzQISE4FGjXK3Am1Omc2OyV8zZshOzERElDUmKlqxf1zv3l2mffyHZjN/7Fq1AmrXlnVVZs/W6CSuKSkJmD5dbr/9dt63XMquNm1kg0OrlQsIExFlFxMVLdy6BSxZIrd79sz0IZrO/AHk6vv223J76lS5OhIA4NdfgZgYGSv01FP6nts+A2j2bBlrTURE98dERQtLlgB37gCVKknfQiY07/oBgOefB0qWBC5elKszAZD18ADg1VcBi0Xfc7duLQsIJyYCkybpe24iIlfEREUL8+fLsWfPe/YraN71A8h0k/795TavigBkgbc//5SnpXdv/c9vMjlaVWbM4AwgIqKsMFFRW1QUsH693O7R454Ps7eoREVJ44tmXn9ddsnbtUu+8rk5c+TYvj0QHGxMDB06yAyg+Hhg5kxjYiAichVMVNT2yy+yOEezZo5sJBNFisjuuoAs/KaZ4sUds45mzdLwRM4vJUUmQQHAK68YF4fJBLzzjtyePl0G9xIRUeaYqKjtt9/k+Mwz932YyeTo/tF8TTb7Oi4//gjcvKnxyZzX6tUygLVECaBTJ2NjeeopGcwbEyNPCxERZY6JippiYoAtW+T2k09m+XDNZ/7YNW8O1KghU5Xt42fyIfumgD16SG+YkSwW4M035fakSdxZmYjoXpioqGnpUrniNGoElC2b5cN1S1RMJkeryqxZ+fKqGB8PLF8ut59/3thY7Pr2Bfz8gIMHgQ0bjI6GiMg5MVFRk30Dwq5ds/Vw3bp+AJmB5OcHHD4M/P23Did0LsuXS4NSxYra7uuTE4ULAy+/LLc5KYuIKHNMVNRy44bjY3E2ExXdWlQAoGBBR1NCPhxUax8H8vzz+q1Emx0DB0o8v/8uU6eJiCg9JipqWbFCppXUrAlUrpytX7k7UdGlN+bVV+X4229AbKwOJ3QO168Da9bIbWfp9rF78EGZKg049rAkIiIHJipqWbZMjtlsTQEcOyjfvg1cu6ZBTP/VqBFQvbosi7pokQ4ndA6LF8sOArVqyZ/vbOzDh+bOlaeGiIgcmKioITlZdksGgM6ds/1rPj5A6dJyW5fun7uXY/3uOx1O6Bzsuwc895yxcdxLx46y+Ny1a9zpgIjov5ioqGHLFtmIsGRJWXI0B3QdpwLIoFoPDyAiAjh2TKeTGic21jF0qFs3Y2O5Fw8PR68cV6olIkpP00Rl3LhxaNSoEfz9/VGiRAl06dIFkZGR6R6TmJiI/v37o2jRonjggQfQrVs3xMTEaBmW+n7/XY6PPQaYc1alus78AYDAQIkTyBetKmvWSLdPlSry5az69AE8PYGtW4EDB4yOhojIeWiaqGzatAn9+/fHtm3bEB4eDqvVirCwMMTHx6c95u2338aKFSvwyy+/YNOmTYiKikLXHIzzcAr2RKVDhxz/qu4tKoCj++eHH4DUVB1PrL+lS+XYpYuRUWStVClHjPlwUhYR0T1pmqisWbMGvXv3Ro0aNVCnTh189913OH/+PHbv3g0AiI2NxbfffotJkyahVatWaNCgAebOnYutW7di27ZtWoamnjNngKNHpf2+bdsc/7ohiUrnzkDRorIj4rp1Op5YX8nJjhzS2RMVAOjXT44//CADrImICPDU82Sx/06JLVKkCABg9+7dsFqtaNOmTdpjqlatirJlyyIiIgJNmzbNUEZSUhKS7trFLS4uDgBgtVphtVpVjdde3v3KNa9YAQ8AtubNkVqggPQz5EBwsAmAJ86cUWC1puQh2hwwmWB+/nl4TJsG27ffIvWu+jdCduo5N/74w4S4OE8EBiqoVy8lp0+N7lq0AB580BMnT5rw008p6NVL3TnrWtUzpcd61gfrWR9a1nN2y9QtUbHZbBg0aBCaN2+OmjVrAgCio6Ph5eWFQoUKpXtsyZIlER0dnWk548aNw+jRozPcv27dOvj5+akeNwCE22f0ZKLJvHkIBHC0fHmctH98z4Hr130AtMO5cwqWL18NT099lrcvWKECWgJQli1D+M8/w/rAA7qc937uV8+5MWtWbQAhqF37HNas2a9q2VoJDa2EkyerY9KkWBQvvkWTc6hdz5Q51rM+WM/60KKeExISsvU4k6Los/FLv379sHr1amzZsgVlypQBACxcuBAvvfRSuhYSAGjcuDEeffRRjB8/PkM5mbWoBAcH4+rVqwgICFA1ZqvVivDwcLRt2xYWiyXjA+7cgWfJkjAlJsK6Z48s9pZDNhtQqJAnEhNNOHbMmtYVpAfP+vVhOnQIKTNnQunTR78T/0eW9ZwLNhtQoYInoqJMWL48Be3bu8b+RlFRErfNZsLBg1ZVBwBrUc+UEetZH6xnfWhZz3FxcShWrBhiY2Pve/3WpUVlwIABWLlyJTZv3pyWpABAYGAgkpOTcfPmzXStKjExMQgMDMy0LG9vb3h7e2e432KxaPZivWfZf/4pK3SVLg1L3bq5Xpu9fHmZKXzhgkXfmSkvvAAMHQrPH390rDpmIDWfw7175aJfoAAQFuYJV3kfK1dOJmWtWgXMn2/BZ5+pfw4t/1fIgfWsD9azPrSo5+yWp+lgWkVRMGDAACxZsgQbNmxAiH0u7r8aNGgAi8WC9evXp90XGRmJ8+fPIzQ0VMvQ1GGPu02bPG0gY8iAWgDo3l2OmzcD58/rfHJt2ZfMb90ayCSvdWr2xq3vv5ddGYiI8jNNE5X+/ftj/vz5WLhwIfz9/REdHY3o6GjcuXMHAFCwYEH06dMHgwcPxsaNG7F792689NJLCA0NzXQgrdP54w855nEwqmGJSnAw8Mgjctu+a5+bWL1ajvZ9dFxJx45A8eJAdLTj7yAiyq80TVRmzpyJ2NhYtGzZEqVKlUr7WnTXPjNffvklOnXqhG7duuHhhx9GYGAgFi9erGVY6rh+HdizR263apWnouwNTbonKoB0/wDA/PkGnFwbsbGycBrgmomKl5csIAwAc+YYGwsRkdE07/rJ7Ku3fcExAD4+Ppg+fTquX7+O+Ph4LF68+J7jU5zKxo2y5XH16kBQUJ6Ksreo6LY67d2eekqujIcOuc2SqH/8IevYVaniSAJdzcsvy3HlSsDVFmomIlIT9/rJLfv4lNat81yUYV0/AFCoENCpk9x2k1YV+/gUV2xNsatRA2jSRMao/PCD0dEQERmHiUpuqTQ+BXB86r92Dfh3/Tp99eghxx9/lHm9LkxRHOM67FsauSp7q8qcOfJ3ERHlR0xUcuP8eeDECVk23z4YNQ/8/YFixeS2Id0/HTpIy8qFCzIDyIUdPgxcvAj4+AAPP2x0NHnz7LPydxw9CuzaZXQ0RETGYKKSG/Zun0aNgIIFVSnS0O4fHx8ZqwK4fPePvdvn0UcBX19jY8mrggWBJ5+U299/b2wsRERGYaKSGyp2+9gZOvMHcMz++fVXWcTORa1dK8d27YyNQy0vvijHH3+UTRbvKT5eXjx798rA6LNnuQgLEbkFJio5pSiyIi2Q52nJdzN05g8APPSQrKsSGyvLorqgxERgy7/b4+RiI2un1KYNUKqUzIZPt5XUlSvAN98ATz8tWe4DDwAVKwL16wO1asl9vr5A1aqygtwPPwA3bxr1ZxAR5Zquuye7hdOnZW12Ly9AxUXpDO36AQCzGXj+eWDCBGDBAqBbN4MCyb1t2yRZCQwEqlUzOhp1eHrKWOeJE4Hvv1fQpegWYNIkYPnyjAOffX1lrFFKiozKTkoCIiPla84ceHp5oVH9+jB5e0uTUx5WU6Z7UxTgwoUHMHeuCYcOAf/8A1y+LPd7espqBsHBklM2bSpbaPCpILo3Jio5ZR9s2rixqoMgDO/6AeSKOGGCtKjcuAEULmxgMDlnHzrUqpV7vfH36iWJyqplKbi69EkUwzX5Qf36MoileXOgbl1JUux/uM0mCfWBA8CmTcCqVTAdPoygbdtkOlT9+sDw4UCXLu5VWQY6fhz47jvgp588ceZM9pctqFIF6NpVel+rV9cuPiJXxUQlp+yJispTSuwtKmfPyjXGbESnXO3asgP0oUPA4sWOTWdcxIYNclRhaRvnkZCAml+/j3p4CXuV+vjJ8wUMeCkBGDTo/lc1sxkoU0a+OnQAPvsM1j178M9HHyFk40aY9uyRq+NDD0kLTcOGuv1J7mbPHuCTT4AlS+zTyE3w8kpF48YmNGliRkiItPJ5eMg4o6go4NQpYMcOGVIUGQmMGydfrVrJU9upE/NHIjsmKjmlUaISHCxvZElJwKVLQOnSqhaffT16AMOGSfePCyUqt27JGz+g6tAhY+3aJc/H8ePoBTP2oj7m1RiPAbNzscuiyQTUro2Dffsi+JtvYJk2TRKUv/6S1sGBA+Vq6+en/t/hpmJigA8+AObOdaxz06ED0KNHCjw81qBr13awWO7/iSMuTsYeLVokvXkbNshXo0bAp5+qOl6fyGVxMG1OXLggfTNmM9CsmapFe3oCZcvKbUO7f55/Xo5//ikLkriIv/6SoRkhIdLn7/LmzZMunePHgaAgPL/oSXh6Ajv3e+Po0TyWXbQoMHasfJTv3l2uspMnA3XqOEYj0339+quMg7Ivxte9u6zhs2oV8PTTCnx8UrNVTkAA8Nxz0hpz5gzw3ntAgQLAzp0yIPzxx91uY3OiHGOikhP21pT69WWVNpUZPvMHAMqVA1q0kHdfF9pR2W26fWw2uVr16iX9BI8/Dhw8iBLPtExbaXfePJXOFRwsLWe//y5NeCdPygKGn33m8isUayUhQVYMfvppGcZVrx7w999SjXkdX1K2LDB+vHQLvfUWYLEAK1ZIuZMmyf5VRPkRE5Wc0Kjbx87wmT929iX1Fy40No4cuHsgrctKTZXuts8/l+8//FA+ahcpAsCxpsr8+SpftB57TJoDXnhBEpRhw4AnnpA50ZTm4kX51587V3rSPvgA2L5d9cZVlCwJfPUVsG+ffGaIjweGDJFuoAsX1D0XkStgopITGicqTjHzB5CPi56eMtIvz/0M2rt2Td7UARdOVKxW6T/47jsZrPT999I9c9eo6k6dHDsd2JfyUU3BgtJUM3s24O0t2zY3agQcO6byiVzT3r0ylGf3buk527BBhvRYLNqds3p1mbA1e7Z0B/35p4x3X7xYu3MSOSMmKtl1+bLjot2ihSancIquH0Deie39DAsWGBtLNtgv2jVqyKdRl5OaCvTsCfz8s1z5fv7Z0XxyFx8fGc8AaLSkvskE9O0rC9KULy8Zc2ioo7kqn9q6FWjZUmbrVK8ug7ZbttTn3GazPCV798rErBs3ZImj999nVxDlH0xUsss+yLBmTbmQa8Bpun4A+XQPSPePk2/da7+OuuT4FEWRAQmLFkmSsnSpTBu+B3v+8ttvwO3bGsVUt670aYSGymq27dsD336r0cmc259/AmFhMjvnoYckabH/n+qpUiU597vvyvcTJsgMI/bOUX7ARCW7NO72ARxdP1FRwJ07mp0mex5/XJZlP3NGPmE7sU2b5KjXp1xVjR4NzJghrRnz58vV5z6aNpWLVkKCJCuaKVFC+jeef16mU73yisyXdfKkVU1//y1PR3y8jA9ZvVq1PUhzxWKRBOWnn2QW+bp10jvnAr2zRHnCRCW7dEhUihZ1TCY6d06z02SPn59j614n7v65ehU4ckRuP/SQsbHk2Pz5kqgAwPTpwDPPZPkrJpOjVUW12T/34uMjz/2HH8r3H34oH+nzQbJy8KCMCbpzRxqUVqyQcSLO4NlngYgI+WBz+rTMYre/PRG5IyYq2XH7NrB/v9zWaHwKIBchp+r+sc/+WbRIBns6IXuPXPXqQLFixsaSIzt2SCsFILNs+vXL9q/27CnHjRt1WGPDZJJBvZMmyfdffCFxu/HOzGfOyFZIN2/KjJ7ffpOczZnUri0vodBQGbfStq20tBC5IyYq2WDauVOmbZYtq/mSsU4z8weQQR8lSkizRXi40dFk6q+/5OhSrSmXLklrVVIS0LmzJAI5UK6cdHMpijTK6OLtt2Vertksq5w9+6ys8+JmYmOlu+fSJRmOtnKl8y7WW6yYjM/q2lWeCvueovmgwYvyGSYq2WCKiJAbai+YkAmnalHx9JQLEuC03T869Mipy2qVaRv2KSTz5+dqY6deveQ4b56OF6bevaV5wdtb5sg+84xbJSupqTKG/Ngx+TyyZo3z78vp6yuTxAYNku/ff1/WC2SyQu6EiUo2mLZvlxs6JiqGT1G2s3f/LF0qowqdyK1bMm0TcKEWlREjZIBBwYLAsmWyhnoudOsmn/QjIx17HOmiSxfZlMbHR+Lv1k1ahtzABx/IIr32P82w/bZyyMMD+PJL6ZUDZKftV1/l9GVyH0xUsmKzwWSf9RIaqvnpnKrrB5BVripWlGkmy5YZHU06ERHyZly+vKwG7/TWrpU10gGZ7vvgg7kuyt/fMYtZkzVV7icsTEaX+vhI30jXrkBios5BqGvhQuk2AaSHq0EDY+PJjcGDpVfObAa++UZah9yowYvyMe6enIUHLl6E6cYNaWOtU0fz893d9aMoTrDVu8kkrSpjxkj3j319FSfgUuNTLl1yjILt109aIvKoVy/pOfrxRxnrquuAzzZtZAe+Tp2kGeLJJ2W5f2cbdZoNx45JCwQgrSr2RfVc0UsvSSPd889Ll1BcHPDbT1b4XTgu2yScOyd7AVy8KIuw3LkjH0KSk6VLz9tbnsNixYDAQPkqUwaoWhWoUsX5+8JcWGKi9AhfviyN1/anxmyWp8XLS1aMKFFCFrb093eC64NOmKhkoUhkpNxo3Fjb9bL/Zd/59/ZtWRreKWaydO8uicratcCVK0Dx4kZHBMCFxqfYbDKn+MoVma5hn0GTR61ayfju8+elZ073C2yrVpKkdOwoAzoef1xa3Xx9dQ4k9+7ckaE28fEydnzMGKMjyrtuzS5hxZBIdJ0YijVrvNGu8HasVDqiIOLyXniJErIgYOPGji+XXA7aOLduyXqKBw7INPhDh6Sr/9q1nJXj6yvXi8qV5atKFdkvt2ZNXS5VumKikoUi9r1OdOj2AeTDTFCQZNanTztJolKlirSF794N/PIL8MYbRkeEpCT5ZwdcoEVl5kzgjz/knWXRItVaHcxmaVX5+GPprjCkJaBlS1kJrUMHmRnWqZN0CznrVJn/GDRILhYlSkjrlIeH0RHlgqLIYK0lSyRjPXQI7QCEIxQd8Du2KC3wqHkT1tYbhuJVi8rgmzJlZOEmPz95XXp5SatKYqJkb1evAtHR8nX2rAyGunBBPu6vWydfdpUry/zoNm3k9VCokCHV4KwSE2UpgfBw+XC1d++9Nyf38ZFGrAcecDw1Npu83yUlSZITE+NocTl6NOOCf97ejlzy4YflKXGK60geMFHJQlqiosNAWrsKFRyJSuPGup32/nr0kERlwQKnSFR27pR/3BIl5H3SaZ08KdMwABmfUrWqqsX37i2JSng48M8/Bo3VefhhaVF57DFZzbZjRxm74iwrpN3DTz/Jhn8mk7ysAwONjiiHTp2STSx/+CH9CpEmE1C3Lpo90gR/ltmNduNaYu+1ung4fjXCP5McJVdu3ZKEZdcuGcG9fbtcJY8fl6/p0yV7btpUWte6dJEPOfnQ7duSMy5dKg3R/93uonx5+exXsyZQq5a8h5UuLT1r2enOiY+XHPLUKUf1Hz4sb9GxsfLUbN8OTJ0qj69dG3j0UcklW7Vymc8RDoqLi42NVQAosbGxqpedHBOjKPJ5RVEuX1a9/Ht58UU55aef6nbKrEVFKYrJJIGdPq1q0cnJycrSpUuV5OTkbP/OJ59IKN26qRqKulJSFKVFCwn00UcVJTVVk9O0bCmn+Pjj+z8uN/WcI3//rSj+/hLMww8ryq1b2pxHBefOKUpAgIQ6fLi6ZWtaz8nJirJggeNJt3/5+ck/ww8/KMr16+l+JTJSUYKD5WHlyinKiRMqxnPjhqIsWaIo/fsrSpUq6WMCFKVqVUV5/31FiYhQFJtNxRPr8HrOodRURdmwQVF69VKUAgXSV0NQkKL07asoCxcqyj//aBvD8ePyEnnzTUWpWTPjU+LrqyidOinK118rysWLWZepZT1n9/rNROU+rMuXKwqg2B58UPWy7+ejj+QF9corup42a61bS2Bjx6pabG7+Edq3l1C++krVUNQ1aZIE+cADinLmjGan+f57OU3Five/Fujyxh4R4cgAWrRQlLg47c6VS6mpitKqlYQYGqooVqu65WtSzzduKMr48YpSurTjimMyKUq7dory00+KkpBw318/d05RKlWSXytZUlEOHFAvtHTOn1eUmTMlLosl/RWyXDlJWvbuVSVpcZZE5eZN+VcPCUn/51aqJEnwjh2afUbJlpgYRVm0SFFee01RypbNmLg0aCAf/CIjM/99Jioq0DJRSfngA0UBlNSePVUv+37sF55WrXQ9bdbmzJHAqlVT9dNRTv8RUlIcH9z37FEtDHVFRiqKj48E+fXXmp7q9m1HfWzadO/H6fbGvn27ohQsKAE1a6YoGvxv5sWUKY5GiOPH1S9f1XqOjlaUwYPTf0QPDFSU0aMlKchhUXXqSBGFCyvKtm15D+++bt5UlB9/VJRnn5Vk/b8tLaNG3fvqmA1GJyonTyrKwIGO/z1AcvS+faVxUeUGJFXYbIqyf7981mzSxNFIbv+qXVtaZo/uvSNNP/v3K9aNG5WtI0cqyUePqh6PSyUq06ZNU8qVK6d4e3srjRs3VrZv357t39UyUUn992NXyvTpqpd9P3/9JS+akBBdT5u1mzcVxdtbgtu7V7Vic/qGs2eP400hJUW1MNRjsylKmzYSZFiYLu9YffrI6Xr3vvdjdH1j37lTUQoVkqCaNpXXjhOIjJSmb0BRpk3T5hyq1POVK4ry7ruOYAFFqVVLUebOVZTExFwXe/26tCIBkvusX5/7EHMkPl5RfvlFuqfs7yH2r3r1FGXCBEU5ezZHRRqVqBw9qijduyuK2ez4E6pVk88j8fG6hpJzVqt03f/5p6L88IMSPWyy8r+H5yntiu1UPJGc7mmpiQPKaIxQDqOaXAc/+0z1cFwmUfnpp58ULy8vZc6cOcrhw4eVvn37KoUKFVJiYmKy9fuaJSopKYrt308Bybt3q1t2Fi5ckBeKh4d0STuVp56S4N55R7Uic/qGM22aIwdwSj//LAF6e8vHLh1s2eK4+NxraIjub+y7d8tHd0BRGjeW7gsDWa3yKRKQPFKr5vg81fPNm4rywQfpWyCaNFGU1atVS3hv3XLk0d7eirJ0qSrFZl9srDQbP/aYvMndfXUMDZX+3KioLIvR+/V85IiiPP98+laI9u0VZe1aJ2w9iY2VJrPvv1eUYcMUpWtXRaleXVG8vDL2/fz7dQ2FlW/xkvIYVmVIWqpaIpVvem/UIEwXSVQaN26s9O/fP+371NRUJSgoSBk3bly2fl+zRGXfPklS/PyU5Dt31C07C6mpjg8dp07peuqsLV4sgZUurVpzRk7fcF54QUL46CNVTq+uuDjHOAIdA7TZFKVyZTntnDmZP8aQT6B79ihKkSISWMOGGQZ66sk+ALtgwRz3muRIruo5JUVRvvlGUUqUcFwd6tdXlJUrNbkKJiYqypNPOj4QzZ+v+imy58oVRZk1SwYH350BmExy38yZ95zIoNfr+eTJjAlKly5O0u1ss8mI2JUrpT+nWzcZrHaPZCQtO61UScYc9u6tKCNHymvv999lQM2pU8r1szeVuXNsSseOimKx2BRAUSZOVL/5OrvXb0OnJycnJ2P37t0YNmxY2n1msxlt2rRBhH0jwP9ISkpC0l17i8TFySJGVqsVVqtVtdjMf/0FDwA3KlXCAzabbCano/LlPREZacKJEykIDlZ0Pfd9tW0Lz0KFYLp4ESkbNkBp2TLPRdqft+w+fxERngBMaNQoBVarE9UNAPOoUfC4eBFKSAhSBg/W9XXTs6cZI0Z4YM4cG154IeNGLzmtZ1XUrAmsXQvP9u1h2rULSuvWSFm9GihSRL8YINM3x4yR182kSSkIDFQ0e2pyWs+mrVvh8fbbMP27cZVSuTJSx46F8sQTMlc1JUX1GM1mmZL96qsemD/fjJ49FVy/bsPrr99jgQ+tFCwIvPyyfEVFwbx4MUy//AJzRATw55/An39CGTAASqtWsD3zDJTHH09bHVfr1/O1a8Cnn5oxa5YZVqvMGX7iCRs+/DAVdevi33NrcurMKQpw7hxMu3fL1/79MO3bB9OVK5k/vFQpKFWqQKlSBahcWW5XriyrRGaxEeoDAHq8kIIeLwBXrlgxYcIxdOlSDVaruilDtv9HFEUx7J0+KioKpUuXxtatWxF614Jq7733HjZt2oTt9hW97jJq1CiMHj06w/0LFy6En4qTw+tNmYKyGzbg2LPPIvL551UrN7vGjGmKPXtK4o039iEs7FzWv6CjOtOno3x4OM62bYv9/fvreu6bN73Qu/djAID583/HAw/om0Dej/8//6DloEEwp6Zi2/DhiGnYUNfzX7vmg759w2CzmTBz5h8oVcp5NpH0P3sWzUeOhHdcHOLKlkXEyJFI1GkVKkUBRo5shoMHi6NevRiMHLnNKZYe97l6FdXnzUPwv0ssW/38EPnsszjdoQMUnZYWtdmAb7+thVWrZO+Op5+ORPfuxwyvH98rVxD0998o89dfKHTqVNr9Ng8PXKtRA9ENGyK6USMklCql+rmTk81YubICfv21MhIS5HmoVy8GPXseQYUKKqzum03eN26g0IkTKHTqFAr/e/SOjc3wOMVsxq3SpRFboQJiQ0IQGxKCuJAQJOdyw1M9JSQkoHv37oiNjUXAfeJ1uUQlsxaV4OBgXL169b5/aI6lpCBl7178dfgwWvToAYvOaxIPHGjGzJkeePfdVHzyic6fcrJg2rQJnm3bQilYECnnz+d5yXSr1Yrw8HC0bds2y3peudKErl09UbWqggMH1P+kmWuKAo+wMJg3bYKtUyekLl5sSBidO3tg7Voz3nsvFWPHpn/d5KSeNXH4MDw7doQpKgpKcDBSVq1SfQG8zMybZ8Irr3jC11fBvn0paRt/aiXLer5zB+Yvv4R5wgSYEhKgmExQXnoJqWPGyAqGOlMUYMwYMz75RJblffZZG/73v1Tn2bbp5EmYf/kF5p9/hunw4XQ/ulWmDHy6dYOpQwcoTZvm6b3IZgMWLjRh1CgPnD8vmVrt2go++ywVbdpofJm8cUNaSXbtcrSYXLiQ4WGKpydQqxZsDRtCqVcPqFMHSs2amm5boeX7RlxcHIoVK5ZlomLoGJWkpCTFw8NDWbJkSbr7X3zxReXxxx/PVhmaLvhm4PS3L76Q7sRnn9X91FlLTXVMyF+4MM/F5aSehw2T0778cp5Pq66FCyUwHx9N10zJyi+/ONbK+G91Gj2dU1EUmdlhXxisaFHN58hevuwYIjNhgqanSnPPerbZFOXXXxWlfHnHeIHmzRVl1y59AsvCnDmK4unpWALnyhWjI8rE8eOyaEmrVorNHqz9y8tLFhocOVJWXrt9O9vFrl8vk4/sRZUpoyjffafBrEKbTf4Hli1TlDFj7j+mxGRSlBo1ZBzJtGky7V/n8ZKKwnVUFEWRwbQDBgxI+z41NVUpXbq08YNpFWPf2O1jVhs10v3U2WNfla5NmzwXlZN6fvRROe3s2Xk+rXpiYxWlVCkJLKvlYTWWnCzLbACStKT/mRMkKooiV8BGjRyLmaxapdmp7AOv69TRbwZdpvV84IDjxWsfjL5wodNNF1m/3rEETsWKMhXXWSVfuaLseOcdJbVHj/QL4dm/zGaZ6fLiizKTaPNmWf3srjo/ckRROnZMvw7KuHFZrp+XNatVlgBetUpRvvxSUd54Q5Io+5T9zL4qVlSU556TT6mbNjnNys7OkKgYvtfP4MGD0atXLzRs2BCNGzfG5MmTER8fj5deesno0AxVQbqMcfq0sXHcU+/estXsH3/IpmX2bZ81lJIiW4wAuu0RmT2jRgGXLgEPPgi8+66hoVgsMi7x00+Br78GnnrK0HAyV6yY7AnUrZtsbte5MzBxouwQqOLgiPBw2WjQZJI9fQzZUfbaNWDkSGDWLOlb8PaWvZ/ef98p90Jq1QqIiJA9Jk+dAho1ku2EunUzOrJMFCyIqBYtULdDB5g9PSXgfwfgYtMm2UTxyBH5mjcv3e9dCWmMUfHv4uuTrZCqeMDTw4Z+j0dhxIAbKF7GG7heQJ4fT0953lJT5ZicLJvp3P0VHQ1cvOj4unBBtkO+1yBoiwWoVg2oU8fxVb++7gPMXYrqKVIuTJ06VSlbtqzi5eWlNG7cWNmWg+Zgd21RiY11JNpOtrCng30xhjxOw81uPe/dK6fz93eihd4OHHCsBbF6tdHRKIoiPU/2qZR3r7zqNC0qdklJjpXq7P15eVjM7G7x8YpSoYIU+9ZbqhSZbcnJycqy335TUr76ytHvBEgzv4HdgjkRE5N+O6F33lF/q4G8yvL1HBWlKCtWyPtTp06KUrascgc+ymd4TwnAzbS/7QksUSJR6f5TenPz5esri/R16yZ91t9/L8teJCXpWk955QwtKk6RqOSFuyYqiiJd+IC8tp2SfVxG2bJ5Wj0ru/U8c6ZqvU3qsNkU5aGHJKiuXY2OJp0OHRwXGDujX8+ZstkUZfJkxzKfLVpkb6e0LAwd6hhroPd2Q9ZVq5RY+y6AgFysNmzQNwgVWK2yOK79z3j44RwvHqupnLyebTZZzb9c2VTHMjWlLykbu02V7pZHHpGxU0FB0vf13/Evd3cnFSok+xbVqiWv127dJBseP142hdywQRbqMXKDHxUxUVGBOycq9m78xYsNOX3WEhIcfa7r1uW6mOzWs31X6REjcn0qdc2b5xhnce6c0dGks2yZY7yqvZHC6Nfzfa1Z4xgcUby4fJ9L+/c7rjO6rroaGSmf3P+9qNmKFlWU6dOdrykih375xbFQbkCAXIudYWhNdl7PNpusY1a/fvrhQd9/n408IilJ3uMSE2WAU0qKc/zhOnOGROX+q76QoZx+nIqvL9Cjh9yeM0fz023bJsemTTU/VdZu3gTeeUdujxghiyg5kQ4dgDJlZIjEb78ZHU02tGsnA5Dq1AGuXAHat5dxHDlcUSs1FXj1VRke0LUr8MQTGsV7t2vXgCFDgBo1gJUroXh64lTnzkg5cgR44w0Z5+DCnnoK2LtX/u/i4oCePYFnngFiYoyO7P42bwYeflj+F/bsAR54QIbVHT8OvPhilmueAV5e8h7n7S3jSjw8VB1DRdnHRMWJ2dd7OHPG2Dju6+WX5bhkCXD9umanuXZN3mAAJ0lURo4ELl8GqlQBBg82OpoMPD2Bvn3l9qxZxsaSbZUrSzb6xhvy/YQJQMOGwK5d2S5i1ixg+3bA3x+YMkWjOO1u3ZIrX4UKwKRJkh116ICUPXtwqE+ftBVU3cGDDwJ//QV8/LG8tn79VV7606ZJcugsFEXG0rZrBzzyCLBlC+DjI3nk6dPymULFdUFJJ0xUnJjTt6gAwL+LDiEpSdbk1oi9NaVKFScYHL93LzB9utyePl0+eTmhPn3kQ+BffwGHDhkdTTb5+Eid/vYbULQocOAA0KSJzKaKv/9KuxcvAvbdOMaNA0qX1ijGhATgyy/lH/Sjj6SZoU4dYPVqQKdF7Izg6QkMHy6JYIMGMuHlzTdlZlB4uCQJRrHZgMWL5UPMo4/KZDJPT6BfP+DkSZlUVry4cfFR3jBRcWIukaiYTMArr8jtr7/W7N3Kabp9bDagf385Pvss0Lq1wQHdW+nSQJcuclvz1gW1de0KHD0KPP+81PXEiUClSsC3397zI/xbb0kjR9OmwOuvaxDT1avA6NHSzTd4sHxfuTKwaJH0LbRvr8FJnU/9+pKszJghW/Xs3QuEhQEtW8qsYD0TlthYL0yaZEaVKjKFescOyXX79ZMW2BkzNExYSTdMVJyYvevn7Fl5r3ZaPXtKe+rhw9IxrAH7HpWGr5/y/fcSTIECwBdfGBxM1gYNkuMPP8h11aUULw4sXAgsXy7/DJcuSVJcty7w44/p1qlYtkw+UXt6ypopHh4qxrFvn3RHlSsna+ZcuyafIr75Rl7zzzyTjQEP7sXDw5EMDBwojYqbN0uy0qABMHcucOeONudOSgJWrgReeMEDffqEYehQD5w8KT1tw4cD585JgqL1Vgmkn/z13+VigoPlDSEpCYiKMjqa+yhYEHjhBbk9Y4bqxaemyic4wOAWlevXZbEuQC5YLvBRrXlzuXAkJgLffOOi/+6dO0vryhdfAIUKST9W9+7SwjJpEm6duowBA+Sh77wD1KqlwjkvX5YWwsaNpXtz5kzp8qlXD/jpJyAyUvrWXHygbF6VKAFMnixrrb3+urRm7N0rQ9dKlpS3hWXLgNu383aeS5ckZ+3ZU87ZuTPw889mpKR4oGFDG/73P+D8eRlDY8B2SaSx/P1f5uQsFlnw9dQp4MQJmcXhtN54Qz7KLl4s7yoq7mp65Ii80T3wAFCzpmrF5tzw4dIsUb26fIx0ASaTtKr07AnMmmXGV1+56KwFb2/pbundW8awTJkiTY1DhmD4O564oLyFisVjMfLlWwBy8Y+SmirjYf78U66sf/3laMa0WKQP7bXXZOlWzvzIoEwZyeXGjpXeuRkzpGVjwQL58vCQhLl5c/n3qVYNCAqS8Wb+/o7FX2/elLePixelsergQRlLfexY+vMFBQFdu6YiJOQvvPlmc1gsLpqEU7YwUXFylSo5EpVHHzU6mvuoU0fehf7+G/jf/2RWjErs3T6NG6vcpJ8Tu3Y5ps9Mn27Qeuy588wz0hAUFWXC1q1B+kzZ1UqRIjJ1Y8gQ4IcfsGPKNkw9Is0pM688Bd/Kf8gUFfsg7/LlgcBA+T379NK4OEk4o6KkpebIEXl+Y2PTn6tBA+C552QuKz+mZ0vRovJae+cdGVf2yy/A0qWSU+7Y4dgCI6dMJnlKW7WSnDE0FEhNteH332Oz/F1yfUxUnFzlysCaNZKoOL033pBE5euvZfqFShdzwwfS2mzytymKrBvTsqVBgeSOl5eM/x0+HFixoiI++8zoiFTg5wfry6+h74zXoADoWXs/2vrdBnaYZZrHyZNylcwJf3+gRQugbVsZzFuunCah5wdmM9CsmXx9+aW0rmzaJGOOjx6VnrPLlzOOYzGZJCcMDJTJU7Vry1ezZhln+znTtGjSFhMVJ1epkhxdIlHp1g14+235pLpihbzZq8DwgbTffAPs3AkEBACff25QEHnz6qvA2LEKTp4sjC1bUtCqldER5d0XX0hvTdGiwBd/1AGKRwA3bshztX+/9BtcvCh9CTdvSsJps8nzWKyYXBGrVJG+iDp15IqYz8ecaKVcOWmYevHF9PffuSMztTw9pcHLvg8g0d34knByLpWoeHvLrIxPPwW++kqVROX6dUf/dJMmeS4u565edSzOMWaMqmNv9FS8ONCzpw3/+58HJkwwu3yicvKkzBQGZK21tDUyCheWubJhYYbFRtnn6ytfRPfDEUhOzp6onDrl5FOU7exLhm/enPsO6bvYi3jwQYMWbHr/fcmWatWS/hMXNmSIDWazDWvXmrF7t9HR5J6iyAyTxESgTRsZKExE7ouJipMrW1aGeiQlAf/8Y3Q02VC6tEwdBVRZZ8TQbp+//3bsYTRzpsu3SVeoADz00EUA0ujlqn74AVi/XqbCzprFSThE7o6JipPz9AQqVpTb9r1unN6QIXL89dc8b1RkT1R0H0hrtcqKVoCsl9G8uc4BaOOpp6QPcfFimeziaq5ccWytNGqU43+DiNwXExUX4FLjVAAZlNiunfRVTZ6c62JsNsdCb7q3qEyZIoMxixYFxo/X+eTaCQ6+hS5dpA/RFWf/DBokC8PWru2Ue0ESkQaYqLgAl0tUAFlIAZAZM7ncVfnoUVnyws9PpdVGs+vCBdlsDpAkpWhRHU+uvaFDZV7nggUyTdRVLF4sq5OazbJUjwstZUNEecBExQW4ZKLSurVM+UxIAKZOzVUR9vVTGjXSeXjIoEGyU2+zZsBLL+l4Yn3Urw88/ri0WI0YYXQ02XPlimOjwfffl8X/iCh/YKLiAlwyUTGZgA8+kNtffinrWOSQIQNpV60CfvtNFnWYOdNtN5v75BN5in75RRZldXYDBkiyUqOGo7GLiPIH93wXdjOVK8vx9Ol0G8Y6v6eekitLbKysq5JDug+kjYtzfGwfNEgGQripmjUd+0ja80ln9fPP8uXhIZtXe3sbHRER6YmJigsoXVqmYqakyJ4ZLsNsdnz8zWGrys2bjlkpurWovPeejE+pWFEWd3Nzo0fLOI/wcJnu64wuXZKleQBJqBo0MDYeItIfExUXYDbLgmeAi3X/ALKsfs2a0qqSgxlA9oXeKlTQaT+4jRtljyJABgD7+elwUmOFhKRvQHK21jqbTZZcv3ZNhjsNH250RERkBCYqLsIlx6kA6VtVJk2SnciyQdeNCOPjZel/QK7cLrbpYF6MGiWTmg4dAmbMMDqa9CZOBP74Q5ZY//FH2VyRiPIfJiouwmUTFUD2/GnYUHYfy+ZISF0H0n7wgQwACg52qzVTsqNIERlYCwAjR2Y7j9Tcjh3Ahx/K7SlTgGrVjI2HiIzDRMVF2AfUumSiYjZLawoAzJ4NHD5834fbbDq2qKxdK1dCe2wBARqf0Pm88opMWY6NlWE6Rrt5E3j+eemKevppWRiYiPIvJiouwqVbVADgoYekZcVmcywGdw/Hj8vFytdXxiZo5soVoHdvud2/P9C+vYYnc14eHsC0aTJd+fvvgdWrjYslNRXo0UMauMqVk9yRe/kQ5W9MVFyEPVE5exZITjY0lNwbP16mmaxZAyxffs+H2bt9GjbUcPVRRZGmhOho6Vf4/HONTuQaQkOBgQPl9iuv5GrZG1WMGgX8/rvMclu8GChUyJg4iMh5MFFxEYGBwAMPSIPE6dNGR5NLDz7o2KClf39ZtyQTuqyfMmOGJEteXrIuu6+vhidzDZ98IglxVJQjadHT4sXA2LFy+3//k+4oIiImKi7CZHKD7h9ARmxWqCDrldxjvql9fIpmA2kjIoC335bbn30G1K2r0Ylci58fMHeuvNbmzZNuIL1ERDgWoBs0yHGbiIiJiguxJyqutJFcBn5+jvVKpk0D/v473Y/j4mSqLKBRi0pMjKyYa7XKSM1BgzQ4ietq3ly6XwCgXz/gwAHtz3nsGNCpE3DnDtChQ77vhSOi/9AsUTl79iz69OmDkJAQ+Pr6omLFivjoo4+Q/J8BFgcOHMBDDz0EHx8fBAcHY8KECVqF5PKqVpWjSycqANCmjQxiVRQZOXnXgIidO+XucuWAUqVUPm9SEvDMM9K3Ua0a8O23HKmZieHDZVzxnTsy/vnKFe3OdfYs0K6dbLDduLEsla/rBpRE5PQ0S1SOHTsGm82Gr7/+GocPH8aXX36JWbNm4YO7NhaJi4tDWFgYypUrh927d+Pzzz/HqFGjMHv2bK3Ccmn2tSSOHTM2DlV89ZV0AZ07B49+/SQ7gYbrp9hsshPy5s2Av78MiPD3V/kk7sFsBubPB8qXB06dAjp2BG7fVv88p04BDz8MnD8v0+9XrgQKFFD/PETk2jT77NK+fXu0v2u6Z4UKFRAZGYmZM2di4sSJAIAFCxYgOTkZc+bMgZeXF2rUqIF9+/Zh0qRJePXVV7UKzWXZW1TcIlEJCJDlRps3h/m331ChUCGgY0ftBtJ+8IGcz9NTdke2VyZlqmhRmZzVvLm0cnXtCixdqt7OAgcOSDfPxYtAlSrAhg1A8eLqlE1E7kXXRtbY2FgUKVIk7fuIiAg8/PDD8Lprbex27dph/PjxuHHjBgoXLpyhjKSkJCQlJaV9H/fvzBGr1Qqr1apqvPby1C43t0JCAMCCq1eBS5esKFbM6IjyqF49mD/9FB7vvYeac+ci8bEO2LbtSQAmNGqUAqtVUeU05k8/hce/K86mzJoFpWVLGaOSz+T09VyhArBsmQlhYR4IDzchLMyGJUtS8zxleOVKE1580QO3b5tQvbqCtWtTULy4+zwlzva+4a5Yz/rQsp6zW6ZJURR1rgZZOHnyJBo0aICJEyeib9++AICwsDCEhITga/vgSgBHjhxBjRo1cOTIEVTLZN3sUaNGYfTo0RnuX7hwIfzywUZyffu2xZUrfvj0079Qvfp1o8PJO0VB3WnTUG79ehzxqokayQdhsaRi4cJVsFjy/tKsvGgRqv34IwDg8Isv4mTXrnkuM785dqwwPv64KeLjvRAUdBvvv78D5crdynE5VqsZCxZUxbJlD0JRTKhV6wree28n/P15oSHKjxISEtC9e3fExsYi4D6rguc4URk6dCjGZ7EfytGjR1H1rqb1ixcv4pFHHkHLli3xzTffpN2fm0QlsxaV4OBgXL169b5/aG5YrVaEh4ejbdu2sGi28ljOdOrkgXXrzJg1KwUvv6xLjqk5a3w84h9+GL8frIfe+B6hteKwaXce1zVJSYH5nXfg8e9Oe6ljx8LmDOvDGygvr+f9+4Enn/TEhQsm+Poq+OgjG95805btBfk2bjRhyBAPHDokg5dfey0VkyZl//ddiTO+b7gj1rM+tKznuLg4FCtWLMtEJcddP0OGDEFv+7Lj91ChQoW021FRUXj00UfRrFmzDINkAwMDERMTk+4++/eBgYGZlu3t7Q1vb+8M91ssFs1erFqWnVPVqwPr1gEnTni6z5t8gQLY/sEHiHjbB4gGmh37Dpa1FWTOam5cvQq8+KJjLfiJE+ExZAg81IvYpeXm9dywIbBnj0zSCg83YehQD3z7rQeGDJF9eTJ7j0lKkqdg2jRg/Xq5r1gxWcytSxcPwM2fEWd633BnrGd9aFHP2S0vx4lK8eLFUTybo94uXryIRx99FA0aNMDcuXNhNqefZBQaGooPP/wQVqs1LeDw8HBUqVIl0/Ep5GYDau+S6uuLiGIdgWgg1LoJeHyQzJMdPlxWj82u1atlF7tLl2S12R9+ALp10yzu/KR4cRlg+/33snnhiRPA668Db74JNGkis9L8/YGEBODkSWDrVrkNyBjmfv1kvT+XH1tFRLrSbHryxYsX0bJlS5QtWxYTJ07ElStXEB0djejo6LTHdO/eHV5eXujTpw8OHz6MRYsW4auvvsJg+zLrlIE9UTl61Ng41HbnjgcOHZFP2E17Vpbpyh9/DDRoAKxYkTZ9+Z5275Z5tB06SJJSrZpcKZmkqMpsllnep04BX34pM3asVmDLFmkpmTQJmDUL+OMPSVICAx1JzZQpTFKIKOc0m/UTHh6OkydP4uTJkyhTpky6n9mHxRQsWBDr1q1D//790aBBAxQrVgwjR47k1OT7sCcqZ84AiYmyeZs7OHGiMGw2E4KDgdLzxgEd68pH9UOHgMcfl4U2nnpK5i0HB8sV8+JFmTu7YgWwa5cU5Okpvzd2rHpzaSmDgABZ1HfQIElCtm2TVpTERGkACwmRHLN2ba6pR0R5o1mi0rt37yzHsgBA7dq18ddff2kVhtspUUJ2lL15Uy4QtWoZHZE6IiNl2nraQm/PPisr2H7+OTB9OnD8OPDpp/cuwMtLlsQfOVKSGtJNpUqO7R2IiNTGxapdjMkkvRoRETJOxX0SFRmTlG5F2qJFZdPADz6QZUtXr5aVwi5fBlJTZY39qlWB1q2BLl0kiyMiIrfCRMUFVa0qiYq7jFNRlHskKnYBAUD37vJFRET5CndPdkHuNvPnxAng1i1veHsrqFfP6GiIiMiZMFFxQe6WqGzbJqMt69dXcjQTmYiI3B8TFRdkT1QiI2VTYFe3fbskKk2busdKu0REpB4mKi6oQgXAYpF1Ki5cMDqavNu2TV6GTFSIiOi/mKi4IE9Px3TQI0eMjSWvbt0CDh+W20xUiIjov5iouKgaNeRov8i7qh07AJvNhOLFE1CqlNHREBGRs2Gi4qJq1pTjoUPGxpFXERFyrFr1urGBEBGRU2Ki4qLcLVGpUuWGsYEQEZFTYqLiouyJyuHDrjvzx2a7O1FhiwoREWXERMVFVawIeHsDd+7IBoWu6Phx4MYNwMdHQfnysUaHQ0REToiJiovy8ACqV5fbrtr9Y29NadBAgcXCGT9ERJQRExUX5urjVOyJSpMmTFKIiChzTFRcmLskKlw/hYiI7oWJigtz5UQlNpYLvRERUdaYqLgwe6Jy7BiQnGxsLDm1YwegKEBICBAYaHQ0RETkrJiouLDgYMDfH0hJAU6cMDqanNm6VY6hocbGQUREzo2JigszmVy3++evv+TYooWxcRARkXNjouLiXDFRsVqBbdvk9kMPGRsLERE5NyYqLs4VE5X9+4H4eKBQIcdaMERERJlhouLi7InKgQPGxpET9m6f5s0BM1+BRER0H7xMuLjateV4+jQQF2dsLNm1ZYsc2e1DRERZYaLi4ooVA8qUkduu0KqiKI5EhQNpiYgoK0xU3EC9enLcu9fYOLLj5Eng8mXZULFhQ6OjISIiZ8dExQ3UrSvHffuMjCJ77ONTGjeWZIWIiOh+mKi4AXui4gotKuz2ISKinGCi4gbsXT+HDzv/UvpMVIiIKCeYqLiB8uWBggUlSTl61Oho7i06Wpb6N5mAZs2MjoaIiFwBExU3YDK5xjiVv/+WY61astgbERFRVpiouAlXGKfCbh8iIsopXRKVpKQk1K1bFyaTCfv+85H/wIEDeOihh+Dj44Pg4GBMmDBBj5Dcjn2cijO3qPz5pxy50BsREWWXLonKe++9h6CgoAz3x8XFISwsDOXKlcPu3bvx+eefY9SoUZg9e7YeYbmVu7t+FMXISDJ3/brs8QMALVsaGgoREbkQzROV1atXY926dZg4cWKGny1YsADJycmYM2cOatSogeeeew5vvfUWJk2apHVYbqdaNcDLC4iNBc6cMTqajDZtkgSqWjUgMNDoaIiIyFV4all4TEwM+vbti6VLl8LPzy/DzyMiIvDwww/Dy8sr7b527dph/PjxuHHjBgoXLpzhd5KSkpCUlJT2fdy/G9xYrVZYrVZV47eXp3a5WjCZgJo1PbBnjxnbtqUgONi5mlU2bDAD8MDDD6fCarWl+5kr1bMrYz3rg/WsD9azPrSs5+yWqVmioigKevfujddffx0NGzbE2bNnMzwmOjoaISEh6e4rWbJk2s8yS1TGjRuH0aNHZ7h/3bp1mSZDaggPD9ekXLWVKFEbQAh+/vksChQ4bHQ46axY0RJAQQQE7MHvv0dl+hhXqWdXx3rWB+tZH6xnfWhRzwkJCdl6XI4TlaFDh2L8+PH3fczRo0exbt063Lp1C8OGDcvpKe5r2LBhGDx4cNr3cXFxCA4ORlhYGAICAlQ9l9VqRXh4ONq2bQuLxaJq2Vq4etWENWuAa9cqoEOHckaHk+bKFeDcOam/QYPqonjxuul+7mr17KpYz/pgPeuD9awPLevZ3iOSlRwnKkOGDEHv3r3v+5gKFSpgw4YNiIiIgPd/NnRp2LAhevToge+//x6BgYGIiYlJ93P794H3GMjg7e2doUwAsFgsmr1YtSxbTaGhctyzxwyTyQxPTTv2sm/rVjnWrAkEBd27Hl2lnl0d61kfrGd9sJ71oUU9Z7e8HF/KihcvjuLFi2f5uClTpmDs2LFp30dFRaFdu3ZYtGgRmjRpAgAIDQ3Fhx9+CKvVmhZweHg4qlSpkmm3D91flSqAvz9w6xZw5AhQu7bREQn7tGTO9iEiopzSbNZP2bJlUbNmzbSvypUrAwAqVqyIMmXKAAC6d+8OLy8v9OnTB4cPH8aiRYvw1Vdfpevaoezz8AAaNpTbO3YYG8vdNm6U46OPGhsHERG5HkNXpi1YsCDWrVuHM2fOoEGDBhgyZAhGjhyJV1991ciwXFrjxnJ0lkQlJkZadwDgkUeMjYWIiFyPbqMYypcvDyWTlchq166Nv/76S68w3J6zJSr2bp/atYGiRQ0NhYiIXBD3+nEz9kTl0CEgPt7YWADAPqOtdWtj4yAiItfERMXNlC4NlCoFpKYav0GhogBr18rtdu2MjYWIiFwTExU3YzIB/06qSpsWbJRjx4ALFwBvb25ESEREucNExQ21aCHHLVuMjcPemvLww4BGiwYTEZGbY6LihuytF1u2ADbb/R+rpXXr5BgWZlwMRETk2piouKF69aQF48YN4OhRY2JISnLM+OH4FCIiyi0mKm7IYgGaNpXbRs383rIFuHNHBvbWrGlMDERE5PqYqLgpe/ePUYnK3d0+JpMxMRARketjouKm7h6nYoTVq+XI8SlERJQXTFTcVJMmsvfP+fPypadz54CDBwGzmeNTiIgob5iouKkHHgDq15fbmzbpe+4VK+TYogWXzSciorxhouLGWrWS4x9/6Hve5cvl2LmzvuclIiL3w0TFjbVtK8fwcFnOXg9xcY5pyY8/rs85iYjIfTFRcWPNmwM+PsClS8CRI/qcc+1awGoFqlQBKlfW55xEROS+mKi4MR8fWb4ecOxirDV2+xARkZqYqLi5u7t/tGa1AqtWyW0mKkREpAYmKm7Onqhs2gQkJ2t7rj/+kGX7S5aUbiciIqK8YqLi5mrVAkqUAOLjtV/87eef5fjUU7KGCxERUV4xUXFzZjPQsaPcXrZMu/MkJwNLlsjtZ57R7jxERJS/MFHJB554Qo7Llmk3TXndOiA2VjYhZLcPERGphYlKPtC2LeDrK0vbHzigzTns3T5PP81uHyIiUg8TlXzAz88xqFaL7p/4eHb7EBGRNpio5BP27p+lS9Uv+9dfgdu3gQcfBJo1U798IiLKv5io5BOdO0uXzN69QGSkumXPmSPH3r0Bk0ndsomIKH9jopJPFC8OtG8vtxcsUK/ckyeBzZslQenVS71yiYiIACYq+coLL8hx/nz1Zv/MnSvHsDCgTBl1yiQiIrJjopKPPP448MADwJkzQERE3stLTARmz5bbr7yS9/KIiIj+i4lKPuLnB3TrJre//Tbv5S1cCFy9CpQtC3TpkvfyiIiI/ouJSj7Tt68cFy4Erl3LfTmKAkyeLLcHDAA8PfMcGhERUQZMVPKZZs2AunWl2yYvrSpr1wIHD0orDbt9iIhIK5omKqtWrUKTJk3g6+uLwoULo8t/+gfOnz+Pjh07ws/PDyVKlMC7776LlJQULUPK90wm4M035faMGYDVmvMyFAX46CO5/dprQOHC6sVHRER0N80Sld9++w09e/bESy+9hP379+Pvv/9G9+7d036empqKjh07Ijk5GVu3bsX333+P7777DiNHjtQqJPrX88/LdOVz54B583L++6tXAzt2yLL877+vfnxERER2miQqKSkpGDhwID7//HO8/vrrqFy5MqpXr45n7lpffd26dThy5Ajmz5+PunXr4rHHHsPHH3+M6dOnIzk5WYuw6F++vsDQoXL7449l5+PsslqB996T2/37AyVLqh8fERGRnSZDIPfs2YOLFy/CbDajXr16iI6ORt26dfH555+jZs2aAICIiAjUqlULJe+60rVr1w79+vXD4cOHUa9evUzLTkpKQlJSUtr3cXFxAACr1Qprbvox7sNentrlOoNXXgEmTvTEuXMmTJ2airfesmXr9yZPNuPwYQ8UK6bgnXdSctV19F/uXM/OhPWsD9azPljP+tCynrNbpiaJyunTpwEAo0aNwqRJk1C+fHl88cUXaNmyJY4fP44iRYogOjo6XZICIO376Ojoe5Y9btw4jB49OsP969atg5+fn4p/hUN4eLgm5RrtySfLYcaMuhg+XEHBghtQvHjifR8fFVUAI0e2BAA8++w+bNt2XtV43LWenQ3rWR+sZ32wnvWhRT0nJCRk63E5SlSGDh2K8ePH3/cxR48ehc0mn84//PBDdPt34Y65c+eiTJky+OWXX/Daa6/l5LTpDBs2DIMHD077Pi4uDsHBwQgLC0NAQECuy82M1WpFeHg42rZtC4vFomrZzqB9e2DfPhu2bvXEwoVtsWpV6j2nGScmAi1beiAx0YyHHrLhiy9qwmyuqUoc7l7PzoL1rA/Wsz5Yz/rQsp7tPSJZyVGiMmTIEPTu3fu+j6lQoQIuXboEAKhevXra/d7e3qhQoQLOn5dP4YGBgdixY0e6342JiUn72b14e3vD29s7w/0Wi0WzF6uWZRvt22+Bhg2BjRvNGDrUjMmTM24smJIiGw7u2SMzfBYuNMPbW/3hTe5cz86E9awP1rM+WM/60KKes1tejhKV4sWLo3jx4lk+rkGDBvD29kZkZCRatGgBQLKys2fPoly5cgCA0NBQfPLJJ7h8+TJKlCgBQJqWAgIC0iU4pK2qVYHvvgOefhqYMgWIjwe++gooUEB+Hh0NvPQSsGYN4OUF/PYb9/QhIiL9aDLrJyAgAK+//jo++ugjrFu3DpGRkejXrx8A4OmnnwYAhIWFoXr16ujZsyf279+PtWvXYvjw4ejfv3+mLSaknaeeAmbNkpaUb78FQkJkJ+SnnwYefFCSFD8/4JdfgEcfNTpaIiLKTzRb+Pzzzz+Hp6cnevbsiTt37qBJkybYsGEDCv+7OpiHhwdWrlyJfv36ITQ0FAUKFECvXr0wZswYrUKi+3jtNaBCBVli/7/rqzRqJJsP1q1rWHhERJRPaZaoWCwWTJw4ERMnTrznY8qVK4fff/9dqxAoh9q2BU6cANatA/bvBywWWXI/NBQwc7MFIiIyALeSo3QsFqBjR/kiIiIyGj8nExERkdNiokJEREROi4kKEREROS0mKkREROS0mKgQERGR02KiQkRERE6LiQoRERE5LSYqRERE5LSYqBAREZHTYqJCRERETouJChERETktJipERETktJioEBERkdNy+d2TFUUBAMTFxalettVqRUJCAuLi4mCxWFQvnwTrWR+sZ32wnvXBetaHlvVsv27br+P34vKJyq1btwAAwcHBBkdCREREOXXr1i0ULFjwnj83KVmlMk7OZrMhKioK/v7+MJlMqpYdFxeH4OBg/PPPPwgICFC1bHJgPeuD9awP1rM+WM/60LKeFUXBrVu3EBQUBLP53iNRXL5FxWw2o0yZMpqeIyAggP8IOmA964P1rA/Wsz5Yz/rQqp7v15Jix8G0RERE5LSYqBAREZHTYqJyH97e3vjoo4/g7e1tdChujfWsD9azPljP+mA968MZ6tnlB9MSERGR+2KLChERETktJipERETktJioEBERkdNiokJEREROi4nKPUyfPh3ly5eHj48PmjRpgh07dhgdklsZN24cGjVqBH9/f5QoUQJdunRBZGSk0WG5vc8++wwmkwmDBg0yOhS3dPHiRbzwwgsoWrQofH19UatWLezatcvosNxKamoqRowYgZCQEPj6+qJixYr4+OOPs9wvhu5v8+bN6Ny5M4KCgmAymbB06dJ0P1cUBSNHjkSpUqXg6+uLNm3a4MSJE7rExkQlE4sWLcLgwYPx0UcfYc+ePahTpw7atWuHy5cvGx2a29i0aRP69++Pbdu2ITw8HFarFWFhYYiPjzc6NLe1c+dOfP3116hdu7bRobilGzduoHnz5rBYLFi9ejWOHDmCL774AoULFzY6NLcyfvx4zJw5E9OmTcPRo0cxfvx4TJgwAVOnTjU6NJcWHx+POnXqYPr06Zn+fMKECZgyZQpmzZqF7du3o0CBAmjXrh0SExO1D06hDBo3bqz0798/7fvU1FQlKChIGTdunIFRubfLly8rAJRNmzYZHYpbunXrllKpUiUlPDxceeSRR5SBAwcaHZLbef/995UWLVoYHYbb69ixo/Lyyy+nu69r165Kjx49DIrI/QBQlixZkva9zWZTAgMDlc8//zztvps3byre3t7Kjz/+qHk8bFH5j+TkZOzevRtt2rRJu89sNqNNmzaIiIgwMDL3FhsbCwAoUqSIwZG4p/79+6Njx47pXtekruXLl6Nhw4Z4+umnUaJECdSrVw//+9//jA7L7TRr1gzr16/H8ePHAQD79+/Hli1b8Nhjjxkcmfs6c+YMoqOj071/FCxYEE2aNNHluujymxKq7erVq0hNTUXJkiXT3V+yZEkcO3bMoKjcm81mw6BBg9C8eXPUrFnT6HDczk8//YQ9e/Zg586dRofi1k6fPo2ZM2di8ODB+OCDD7Bz50689dZb8PLyQq9evYwOz20MHToUcXFxqFq1Kjw8PJCamopPPvkEPXr0MDo0txUdHQ0AmV4X7T/TEhMVMlz//v1x6NAhbNmyxehQ3M4///yDgQMHIjw8HD4+PkaH49ZsNhsaNmyITz/9FABQr149HDp0CLNmzWKioqKff/4ZCxYswMKFC1GjRg3s27cPgwYNQlBQEOvZTbHr5z+KFSsGDw8PxMTEpLs/JiYGgYGBBkXlvgYMGICVK1di48aNKFOmjNHhuJ3du3fj8uXLqF+/Pjw9PeHp6YlNmzZhypQp8PT0RGpqqtEhuo1SpUqhevXq6e6rVq0azp8/b1BE7undd9/F0KFD8dxzz6FWrVro2bMn3n77bYwbN87o0NyW/dpn1HWRicp/eHl5oUGDBli/fn3afTabDevXr0doaKiBkbkXRVEwYMAALFmyBBs2bEBISIjRIbml1q1b4+DBg9i3b1/aV8OGDdGjRw/s27cPHh4eRofoNpo3b55hiv3x48dRrlw5gyJyTwkJCTCb01+6PDw8YLPZDIrI/YWEhCAwMDDddTEuLg7bt2/X5brIrp9MDB48GL169ULDhg3RuHFjTJ48GfHx8XjppZeMDs1t9O/fHwsXLsSyZcvg7++f1s9ZsGBB+Pr6Ghyd+/D3988w7qdAgQIoWrQoxwOp7O2330azZs3w6aef4plnnsGOHTswe/ZszJ492+jQ3Ernzp3xySefoGzZsqhRowb27t2LSZMm4eWXXzY6NJd2+/ZtnDx5Mu37M2fOYN++fShSpAjKli2LQYMGYezYsahUqRJCQkIwYsQIBAUFoUuXLtoHp/m8Ihc1depUpWzZsoqXl5fSuHFjZdu2bUaH5FYAZPo1d+5co0Nze5yerJ0VK1YoNWvWVLy9vZWqVasqs2fPNjoktxMXF6cMHDhQKVu2rOLj46NUqFBB+fDDD5WkpCSjQ3NpGzduzPQ9uVevXoqiyBTlESNGKCVLllS8vb2V1q1bK5GRkbrEZlIULudHREREzoljVIiIiMhpMVEhIiIip8VEhYiIiJwWExUiIiJyWkxUiIiIyGkxUSEiIiKnxUSFiIiInBYTFSIiInJaTFSIiIjIaTFRISIiIqfFRIWIiIicFhMVIiIiclr/B/8ZFyJ6OyJRAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x = tc.linspace(0, 10, 10000)\n",
        "fig, ax = plot_func_and_deriv(x, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0a1f72a",
      "metadata": {
        "id": "c0a1f72a"
      },
      "source": [
        "### Step 4. Torch의 자동미분을 이용한 경사하강법"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72b0de77",
      "metadata": {
        "id": "72b0de77"
      },
      "source": [
        "#### 경사하강법 코드 수정하기 (1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a2062d0",
      "metadata": {
        "id": "6a2062d0"
      },
      "source": [
        "자동미분을 이용하면 경사하강법을 쉽게 구현할 수 있다. 연습을 위해 간단한 일변수 함수에 대해 경사하강법을 수행해볼 것이다. 앞선 예제에서도 다룬적 있는 함수 $\\mathscr{L}(w) = w^2$에 대한 경사하강법을 수행하며 자동미분을 잘 활용해보자.\n",
        "\n",
        "앞선 예제에서는 $\\mathscr{L}(w) = w^2$의 도함수가 $\\frac{d \\mathscr{L}}{d w} = 2w$임을 알고 있는 상태에서 경사하강법 함수 descent_down_parabola()를 작성해보았다.\n",
        "\n",
        "```python\n",
        "def descent_down_parabola(w_start, learning_rate, num_steps):\n",
        "    w_values = [w_start]\n",
        "    for _ in range(num_steps):\n",
        "        w_old = w_values[-1]\n",
        "        w_new = w_old - learning_rate * (2 * w_old)\n",
        "        w_values.append(w_new)\n",
        "    return np.array(w_values)\n",
        "```\n",
        "\n",
        "이번에는 도함수를 모르는 $\\mathscr{L}(w)$에 대해서도 적용할 수 있는, 자동미분을 이용한 경사하강법 함수를 작성해보자. $w$의 값을 PyTorch 텐서로 저장한 후, $\\mathscr{L}(w)$를 $w$의 식으로 정의해주어, .backward() 메서드를 사용하여 편미분계수를 구할 수 있다.\n",
        "\n",
        "아래의 경사하강법 공식에 따라 자동미분을 이용한 경사하강법을 프로그래밍으로 구현해보자.\n",
        "\n",
        "\\begin{equation}\n",
        "w_{\\mathrm{new}} = w_{\\mathrm{old}} - \\delta \\frac{\\mathrm{d}\\mathscr{L}}{\\mathrm{d}w}\\big|_{w_{\\mathrm{old}}}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2da681a1",
      "metadata": {
        "id": "2da681a1"
      },
      "source": [
        "다음과 같이 $w$의 시작점과 학습률 $\\delta$, 몇 단계 반복할 것인지가 주어졌다고 하자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "941881f8",
      "metadata": {
        "id": "941881f8"
      },
      "outputs": [],
      "source": [
        "#파라미터들의 초기값 설정\n",
        "w = tc.tensor([10.0], requires_grad=True)\n",
        "learning_rate = 0.3\n",
        "num_steps = 20  #파라미터 반복 횟수"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64bfcec4",
      "metadata": {
        "id": "64bfcec4"
      },
      "source": [
        "이러한 상황에 대해 아래의 코드를 채워 경사하강법을 수행하는 코드를 작성해보자. 제대로 코드를 작성한다면, 다음과 같이 $w=0$으로 서서히 가까워지는 결과가 출력될 것이다.\n",
        "```\n",
        "Tensor(4.)\n",
        "Tensor(1.6)\n",
        "Tensor(0.64)\n",
        "Tensor(0.256)\n",
        "Tensor(0.1024)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "7fda26a0",
      "metadata": {
        "id": "7fda26a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b250154-eba9-4ded-9028-46232671341c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.], requires_grad=True)\n",
            "tensor([1.6000], requires_grad=True)\n",
            "tensor([0.6400], requires_grad=True)\n",
            "tensor([0.2560], requires_grad=True)\n",
            "tensor([0.1024], requires_grad=True)\n",
            "tensor([0.0410], requires_grad=True)\n",
            "tensor([0.0164], requires_grad=True)\n",
            "tensor([0.0066], requires_grad=True)\n",
            "tensor([0.0026], requires_grad=True)\n",
            "tensor([0.0010], requires_grad=True)\n",
            "tensor([0.0004], requires_grad=True)\n",
            "tensor([0.0002], requires_grad=True)\n",
            "tensor([6.7109e-05], requires_grad=True)\n",
            "tensor([2.6844e-05], requires_grad=True)\n",
            "tensor([1.0737e-05], requires_grad=True)\n",
            "tensor([4.2950e-06], requires_grad=True)\n",
            "tensor([1.7180e-06], requires_grad=True)\n",
            "tensor([6.8719e-07], requires_grad=True)\n",
            "tensor([2.7488e-07], requires_grad=True)\n",
            "tensor([1.0995e-07], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "for _ in range(num_steps):\n",
        "    ℒ = w ** 2\n",
        "    ℒ.backward()\n",
        "    # 여기에 코드 작성\n",
        "\n",
        "    #  블록 안에서 w를 업데이트. 이는 PyTorch가 이 블록 내의 연산을 추적하지 않도록 한다.\n",
        "    #  메모리 관리에 유리하다\n",
        "    with tc.no_grad():\n",
        "      w -= learning_rate * w.grad\n",
        "    #w의 그래디언트를 초기화. 이를 통해 다음 단계에서 그래디언트가 누적되지 않도록 한다.\n",
        "    w.grad = None\n",
        "\n",
        "    print(w)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "604b8e15",
      "metadata": {
        "id": "604b8e15"
      },
      "source": [
        "그런데 코드를 작성할 때, 한가지 생각해볼만한 부분이 있다. 위의 코드를 완성하여 원하는 출력값도 제대로 얻었다면, 아래의 두 코드와 자신의 답변을 비교해보자. 꼭 먼저 코드를 직접 작성해본 후에 답변을 확인하길 바란다.\n",
        "\n",
        "다음의 두 코드는 모두 원하는 출력값을 얻게 해주는 코드이다.\n",
        "첫번째 코드는 다음과 같다.\n",
        "```python\n",
        "w = w - learning_rate * w.grad\n",
        "```\n",
        "두번째 코드는 다음과 같다.\n",
        "```python\n",
        "w.data -= learning_rate * w.grad\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "205b2767",
      "metadata": {
        "id": "205b2767"
      },
      "source": [
        "두 코드는 동일한 출력값을 얻게 해줄 뿐 아니라, 사실상 같은 의미라고 느껴진다. 그리고 첫번째 코드가 우리가 알고 있는 공식에 더 가까원 형태이기 때문에 좀 더 직관적이다. 그러나, 두번째 코드는 두가지 이점이 있다.\n",
        "\n",
        "첫째로 컴퓨터 계산 속도를 최적화할 수 있다. 앞서 PyTorch의 텐서는 NumPy 배열의 수학적 연산들을 추적하는 추가 기능을 갖고 있는 객체라는 것을 배웠다. 그러나 이렇게 수학 연산을 추적하는 과정이 w 값을 갱신하는 과정에서는 굳이 필요하지 않다. 따라서 첫번째 코드와 같이 텐서를 사용하면, 불필요한 수학 연산의 추적으로 인해 간접적인 연산 처리 시간인 오버헤드(overhead)만 발생한다. 그러나 두번째 코드에서는 직접 텐서의 데이터를 업데이트함으로써, 불필요한 연산 그래프 추적을 피한다.\n",
        "\n",
        "둘째로 추가적인 메모리 공간을 필요로 하지 않는다. 연산자 '-='는 증강 업데이트(augmented update)를 실행하는 연산자이다. 이는 컴퓨터가 새로운 메모리 공간을 할당하여 배열의 값을 교체하는 대신, 사용하던 메모리 공간을 그대로 다시 덮어쓰는 것을 의미한다. 따라서 기존 메모리 공간을 그대로 사용하므로, 메모리 사용이 최적화된다.\n",
        "\n",
        "조만간 신경망에 대해 배운 후, 어렵고 복잡한 수학적 함수의 파라미터를 조정하게 되면, 수많은 대규모 데이터를 업데이트하게 될 것이다. 이런 상황에서 위의 두가지 이점은 학습의 성능에 큰 차이를 만들 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "606ef82a",
      "metadata": {
        "id": "606ef82a"
      },
      "source": [
        "#### 경사하강법 코드 수정하기 (2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf2419b9",
      "metadata": {
        "id": "cf2419b9"
      },
      "source": [
        "이번에는 앞선 예제에서 다룬적 있는 이변수 함수 $\\mathscr{L}(w_1, w_2) = 2w_1^2 + 3w_2^2$에 대한 경사하강법을 수행하며 자동미분을 잘 활용해보자.\n",
        "\n",
        "앞선 예제에서는 $\\mathscr{L}(w) = w^2$의 도함수가 $\\frac{d \\mathscr{L}}{d w} = 2w$임을 알고 있는 상태에서 경사하강법 함수 descent_down_2d_parabola()를 작성해보았다.\n",
        "\n",
        "```python\n",
        "def descent_down_2d_parabola(w_start, learning_rate, num_steps):\n",
        "    xy_values = [w_start]\n",
        "    for _ in range(num_steps):\n",
        "        xy_old = xy_values[-1]\n",
        "        xy_new = xy_old - learning_rate * (np.array([4., 6.]) * xy_old)\n",
        "        xy_values.append(xy_new)\n",
        "    return np.array(xy_values)\n",
        "```\n",
        "\n",
        "이번에는 도함수를 모르는 $\\mathscr{L}(w_1, w_2)$에 대해서도 적용할 수 있는, 자동미분을 이용한 경사하강법 함수를 작성해보자. 다차원 텐서로 정의된 함수의 자동미분을 잘 떠올리면 해결하는 데 도움이 될 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0657ae3",
      "metadata": {
        "id": "f0657ae3"
      },
      "source": [
        "다음과 같이 $\\rm\\textbf w$의 시작점과 학습률 $\\delta$, 몇 단계 반복할 것인지가 주어졌다고 하자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "8ff9d793",
      "metadata": {
        "id": "8ff9d793"
      },
      "outputs": [],
      "source": [
        "w = tc.tensor([2., 4.], requires_grad=True)\n",
        "learning_rate = 0.1\n",
        "num_steps = 30"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c03fd2c5",
      "metadata": {
        "id": "c03fd2c5"
      },
      "source": [
        "이러한 상황에 대해 아래의 코드를 채워 경사하강법을 수행하는 코드를 작성해보자. 제대로 코드를 작성한다면, 다음과 같이 $w_1=0, w_2=0$으로 서서히 가까워지는 결과가 출력될 것이다.\n",
        "```\n",
        "Tensor([1.2, 1.6])\n",
        "Tensor([0.72, 0.64])\n",
        "Tensor([0.432, 0.256])\n",
        "Tensor([0.2592, 0.1024])\n",
        "Tensor([0.15552, 0.04096])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "6dc9819f",
      "metadata": {
        "id": "6dc9819f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01c73485-3c4b-4e2b-f5df-f9f71d575bcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 8.8430e-08, -9.2234e-13], requires_grad=True)\n",
            "tensor([ 5.3058e-08, -3.6893e-13], requires_grad=True)\n",
            "tensor([ 3.1835e-08, -1.4757e-13], requires_grad=True)\n",
            "tensor([ 1.9101e-08, -5.9030e-14], requires_grad=True)\n",
            "tensor([ 1.1460e-08, -2.3612e-14], requires_grad=True)\n",
            "tensor([ 6.8763e-09, -9.4447e-15], requires_grad=True)\n",
            "tensor([ 4.1258e-09, -3.7779e-15], requires_grad=True)\n",
            "tensor([ 2.4755e-09, -1.5112e-15], requires_grad=True)\n",
            "tensor([ 1.4853e-09, -6.0446e-16], requires_grad=True)\n",
            "tensor([ 8.9117e-10, -2.4179e-16], requires_grad=True)\n",
            "tensor([ 5.3470e-10, -9.6714e-17], requires_grad=True)\n",
            "tensor([ 3.2082e-10, -3.8686e-17], requires_grad=True)\n",
            "tensor([ 1.9249e-10, -1.5474e-17], requires_grad=True)\n",
            "tensor([ 1.1550e-10, -6.1897e-18], requires_grad=True)\n",
            "tensor([ 6.9297e-11, -2.4759e-18], requires_grad=True)\n",
            "tensor([ 4.1578e-11, -9.9035e-19], requires_grad=True)\n",
            "tensor([ 2.4947e-11, -3.9614e-19], requires_grad=True)\n",
            "tensor([ 1.4968e-11, -1.5846e-19], requires_grad=True)\n",
            "tensor([ 8.9809e-12, -6.3383e-20], requires_grad=True)\n",
            "tensor([ 5.3885e-12, -2.5353e-20], requires_grad=True)\n",
            "tensor([ 3.2331e-12, -1.0141e-20], requires_grad=True)\n",
            "tensor([ 1.9399e-12, -4.0565e-21], requires_grad=True)\n",
            "tensor([ 1.1639e-12, -1.6226e-21], requires_grad=True)\n",
            "tensor([ 6.9835e-13, -6.4904e-22], requires_grad=True)\n",
            "tensor([ 4.1901e-13, -2.5961e-22], requires_grad=True)\n",
            "tensor([ 2.5141e-13, -1.0385e-22], requires_grad=True)\n",
            "tensor([ 1.5084e-13, -4.1538e-23], requires_grad=True)\n",
            "tensor([ 9.0507e-14, -1.6615e-23], requires_grad=True)\n",
            "tensor([ 5.4304e-14, -6.6461e-24], requires_grad=True)\n",
            "tensor([ 3.2582e-14, -2.6585e-24], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "#결과적으로 1에 가까워지는 모습을 볼 수 있다\n",
        "const = tc.tensor([2.0, 3.0])\n",
        "for _ in range(num_steps):\n",
        "    ℒ = const * w ** 2\n",
        "    ℒ.sum().backward()\n",
        "    # 여기에 코드 작성\n",
        "\n",
        "    # w 업데이트 (메모리 최적화)\n",
        "    with tc.no_grad():\n",
        "      w -= learning_rate * w.grad\n",
        "    # w 값 출력\n",
        "    print(w)\n",
        "\n",
        "    # 그래디언트 초기화\n",
        "    w.grad.zero_()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f86fbb1",
      "metadata": {
        "id": "8f86fbb1"
      },
      "source": [
        "#### 일반적인 경사하강법 함수 작성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "633555d6",
      "metadata": {
        "id": "633555d6"
      },
      "source": [
        "일변수 함수, 다변수 함수에 대해 경사하강법을 수행해보았으니, 보편적인 상황에 대해 적용할 수 있는 일반적인 경사하강법 함수를 작성하는 것만 남았다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78175514",
      "metadata": {
        "id": "78175514"
      },
      "source": [
        "<문제: 일반적인 경사하강법 함수 작성하기>\n",
        "\n",
        "이 문제의 목표는 어떤 함수가 어떤 텐서로 정의되어 있는지에 상관없이 사용할 수 있는 경사하강법 함수를 작성하는 것이다. 함수 외부에서 텐서와 텐서들로 정의된 함수를 모두 정의한 후, .backward() 메서드까지 실행한다. 함수 내부로는 텐서들만 전달해주어, 함수 내에서는 그 텐서들을 이용하여 경사하강법을 실행한다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d8ac2fb",
      "metadata": {
        "id": "4d8ac2fb"
      },
      "source": [
        "아래 함수의 주석을 잘 보고, 일반적인 경사하강법 함수를 작성해보자. 주석을 보면 이 함수는 단일 텐서를 인자로 입력받을 수도 있지만, 여러개의 텐서로 이루어진 iterable한 객체를 입력받을 수도 있다. 어떻게 코딩해야 할지 막막한 느낌이 든다면, 다음 힌트를 살펴보자.\n",
        "\n",
        "> HINT\n",
        "> 1. 여러 개의 텐서로 이루어진 iterable한 자료형이 들어올 수 있으므로, for문을 이용하여 텐서를 하나씩 꺼내며 경사하강하는 코드를 작성해야한다.\n",
        "> 2. 단일 텐서가 들어오면 for문을 이용할 수 없으므로, 단일 텐서를 단일 텐서가 들어있는 리스트로 바꾸어주는 과정이 있어야 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "db9666b8",
      "metadata": {
        "id": "db9666b8"
      },
      "outputs": [],
      "source": [
        "def gradient_step(tensors, learning_rate):\n",
        "    \"\"\"\n",
        "    경사하강법의 공식에 따라 gradient-step을 실행.\n",
        "\n",
        "    매개변수 (Parameters)\n",
        "    ----------\n",
        "    tensors : Union[Tensor, Iterable[Tensors]]\n",
        "        단일 텐서, 혹은 텐서로 이루어진 iterable(리스트, 튜플 등) 모두 가능\n",
        "        만약 특정 tensor에 대한 `tensor.grad`가 `None`인 경우, 업데이트를 건너 뜀\n",
        "\n",
        "    learning_rate : float\n",
        "        매 gradient-step에서의 학습률. 양수\n",
        "\n",
        "    참고\n",
        "    -----\n",
        "    함수에서 진행되는 모든 gradient-steps는 tensor 내에서 바로 반영되므로, 반환 값 없음\n",
        "    \"\"\"\n",
        "    # isinstance 함수를 이용하여 입력된 tensors가 단일 텐서인지, iterable인지 판단한다\n",
        "\n",
        "    if isinstance(tensors, tc.Tensor):\n",
        "        # Only one tensor was provided. Pack\n",
        "        # it into a list so it can be accessed via\n",
        "        # iteration\n",
        "        tensors = [tensors]\n",
        "\n",
        "\n",
        "    # for 문을 이용하여 tensors의 tensor를 하나씩 꺼내며 경사하강을 진행\n",
        "    for i in tensors:\n",
        "      if f.grad is not None:\n",
        "        f.data -= learning_rate * t.grad\n",
        "        t.grad.zero_()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63edb99a",
      "metadata": {
        "id": "63edb99a"
      },
      "source": [
        "앞서 수행했던 함수 $\\mathscr{L}(w) = w^2$에 대한 경사하강법을 다시 한번 실행해봄으로써 보편적인 경사하강법 함수가 우리가 원하는대로 동작하는지 확인해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbf280d6",
      "metadata": {
        "id": "fbf280d6"
      },
      "outputs": [],
      "source": [
        "w = tc.tensor(10.0, requires_grad=True)\n",
        "learning_rate = 0.3\n",
        "num_steps = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9abee228",
      "metadata": {
        "id": "9abee228"
      },
      "outputs": [],
      "source": [
        "for _ in range(num_steps):\n",
        "    ℒ = w ** 2\n",
        "    ℒ.backward()\n",
        "    강의의 코드를 직접 타이핑해보세요.\n",
        "    print(w)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99313c60",
      "metadata": {
        "id": "99313c60"
      },
      "source": [
        "### 배운 내용 되돌아보기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cecca3d9",
      "metadata": {
        "id": "cecca3d9"
      },
      "source": [
        "이번 실습에서는 자동미분을 도와주는 PyTorch 라이브러리의 사용법을 배우고 익혔다. PyTorch는 앞으로의 거의 모든 실습에서 사용되는 중요한 라이브러리이다.\n",
        "\n",
        "- Tensor를 생성하는 여러 가지 함수들을 사용해보았다. 원소를 직접 적어줄 수도 있고, 리스트, 튜플, NumPy의 ndarray 등으로부터 Tensor를 생성할 수도 있었다.\n",
        "\n",
        "- 기존에 생성된 Tensor의 행과 열을 자유자재로 바꾸거나 일부 행이나 열만 슬라이싱 해보았다.\n",
        "\n",
        "- PyTorch에서 제공하는 다양한 수학 연산 함수들을 사용해보았다. 그 과정에서 NumPy의 함수들과의 유사성을 확인하였다.\n",
        "\n",
        "- 선형대수 연산을 돕는 함수인 matmul()과 einsum()을 사용해보았다.\n",
        "\n",
        "- PyTorch에 딥러닝을 위한 특수 함수들이 다양하게 존재함을 알게 되었으나, 사용해보지는 않았다.\n",
        "\n",
        "- PyTorch 텐서 객체의 .backward() 메서드를 사용하여 자동미분을 실행하고, 텐서의 .grad 속성을 이용하여 편미분 계수를 구해보았다.\n",
        "\n",
        "- 경사하강을 반복하며 최적의 모델을 찾아갈 때, 경사하강이 1회 종료될 때마다 기존의 편미분 계수를 폐기해주어야 함을 알게 되었다. 이를 위해 .grad 속성을 폐기하는 방법을 직접 사용해보았다.\n",
        "\n",
        "- PyTorch 텐서와 NumPy의 배열 사이의 관계를 알게 되었다.\n",
        "\n",
        "- 불필요한 편미분 계수를 계산하는 것을 방지하기 위해, 텐서를 상수 취급하는 방법을 도입해야 함을 알게 되었다. 그리고 텐서를 상수 취급하기 위한 방법을 사용해보았다.\n",
        "\n",
        "- 다차원 텐서에 대해 정의된 함수 (다변수 함수)에서 자동미분을 실행하면 다차원 텐서의 각 원소가 스칼라 값 변수로 해석되어 자동미분이 이루어짐을 알게 되었다. 또한 다차원 텐서의 .grad 속성에 함수의 그래디언트 값이 저장됨을 확인하였다.\n",
        "\n",
        "- 다변수 벡터 함수에 대해 자동미분을 실행하면 모든 성분함수를 합한 것에 대해 자동미분이 이루어짐을 알게 되었다. 또한 이런 규칙이 어떤 유용함을 가지는지 확인하였다.\n",
        "\n",
        "- PyTorch의 자동미분을 이용하여 경사하강법 함수를 새롭게 구현해보았다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "649f5f3b",
      "metadata": {
        "id": "649f5f3b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xfCuA6MxGEHh",
        "G1rUUHZFGi-3",
        "b-l8ieGVGv3M",
        "rbGPZ_ydG53A",
        "U0_bPo_AHGKV",
        "61fa582a",
        "b10bbdab"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}